{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "667fe6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "\n",
    "def find_all_scene_ids(dataset_dir):\n",
    "    scene_ids = []\n",
    "    for file in os.listdir(dataset_dir):\n",
    "        if file.endswith(\".edges\"):\n",
    "            scene_id = file.split(\".\")[0]\n",
    "            scene_ids.append(scene_id)\n",
    "    return scene_ids\n",
    "\n",
    "\n",
    "def load_all_subgraphs(dataset_dir):\n",
    "    scene_ids = find_all_scene_ids(dataset_dir)\n",
    "    scenes = []\n",
    "    for scene_id in scene_ids:\n",
    "        edges_file = os.path.join(dataset_dir, f\"{scene_id}.edges\")\n",
    "        nodes_file = os.path.join(dataset_dir, f\"{scene_id}.nodes\")\n",
    "        if not os.path.exists(edges_file) or not os.path.exists(nodes_file):\n",
    "            print(f\"Skipping scene ID {scene_id}: Missing files.\")\n",
    "            continue\n",
    "\n",
    "        edges = pd.read_csv(edges_file, sep=\",\", header=None, names=[\"target\", \"source\"])\n",
    "        nodes = pd.read_csv(\n",
    "            nodes_file,\n",
    "            sep=\",\",\n",
    "            header=None,\n",
    "            names=[\"node_id\", \"current_x\", \"current_y\", \"previous_x\", \"previous_y\", \"future_x\", \"future_y\"],\n",
    "        )\n",
    "        for col in nodes.columns:\n",
    "            nodes[col] = pd.to_numeric(nodes[col], errors=\"coerce\")\n",
    "\n",
    "        if nodes.isnull().any().any():\n",
    "            nan_nodes = nodes[nodes.isnull().any(axis=1)]\n",
    "            nan_node_ids = nan_nodes[\"node_id\"].tolist()\n",
    "            print(f\"Scene {scene_id}: Filtering {len(nan_node_ids)} nodes with NaN values.\")\n",
    "            edges = edges[~edges[\"source\"].isin(nan_node_ids) & ~edges[\"target\"].isin(nan_node_ids)]\n",
    "            nodes = nodes.dropna(subset=[\"future_x\", \"future_y\"])\n",
    "\n",
    "        if (edges[\"source\"] == -1).any() or (edges[\"target\"] == -1).any():\n",
    "            print(f\"Scene {scene_id} contains -1 edges. Removing these edges.\")\n",
    "            edges = edges[(edges[\"source\"] != -1) & (edges[\"target\"] != -1)]\n",
    "            connected_nodes = pd.unique(edges[[\"target\", \"source\"]].values.ravel())\n",
    "            nodes = nodes[nodes[\"node_id\"].isin(connected_nodes)]\n",
    "        if len(nodes) > 0:\n",
    "            scenes.append({\"scene_id\": scene_id, \"edges\": edges, \"nodes\": nodes})\n",
    "        else:\n",
    "            print(f\"NOTE! Scene {scene_id} skipped: no valid nodes after filtering.\")\n",
    "    return scenes\n",
    "\n",
    "\n",
    "def convert_scene_to_tensors(scene, feature_cols, target_cols):\n",
    "    nodes_df = scene[\"nodes\"].reset_index(drop=True)\n",
    "    edges_df = scene[\"edges\"].reset_index(drop=True)\n",
    "    node_id_to_idx = {nid: i for i, nid in enumerate(nodes_df[\"node_id\"])}\n",
    "    edges_df = edges_df.copy()\n",
    "    edges_df[\"target\"] = edges_df[\"target\"].map(node_id_to_idx)\n",
    "    edges_df[\"source\"] = edges_df[\"source\"].map(node_id_to_idx)\n",
    "    edges_df = edges_df.dropna().astype(int)\n",
    "    features = nodes_df[feature_cols].to_numpy().astype(np.float32)\n",
    "    targets = nodes_df[target_cols].to_numpy().astype(np.float32)\n",
    "    edges = edges_df.to_numpy().astype(np.int32)\n",
    "    return features, edges, targets\n",
    "\n",
    "\n",
    "def split_scenes(scenes, train_ratio=0.7, val_ratio=0.15):\n",
    "    np.random.shuffle(scenes)\n",
    "    n_total = len(scenes)\n",
    "    n_train = int(n_total * train_ratio)\n",
    "    n_val = int(n_total * val_ratio)\n",
    "    train_scenes = scenes[:n_train]\n",
    "    val_scenes = scenes[n_train : n_train + n_val]\n",
    "    test_scenes = scenes[n_train + n_val :]\n",
    "    return train_scenes, val_scenes, test_scenes\n",
    "\n",
    "\n",
    "def scene_generator(scene_list, feature_cols, target_cols):\n",
    "    for scene in scene_list:\n",
    "        yield convert_scene_to_tensors(scene, feature_cols, target_cols)\n",
    "\n",
    "\n",
    "def squeeze_batch(features, edges, targets):\n",
    "    return tf.squeeze(features, axis=0), tf.squeeze(edges, axis=0), tf.squeeze(targets, axis=0)\n",
    "\n",
    "\n",
    "# # 1. Fit scalers on training data\n",
    "# all_train_features = np.vstack([scene[\"nodes\"][feature_cols].values for scene in train_scenes])\n",
    "# all_train_targets = np.vstack([scene[\"nodes\"][target_cols].values for scene in train_scenes])\n",
    "# feature_scaler = StandardScaler().fit(all_train_features)\n",
    "# target_scaler = StandardScaler().fit(all_train_targets)\n",
    "\n",
    "\n",
    "# # 2. Use scalers in tensor conversion\n",
    "# def convert_scene_to_tensors(scene):\n",
    "#     nodes_df = scene[\"nodes\"].reset_index(drop=True)\n",
    "#     edges_df = scene[\"edges\"].reset_index(drop=True)\n",
    "#     node_id_to_idx = {nid: i for i, nid in enumerate(nodes_df[\"node_id\"])}\n",
    "#     edges_df = edges_df.copy()\n",
    "#     edges_df[\"target\"] = edges_df[\"target\"].map(node_id_to_idx)\n",
    "#     edges_df[\"source\"] = edges_df[\"source\"].map(node_id_to_idx)\n",
    "#     edges_df = edges_df.dropna().astype(int)\n",
    "#     features = feature_scaler.transform(nodes_df[feature_cols].to_numpy().astype(np.float32))\n",
    "#     targets = target_scaler.transform(nodes_df[target_cols].to_numpy().astype(np.float32))\n",
    "#     edges = edges_df.to_numpy().astype(np.int32)\n",
    "#     return features, edges, targets\n",
    "\n",
    "\n",
    "def mean_euclidean_distance(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.norm(y_true - y_pred, axis=-1))\n",
    "\n",
    "\n",
    "def compile_and_train(gat_model, train_dataset, val_dataset, epochs, learning_rate):\n",
    "    loss_fn = keras.losses.MeanSquaredError()\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    metrics = [\n",
    "        keras.metrics.MeanAbsoluteError(),\n",
    "        keras.metrics.MeanSquaredError(),\n",
    "        keras.metrics.RootMeanSquaredError(name=\"rmse\"),\n",
    "        keras.metrics.R2Score(),\n",
    "        keras.metrics.MeanMetricWrapper(mean_euclidean_distance, name=\"mean_euclidean_distance\"),\n",
    "    ]\n",
    "\n",
    "    gat_model.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", min_delta=1e-5, patience=15, verbose=1, restore_best_weights=True, start_from_epoch=0\n",
    "    )\n",
    "\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.1, patience=5, verbose=1, min_delta=1e-4, min_lr=1e-6\n",
    "    )\n",
    "\n",
    "    print(\"Training...\")\n",
    "    history = gat_model.fit(\n",
    "        train_dataset,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=[reduce_lr, early_stopping],\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    return gat_model, history\n",
    "\n",
    "\n",
    "def evaluate_and_plot(gat_model, history, test_dataset, task, run=\"1\"):\n",
    "    plot_dir = \"plots\"\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "    print(\"Evaluating on test dataset...\")\n",
    "    results = gat_model.evaluate(test_dataset, verbose=2)\n",
    "    print(\"Test metrics:\", results)\n",
    "\n",
    "    print(\"\\nSample predictions for test scenes:\")\n",
    "    for features, edges, targets in test_dataset.take(1):\n",
    "        predictions = gat_model((features, edges), training=False)\n",
    "        for i in range(min(5, predictions.shape[0])):\n",
    "            print(\n",
    "                f\"Node {i}: True future_x={targets[i, 0]:.1f}, future_y={targets[i, 1]:.1f} | \"\n",
    "                f\"Predicted future_x={predictions[i, 0]:.1f}, future_y={predictions[i, 1]:.1f}\"\n",
    "            )\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.scatter(targets[:20, 0], targets[:20, 1], label=\"True\", c=\"g\")\n",
    "        plt.scatter(predictions[:20, 0], predictions[:20, 1], label=\"Pred\", c=\"r\", marker=\"x\")\n",
    "        plt.legend()\n",
    "        targets_np = targets[:20].numpy()\n",
    "        predictions_np = predictions[:20].numpy()\n",
    "\n",
    "        x_min = int(np.floor(min(targets_np[:, 0].min(), predictions_np[:, 0].min()) / 500.0)) * 500\n",
    "        x_max = int(np.ceil(max(targets_np[:, 0].max(), predictions_np[:, 0].max()) / 500.0)) * 500\n",
    "        y_min = int(np.floor(min(targets_np[:, 1].min(), predictions_np[:, 1].min()) / 500.0)) * 500\n",
    "        y_max = int(np.ceil(max(targets_np[:, 1].max(), predictions_np[:, 1].max()) / 500.0)) * 500\n",
    "\n",
    "        plt.xticks(np.arange(x_min, x_max + 1, 500), rotation=45)\n",
    "        plt.yticks(np.arange(y_min, y_max + 1, 500))\n",
    "        plt.xlabel(\"future_x\")\n",
    "        plt.ylabel(\"future_y\")\n",
    "        plt.title(\"True vs Predicted Future Positions\")\n",
    "        plt.grid(True)\n",
    "        scatter_path = f\"task_{task}_run_{run}_scatter.png\" if task == 2 else f\"task_{task}_scatter.png\"\n",
    "        plt.savefig(os.path.join(plot_dir, scatter_path))\n",
    "        plt.close()\n",
    "\n",
    "    med = history.history.get(\"mean_euclidean_distance\", [])\n",
    "    mae = history.history.get(\"mean_absolute_error\", [])\n",
    "    loss = history.history.get(\"loss\", [])\n",
    "    val_loss = history.history.get(\"val_loss\", [])\n",
    "    epochs_range = range(len(loss))\n",
    "\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(12, 12), gridspec_kw={\"height_ratios\": [1, 1, 0.6]})\n",
    "\n",
    "    axs[0].plot(epochs_range, med, label=\"Mean Euclidean Distance\")\n",
    "    axs[0].plot(epochs_range, mae, label=\"Mean Absolute Error\")\n",
    "    axs[0].set_xlabel(\"Epoch\")\n",
    "    axs[0].set_ylabel(\"Distance/Error\")\n",
    "    axs[0].legend(loc=\"upper right\")\n",
    "    axs[0].set_title(\"Mean Euclidean Distance and Mean Absolute Error\")\n",
    "    axs[0].set_yscale(\"log\")\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    axs[1].plot(epochs_range, loss, label=\"Training Loss\")\n",
    "    axs[1].plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].set_ylabel(\"Loss\")\n",
    "    axs[1].legend(loc=\"upper right\")\n",
    "    axs[1].set_title(\"Training and Validation Loss\")\n",
    "    axs[1].set_yscale(\"log\")\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    if isinstance(results, list) and isinstance(results[-1], dict):\n",
    "        test_metrics = results[-1]\n",
    "    elif isinstance(results, dict):\n",
    "        test_metrics = results\n",
    "    else:\n",
    "        test_metrics = {}\n",
    "\n",
    "    cell_text = [[k.replace(\"_\", \" \").capitalize(), f\"{v.numpy():,.4f}\"] for k, v in test_metrics.items()]\n",
    "    table = axs[2].table(cellText=cell_text, colLabels=[\"Metric\", \"Value(mm)\"], loc=\"center\")\n",
    "    table.scale(1, 2)\n",
    "    axs[2].axis(\"off\")\n",
    "    axs[2].set_title(\"Test Set Metrics\", fontweight=\"bold\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    history_path = f\"task_{task}_run_{run}_history.png\" if task == 2 else f\"task_{task}_history.png\"\n",
    "    plt.savefig(os.path.join(plot_dir, history_path))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Define Model Components\n",
    "# -------------------------\n",
    "class GraphAttention(layers.Layer):\n",
    "    def __init__(self, units, kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(input_shape[0][-1], self.units),\n",
    "            trainable=True,\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            name=\"kernel\",\n",
    "        )\n",
    "        self.kernel_attention = self.add_weight(\n",
    "            shape=(self.units * 2, 1),\n",
    "            trainable=True,\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            name=\"kernel_attention\",\n",
    "        )\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        node_states, edges = inputs\n",
    "\n",
    "        # Linearly transform node states\n",
    "        node_states_transformed = tf.matmul(node_states, self.kernel)\n",
    "\n",
    "        # (1) Compute pair-wise attention scores\n",
    "        target_states = tf.gather(node_states_transformed, edges[:, 0])\n",
    "        source_states = tf.gather(node_states_transformed, edges[:, 1])\n",
    "        concat_features = tf.concat([target_states, source_states], axis=-1)\n",
    "        attention_scores = tf.nn.leaky_relu(tf.matmul(concat_features, self.kernel_attention))\n",
    "        attention_scores = tf.squeeze(attention_scores, axis=-1)\n",
    "\n",
    "        # (2) Normalize attention scores\n",
    "        attention_scores = tf.exp(tf.clip_by_value(attention_scores, -2, 2))\n",
    "        num_nodes = tf.shape(node_states)[0]\n",
    "        attention_sum = tf.math.unsorted_segment_sum(attention_scores, segment_ids=edges[:, 0], num_segments=num_nodes)\n",
    "        normalized_attention = attention_scores / tf.gather(attention_sum, edges[:, 0])\n",
    "\n",
    "        # (3) Gather node states of neighbors, apply attention scores and aggregate\n",
    "        node_states_neighbors = tf.gather(node_states_transformed, edges[:, 1])\n",
    "        out = tf.math.unsorted_segment_sum(\n",
    "            data=node_states_neighbors * normalized_attention[:, tf.newaxis],\n",
    "            segment_ids=edges[:, 0],\n",
    "            num_segments=num_nodes,\n",
    "        )\n",
    "        return out\n",
    "\n",
    "\n",
    "class CosineSimilarityGraphAttention(layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(input_shape[0][-1], self.units),\n",
    "            trainable=True,\n",
    "            initializer=\"glorot_uniform\",\n",
    "            name=\"kernel\",\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        node_states, edges = inputs\n",
    "\n",
    "        # Linearly transform node states\n",
    "        node_states_transformed = tf.matmul(node_states, self.kernel)\n",
    "\n",
    "        target_states = tf.gather(node_states_transformed, edges[:, 0])\n",
    "        source_states = tf.gather(node_states_transformed, edges[:, 1])\n",
    "\n",
    "        # Normalized vectors (safe cosine similarity)\n",
    "        normalized_target = tf.math.l2_normalize(target_states, axis=-1, epsilon=1e-8)\n",
    "        normalized_source = tf.math.l2_normalize(source_states, axis=-1, epsilon=1e-8)\n",
    "\n",
    "        cosine_sim = tf.reduce_sum(normalized_target * normalized_source, axis=-1)\n",
    "\n",
    "        # Stable softmax over incoming edges\n",
    "        num_nodes = tf.shape(node_states)[0]\n",
    "        segment_max = tf.math.unsorted_segment_max(cosine_sim, edges[:, 0], num_nodes)\n",
    "        shifted_sim = cosine_sim - tf.gather(segment_max, edges[:, 0])\n",
    "        exp_sim = tf.exp(shifted_sim)\n",
    "\n",
    "        attention_sum = tf.math.unsorted_segment_sum(exp_sim, edges[:, 0], num_nodes)\n",
    "        normalized_attention = exp_sim / (tf.gather(attention_sum, edges[:, 0]) + 1e-8)\n",
    "\n",
    "        # Weighted sum of source node features\n",
    "        node_states_neighbors = tf.gather(node_states_transformed, edges[:, 1])\n",
    "        out = tf.math.unsorted_segment_sum(\n",
    "            data=node_states_neighbors * normalized_attention[:, tf.newaxis],\n",
    "            segment_ids=edges[:, 0],\n",
    "            num_segments=num_nodes,\n",
    "        )\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHeadGraphAttention(layers.Layer):\n",
    "    def __init__(self, units, num_heads=8, merge_type=\"concat\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.merge_type = merge_type\n",
    "        self.attention_layers = [GraphAttention(units) for _ in range(num_heads)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        node_features, edges = inputs\n",
    "\n",
    "        # Obtain outputs from each attention head\n",
    "        outputs = [attn([node_features, edges]) for attn in self.attention_layers]\n",
    "        # Concatenate or average the node states from each head\n",
    "        if self.merge_type == \"concat\":\n",
    "            outputs = tf.concat(outputs, axis=-1)\n",
    "        else:\n",
    "            outputs = tf.reduce_mean(tf.stack(outputs, axis=-1), axis=-1)\n",
    "        # Activate and return node states\n",
    "        return tf.nn.relu(outputs)\n",
    "\n",
    "\n",
    "class MultiHeadCosineGraphAttention(layers.Layer):\n",
    "    def __init__(self, units, num_heads=8, merge_type=\"concat\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.merge_type = merge_type\n",
    "        self.attention_layers = [CosineSimilarityGraphAttention(units) for _ in range(num_heads)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        node_features, edges = inputs\n",
    "\n",
    "        # Obtain outputs from each attention head\n",
    "        outputs = [attention_layer([node_features, edges]) for attention_layer in self.attention_layers]\n",
    "        # Concatenate or average the node states from each head\n",
    "        if self.merge_type == \"concat\":\n",
    "            outputs = tf.concat(outputs, axis=-1)\n",
    "        else:\n",
    "            outputs = tf.reduce_mean(tf.stack(outputs, axis=-1), axis=-1)\n",
    "        # Activate and return node states\n",
    "        return tf.nn.relu(outputs)\n",
    "\n",
    "\n",
    "class GraphAttentionNetwork(keras.Model):\n",
    "    def __init__(self, hidden_units, num_heads, num_layers, output_dim, task, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        if task == 2:\n",
    "            self.preprocess = keras.Sequential(\n",
    "                [\n",
    "                    layers.Dense(hidden_units * num_heads, activation=\"relu\"),\n",
    "                    layers.Dense(hidden_units * num_heads, activation=\"relu\"),\n",
    "                    layers.Dense(hidden_units * num_heads, activation=None),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.preprocess = layers.Dense(hidden_units * num_heads, activation=\"relu\")\n",
    "        self.attention_layers = [MultiHeadGraphAttention(hidden_units, num_heads) for _ in range(num_layers)]\n",
    "        self.output_layer = layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        node_states, edges = inputs\n",
    "        x = self.preprocess(node_states)\n",
    "        for attention_layer in self.attention_layers:\n",
    "            x = attention_layer([x, edges]) + x\n",
    "        outputs = self.output_layer(x)\n",
    "        return outputs\n",
    "\n",
    "    def train_step(self, data):\n",
    "        node_features, edges, targets = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            outputs = self([node_features, edges], training=True)\n",
    "            # Compute loss\n",
    "            loss = self.compiled_loss(targets, outputs)\n",
    "        # Compute gradients\n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        # Apply gradients (update wights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        # Update metric(s)\n",
    "        self.compiled_metrics.update_state(targets, outputs)\n",
    "        logs = {m.name: m.result() for m in self.metrics}\n",
    "        logs[\"loss\"] = loss\n",
    "\n",
    "        return logs\n",
    "\n",
    "    def predict_step(self, data):\n",
    "        node_features, edges, _ = data\n",
    "        # Forward pass\n",
    "        outputs = self([node_features, edges], training=False)\n",
    "        return outputs\n",
    "\n",
    "    def test_step(self, data):\n",
    "        node_features, edges, targets = data\n",
    "        # Forward pass\n",
    "        outputs = self([node_features, edges], training=False)\n",
    "        # Compute loss\n",
    "        loss = self.compiled_loss(targets, outputs)\n",
    "        # Update metric(s)\n",
    "        self.compiled_metrics.update_state(targets, outputs)\n",
    "        logs = {m.name: m.result() for m in self.metrics}\n",
    "        logs[\"loss\"] = loss\n",
    "\n",
    "        return logs\n",
    "\n",
    "\n",
    "class CosineGraphAttentionNetwork(keras.Model):\n",
    "    def __init__(self, hidden_units, num_heads, num_layers, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.preprocess = layers.Dense(hidden_units * num_heads, activation=\"relu\")\n",
    "        self.attention_layers = [MultiHeadCosineGraphAttention(hidden_units, num_heads) for _ in range(num_layers)]\n",
    "        self.output_layer = layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        node_features, edges = inputs\n",
    "        x = self.preprocess(node_features)\n",
    "        for attention_layer in self.attention_layers:\n",
    "            x = attention_layer([x, edges]) + x\n",
    "        outputs = self.output_layer(x)\n",
    "        return outputs\n",
    "\n",
    "    def train_step(self, data):\n",
    "        node_features, edges, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            outputs = self([node_features, edges], training=True)\n",
    "            # Compute loss\n",
    "            loss = self.compiled_loss(targets, outputs)\n",
    "        # Compute gradients\n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        # Apply gradients (update weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        # Update metric(s)\n",
    "        self.compiled_metrics.update_state(targets, outputs)\n",
    "        logs = {m.name: m.result() for m in self.metrics}\n",
    "        logs[\"loss\"] = loss\n",
    "\n",
    "        return logs\n",
    "\n",
    "    def test_step(self, data):\n",
    "        node_features, edges, targets = data\n",
    "        # Forward pass\n",
    "        outputs = self([node_features, edges], training=False)\n",
    "        # Compute loss\n",
    "        loss = self.compiled_loss(targets, outputs)\n",
    "        # Update metric(s)\n",
    "        self.compiled_metrics.update_state(targets, outputs)\n",
    "        logs = {m.name: m.result() for m in self.metrics}\n",
    "        logs[\"loss\"] = loss\n",
    "\n",
    "        return logs\n",
    "\n",
    "    def predict_step(self, data):\n",
    "        node_features, edges, _ = data\n",
    "        return self([node_features, edges], training=False)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Model Training & Evaluation\n",
    "# -------------------------\n",
    "\n",
    "\n",
    "# # 3. Inverse-transform predictions for interpretability\n",
    "# for features, edges, targets in test_dataset.take(1):\n",
    "#     predictions = gat_model((features, edges), training=False)\n",
    "#     # Inverse-transform for readability\n",
    "#     predictions_orig = target_scaler.inverse_transform(predictions.numpy())\n",
    "#     targets_orig = target_scaler.inverse_transform(targets.numpy())\n",
    "#     for i in range(min(5, predictions.shape[0])):\n",
    "#         print(\n",
    "#             f\"Node {i}: True future_x={targets_orig[i, 0]:.1f}, future_y={targets_orig[i, 1]:.1f} | \"\n",
    "#             f\"Predicted future_x={predictions_orig[i, 0]:.1f}, future_y={predictions_orig[i, 1]:.1f}\"\n",
    "#         )\n",
    "\n",
    "# # --- Compute metrics in original scale ---\n",
    "\n",
    "\n",
    "# # Collect all predictions and targets\n",
    "# all_preds = []\n",
    "# all_targets = []\n",
    "# for features, edges, targets in test_dataset:\n",
    "#     preds = gat_model((features, edges), training=False)\n",
    "#     all_preds.append(preds.numpy())\n",
    "#     all_targets.append(targets.numpy())\n",
    "\n",
    "# all_preds = np.vstack(all_preds)\n",
    "# all_targets = np.vstack(all_targets)\n",
    "\n",
    "# # Inverse transform\n",
    "# all_preds_orig = target_scaler.inverse_transform(all_preds)\n",
    "# all_targets_orig = target_scaler.inverse_transform(all_targets)\n",
    "\n",
    "# # Compute metrics\n",
    "# mae_orig = mean_absolute_error(all_targets_orig, all_preds_orig)\n",
    "# mse_orig = mean_squared_error(all_targets_orig, all_preds_orig)\n",
    "# euclidean_orig = np.mean(np.linalg.norm(all_targets_orig - all_preds_orig, axis=1))\n",
    "\n",
    "# print(f\"Test MAE (original scale): {mae_orig:.4f}\")\n",
    "# print(f\"Test MSE (original scale): {mse_orig:.4f}\")\n",
    "# print(f\"Test Mean Euclidean Distance (original scale): {euclidean_orig:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1803a559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene 1352890817715: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890817715 contains -1 edges. Removing these edges.\n",
      "Scene 1352890814428: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890814428 contains -1 edges. Removing these edges.\n",
      "Scene 1352890802323 contains -1 edges. Removing these edges.\n",
      "Scene 1352890800322: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890800322 contains -1 edges. Removing these edges.\n",
      "Scene 1352890875617 contains -1 edges. Removing these edges.\n",
      "Scene 1352890804562: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890804562 contains -1 edges. Removing these edges.\n",
      "Scene 1352890841688: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890841688 contains -1 edges. Removing these edges.\n",
      "Scene 1352890837555 contains -1 edges. Removing these edges.\n",
      "Scene 1352890825684 contains -1 edges. Removing these edges.\n",
      "Scene 1352890801553: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890801553 contains -1 edges. Removing these edges.\n",
      "Scene 1352890832535: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890832535 contains -1 edges. Removing these edges.\n",
      "Scene 1352890829505: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890829505 contains -1 edges. Removing these edges.\n",
      "Scene 1352890803926: Filtering 2 nodes with NaN values.\n",
      "Scene 1352890803926 contains -1 edges. Removing these edges.\n",
      "Scene 1352890842354: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890842354 contains -1 edges. Removing these edges.\n",
      "Scene 1352890813672 contains -1 edges. Removing these edges.\n",
      "Scene 1352890884154 contains -1 edges. Removing these edges.\n",
      "Scene 1352890846971: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890846971 contains -1 edges. Removing these edges.\n",
      "Scene 1352890834297 contains -1 edges. Removing these edges.\n",
      "Scene 1352890834338 contains -1 edges. Removing these edges.\n",
      "Scene 1352890812682: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890812682 contains -1 edges. Removing these edges.\n",
      "Scene 1352890801292: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890801292 contains -1 edges. Removing these edges.\n",
      "Scene 1352890807487: Filtering 2 nodes with NaN values.\n",
      "Scene 1352890807487 contains -1 edges. Removing these edges.\n",
      "Scene 1352890815643 contains -1 edges. Removing these edges.\n",
      "Scene 1352890808973 contains -1 edges. Removing these edges.\n",
      "Scene 1352890834536 contains -1 edges. Removing these edges.\n",
      "Scene 1352890836794 contains -1 edges. Removing these edges.\n",
      "Scene 1352890828841 contains -1 edges. Removing these edges.\n",
      "Scene 1352890919291: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890919291 contains -1 edges. Removing these edges.\n",
      "Scene 1352890828882 contains -1 edges. Removing these edges.\n",
      "Scene 1352890891802 contains -1 edges. Removing these edges.\n",
      "Scene 1352890801118 contains -1 edges. Removing these edges.\n",
      "Scene 1352890849798: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890849798 contains -1 edges. Removing these edges.\n",
      "Scene 1352890894347: Filtering 2 nodes with NaN values.\n",
      "Scene 1352890894347 contains -1 edges. Removing these edges.\n",
      "Scene 1352890800459: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890800459 contains -1 edges. Removing these edges.\n",
      "Scene 1352890803486: Filtering 2 nodes with NaN values.\n",
      "Scene 1352890803486 contains -1 edges. Removing these edges.\n",
      "Scene 1352890829713: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890829713 contains -1 edges. Removing these edges.\n",
      "Scene 1352890828668 contains -1 edges. Removing these edges.\n",
      "Scene 1352890809063 contains -1 edges. Removing these edges.\n",
      "Scene 1352890829002: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890829002 contains -1 edges. Removing these edges.\n",
      "Scene 1352890918879 contains -1 edges. Removing these edges.\n",
      "Scene 1352890890812: Filtering 2 nodes with NaN values.\n",
      "Scene 1352890890812 contains -1 edges. Removing these edges.\n",
      "Scene 1352890837871 contains -1 edges. Removing these edges.\n",
      "Scene 135289080699: Filtering 2 nodes with NaN values.\n",
      "Scene 135289080699 contains -1 edges. Removing these edges.\n",
      "Scene 1352890815512: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890815512 contains -1 edges. Removing these edges.\n",
      "Scene 1352890829207: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890829207 contains -1 edges. Removing these edges.\n",
      "Scene 1352890839303 contains -1 edges. Removing these edges.\n",
      "Scene 1352890919525: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890919525 contains -1 edges. Removing these edges.\n",
      "Scene 135289083242: Filtering 1 nodes with NaN values.\n",
      "Scene 135289083242 contains -1 edges. Removing these edges.\n",
      "Scene 1352890832654: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890832654 contains -1 edges. Removing these edges.\n",
      "Scene 135289082308 contains -1 edges. Removing these edges.\n",
      "Scene 1352890832698: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890832698 contains -1 edges. Removing these edges.\n",
      "Scene 1352890818928: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890818928 contains -1 edges. Removing these edges.\n",
      "Scene 1352890809821: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890809821 contains -1 edges. Removing these edges.\n",
      "Scene 1352890803574: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890803574 contains -1 edges. Removing these edges.\n",
      "Scene 13528908000089998: Filtering 1 nodes with NaN values.\n",
      "Scene 13528908000089998 contains -1 edges. Removing these edges.\n",
      "Scene 1352890830824 contains -1 edges. Removing these edges.\n",
      "Scene 1352890849578: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890849578 contains -1 edges. Removing these edges.\n",
      "Scene 1352890826701 contains -1 edges. Removing these edges.\n",
      "Scene 13528908087 contains -1 edges. Removing these edges.\n",
      "Scene 1352890833057: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890833057 contains -1 edges. Removing these edges.\n",
      "Scene 1352890809106 contains -1 edges. Removing these edges.\n",
      "Scene 1352890834498 contains -1 edges. Removing these edges.\n",
      "Scene 1352890919111 contains -1 edges. Removing these edges.\n",
      "Scene 1352890832737: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890832737 contains -1 edges. Removing these edges.\n",
      "Scene 135289080379: Filtering 1 nodes with NaN values.\n",
      "Scene 135289080379 contains -1 edges. Removing these edges.\n",
      "Scene 135289091722: Filtering 1 nodes with NaN values.\n",
      "Scene 135289091722 contains -1 edges. Removing these edges.\n",
      "Scene 1352890906673: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890906673 contains -1 edges. Removing these edges.\n",
      "Scene 1352890844758: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890844758 contains -1 edges. Removing these edges.\n",
      "NOTE! Scene 1352890844758 skipped: no valid nodes after filtering.\n",
      "Scene 1352890813256: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890813256 contains -1 edges. Removing these edges.\n",
      "Scene 1352890801209: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890801209 contains -1 edges. Removing these edges.\n",
      "Scene 1352890818793: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890818793 contains -1 edges. Removing these edges.\n",
      "Scene 13528908349910002: Filtering 1 nodes with NaN values.\n",
      "Scene 13528908349910002 contains -1 edges. Removing these edges.\n",
      "Scene 1352890812805: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890812805 contains -1 edges. Removing these edges.\n",
      "Scene 1352890833183 contains -1 edges. Removing these edges.\n",
      "Scene 1352890886909 contains -1 edges. Removing these edges.\n",
      "Scene 135289080254: Filtering 1 nodes with NaN values.\n",
      "Scene 135289080254 contains -1 edges. Removing these edges.\n",
      "Scene 1352890813937 contains -1 edges. Removing these edges.\n",
      "Scene 1352890831704 contains -1 edges. Removing these edges.\n",
      "Scene 1352890803131: Filtering 2 nodes with NaN values.\n",
      "Scene 1352890803131 contains -1 edges. Removing these edges.\n",
      "Scene 1352890806668: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890806668 contains -1 edges. Removing these edges.\n",
      "Scene 1352890805653: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890805653 contains -1 edges. Removing these edges.\n",
      "Scene 1352890805012: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890805012 contains -1 edges. Removing these edges.\n",
      "Scene 1352890878093 contains -1 edges. Removing these edges.\n",
      "Scene 1352890806119: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890806119 contains -1 edges. Removing these edges.\n",
      "Scene 1352890823766: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890823766 contains -1 edges. Removing these edges.\n",
      "Scene 135289081753 contains -1 edges. Removing these edges.\n",
      "Scene 1352890803042: Filtering 2 nodes with NaN values.\n",
      "Scene 1352890803042 contains -1 edges. Removing these edges.\n",
      "Scene 1352890821689 contains -1 edges. Removing these edges.\n",
      "Scene 1352890835826: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890835826 contains -1 edges. Removing these edges.\n",
      "Scene 1352890844845: Filtering 2 nodes with NaN values.\n",
      "Scene 1352890844845 contains -1 edges. Removing these edges.\n",
      "NOTE! Scene 1352890844845 skipped: no valid nodes after filtering.\n",
      "Scene 1352890834053 contains -1 edges. Removing these edges.\n",
      "Scene 135289091765 contains -1 edges. Removing these edges.\n",
      "Scene 1352890916071 contains -1 edges. Removing these edges.\n",
      "Scene 1352890820444 contains -1 edges. Removing these edges.\n",
      "Scene 1352890860907: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890860907 contains -1 edges. Removing these edges.\n",
      "Scene 1352890803972: Filtering 2 nodes with NaN values.\n",
      "Scene 1352890803972 contains -1 edges. Removing these edges.\n",
      "Scene 1352890819103: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890819103 contains -1 edges. Removing these edges.\n",
      "Scene 1352890810586 contains -1 edges. Removing these edges.\n",
      "Scene 1352890820576 contains -1 edges. Removing these edges.\n",
      "Scene 1352890915979 contains -1 edges. Removing these edges.\n",
      "Scene 1352890844712: Filtering 2 nodes with NaN values.\n",
      "Scene 1352890844712 contains -1 edges. Removing these edges.\n",
      "NOTE! Scene 1352890844712 skipped: no valid nodes after filtering.\n",
      "Scene 1352890838234: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890838234 contains -1 edges. Removing these edges.\n",
      "Scene 1352890829166: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890829166 contains -1 edges. Removing these edges.\n",
      "Scene 1352890845672: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890845672 contains -1 edges. Removing these edges.\n",
      "NOTE! Scene 1352890845672 skipped: no valid nodes after filtering.\n",
      "Scene 1352890842712: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890842712 contains -1 edges. Removing these edges.\n",
      "Scene 1352890832497: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890832497 contains -1 edges. Removing these edges.\n",
      "Scene 1352890843708: Filtering 2 nodes with NaN values.\n",
      "Scene 1352890843708 contains -1 edges. Removing these edges.\n",
      "Scene 13528908058: Filtering 1 nodes with NaN values.\n",
      "Scene 13528908058 contains -1 edges. Removing these edges.\n",
      "Scene 1352890839439 contains -1 edges. Removing these edges.\n",
      "Scene 13528908003660002: Filtering 1 nodes with NaN values.\n",
      "Scene 13528908003660002 contains -1 edges. Removing these edges.\n",
      "Scene 1352890824946 contains -1 edges. Removing these edges.\n",
      "Scene 1352890824516 contains -1 edges. Removing these edges.\n",
      "Scene 135289081098 contains -1 edges. Removing these edges.\n",
      "Scene 13528908292589998: Filtering 1 nodes with NaN values.\n",
      "Scene 13528908292589998 contains -1 edges. Removing these edges.\n",
      "Scene 1352890817934: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890817934 contains -1 edges. Removing these edges.\n",
      "Scene 1352890800907 contains -1 edges. Removing these edges.\n",
      "Scene 1352890815016: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890815016 contains -1 edges. Removing these edges.\n",
      "Scene 1352890834692 contains -1 edges. Removing these edges.\n",
      "Scene 1352890867565: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890867565 contains -1 edges. Removing these edges.\n",
      "Scene 1352890814839: Filtering 2 nodes with NaN values.\n",
      "Scene 1352890814839 contains -1 edges. Removing these edges.\n",
      "Scene 1352890916428: Filtering 2 nodes with NaN values.\n",
      "Scene 1352890916428 contains -1 edges. Removing these edges.\n",
      "Scene 1352890887794: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890887794 contains -1 edges. Removing these edges.\n",
      "Scene 1352890813762 contains -1 edges. Removing these edges.\n",
      "Scene 13528908331360002 contains -1 edges. Removing these edges.\n",
      "Scene 1352890807035: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890807035 contains -1 edges. Removing these edges.\n",
      "Scene 1352890807396: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890807396 contains -1 edges. Removing these edges.\n",
      "Scene 1352890806949: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890806949 contains -1 edges. Removing these edges.\n",
      "Scene 1352890801417: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890801417 contains -1 edges. Removing these edges.\n",
      "Scene 1352890809687: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890809687 contains -1 edges. Removing these edges.\n",
      "Scene 1352890820225 contains -1 edges. Removing these edges.\n",
      "Scene 135289080722: Filtering 1 nodes with NaN values.\n",
      "Scene 135289080722 contains -1 edges. Removing these edges.\n",
      "Scene 1352890891769: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890891769 contains -1 edges. Removing these edges.\n",
      "Scene 1352890832459: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890832459 contains -1 edges. Removing these edges.\n",
      "Scene 1352890894309: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890894309 contains -1 edges. Removing these edges.\n",
      "Scene 1352890837646 contains -1 edges. Removing these edges.\n",
      "Scene 1352890829843: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890829843 contains -1 edges. Removing these edges.\n",
      "Scene 1352890841153: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890841153 contains -1 edges. Removing these edges.\n",
      "Scene 1352890800768: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890800768 contains -1 edges. Removing these edges.\n",
      "Scene 1352890811843: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890811843 contains -1 edges. Removing these edges.\n",
      "Scene 1352890827838 contains -1 edges. Removing these edges.\n",
      "Scene 13528908329: Filtering 1 nodes with NaN values.\n",
      "Scene 13528908329 contains -1 edges. Removing these edges.\n",
      "Scene 1352890803659: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890803659 contains -1 edges. Removing these edges.\n",
      "Scene 135289083891 contains -1 edges. Removing these edges.\n",
      "Scene 1352890804018: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890804018 contains -1 edges. Removing these edges.\n",
      "Scene 1352890814167: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890814167 contains -1 edges. Removing these edges.\n",
      "Scene 1352890875117 contains -1 edges. Removing these edges.\n",
      "Scene 1352890836572 contains -1 edges. Removing these edges.\n",
      "Scene 1352890825035 contains -1 edges. Removing these edges.\n",
      "Scene 135289083596: Filtering 1 nodes with NaN values.\n",
      "Scene 135289083596 contains -1 edges. Removing these edges.\n",
      "Scene 13528908282510002 contains -1 edges. Removing these edges.\n",
      "Scene 1352890802778: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890802778 contains -1 edges. Removing these edges.\n",
      "Scene 1352890812416: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890812416 contains -1 edges. Removing these edges.\n",
      "Scene 135289083913 contains -1 edges. Removing these edges.\n",
      "Scene 1352890832378: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890832378 contains -1 edges. Removing these edges.\n",
      "Scene 1352890917968: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890917968 contains -1 edges. Removing these edges.\n",
      "Scene 13528908366160002 contains -1 edges. Removing these edges.\n",
      "Scene 1352890823862: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890823862 contains -1 edges. Removing these edges.\n",
      "Scene 1352890919792: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890919792 contains -1 edges. Removing these edges.\n",
      "Scene 1352890872601: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890872601 contains -1 edges. Removing these edges.\n",
      "Scene 1352890894888: Filtering 4 nodes with NaN values.\n",
      "Scene 1352890894888 contains -1 edges. Removing these edges.\n",
      "Scene 135289091426 contains -1 edges. Removing these edges.\n",
      "Scene 1352890919969: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890919969 contains -1 edges. Removing these edges.\n",
      "Scene 1352890835036: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890835036 contains -1 edges. Removing these edges.\n",
      "Scene 1352890809912: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890809912 contains -1 edges. Removing these edges.\n",
      "Scene 135289080146: Filtering 1 nodes with NaN values.\n",
      "Scene 135289080146 contains -1 edges. Removing these edges.\n",
      "Scene 1352890833505 contains -1 edges. Removing these edges.\n",
      "Scene 1352890895393: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890895393 contains -1 edges. Removing these edges.\n",
      "Scene 1352890838867: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890838867 contains -1 edges. Removing these edges.\n",
      "Scene 1352890833338 contains -1 edges. Removing these edges.\n",
      "Scene 1352890819768: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890819768 contains -1 edges. Removing these edges.\n",
      "Scene 1352890803216: Filtering 2 nodes with NaN values.\n",
      "Scene 1352890803216 contains -1 edges. Removing these edges.\n",
      "Scene 1352890808433 contains -1 edges. Removing these edges.\n",
      "Scene 1352890800052: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890800052 contains -1 edges. Removing these edges.\n",
      "Scene 1352890811475: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890811475 contains -1 edges. Removing these edges.\n",
      "Scene 1352890834655 contains -1 edges. Removing these edges.\n",
      "Scene 1352890814706: Filtering 2 nodes with NaN values.\n",
      "Scene 1352890814706 contains -1 edges. Removing these edges.\n",
      "Scene 1352890837601 contains -1 edges. Removing these edges.\n",
      "Scene 1352890808346 contains -1 edges. Removing these edges.\n",
      "Scene 1352890818385: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890818385 contains -1 edges. Removing these edges.\n",
      "Scene 1352890838146: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890838146 contains -1 edges. Removing these edges.\n",
      "Scene 1352890800142: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890800142 contains -1 edges. Removing these edges.\n",
      "Scene 1352890851846: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890851846 contains -1 edges. Removing these edges.\n",
      "Scene 1352890837115 contains -1 edges. Removing these edges.\n",
      "Scene 13528909148 contains -1 edges. Removing these edges.\n",
      "Scene 1352890908102: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890908102 contains -1 edges. Removing these edges.\n",
      "Scene 1352890841295 contains -1 edges. Removing these edges.\n",
      "Scene 1352890870132: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890870132 contains -1 edges. Removing these edges.\n",
      "Scene 1352890837204 contains -1 edges. Removing these edges.\n",
      "Scene 1352890802191 contains -1 edges. Removing these edges.\n",
      "Scene 1352890819948 contains -1 edges. Removing these edges.\n",
      "Scene 1352890824206 contains -1 edges. Removing these edges.\n",
      "Scene 135289081789: Filtering 1 nodes with NaN values.\n",
      "Scene 135289081789 contains -1 edges. Removing these edges.\n",
      "Scene 1352890910955: Filtering 1 nodes with NaN values.\n",
      "Scene 1352890910955 contains -1 edges. Removing these edges.\n",
      "Loaded 189 scenes.\n",
      "Train scenes: 132, Val scenes: 28, Test scenes: 29\n",
      "\n",
      "Running Task 1...\n",
      "\n",
      "Training...\n",
      "Epoch 1/100\n",
      "132/132 - 13s - 98ms/step - mean_absolute_error: 6374.2915 - mean_euclidean_distance: 9688.4766 - mean_squared_error: 94773064.0000 - r2_score: 0.2625 - rmse: 9735.1455 - loss: 69558224.0000 - val_loss: 66571124.0000 - learning_rate: 0.0100\n",
      "Epoch 2/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 1733.9709 - mean_euclidean_distance: 3065.8762 - mean_squared_error: 8360334.0000 - r2_score: 0.9186 - rmse: 2891.4243 - loss: 1027963.5625 - val_loss: 880937.8750 - learning_rate: 0.0100\n",
      "Epoch 3/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 1135.0613 - mean_euclidean_distance: 1965.0959 - mean_squared_error: 3255151.2500 - r2_score: 0.9533 - rmse: 1804.2037 - loss: 1290726.3750 - val_loss: 576461.0000 - learning_rate: 0.0100\n",
      "Epoch 4/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 930.5980 - mean_euclidean_distance: 1662.2742 - mean_squared_error: 2495778.7500 - r2_score: 0.9565 - rmse: 1579.8033 - loss: 2504541.7500 - val_loss: 948481.1875 - learning_rate: 0.0100\n",
      "Epoch 5/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 755.7582 - mean_euclidean_distance: 1361.5739 - mean_squared_error: 2245950.0000 - r2_score: 0.9612 - rmse: 1498.6494 - loss: 2009422.5000 - val_loss: 665521.6875 - learning_rate: 0.0100\n",
      "Epoch 6/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 1053.0579 - mean_euclidean_distance: 1797.0369 - mean_squared_error: 2053814.3750 - r2_score: 0.9622 - rmse: 1433.1135 - loss: 907396.5625 - val_loss: 1508263.3750 - learning_rate: 0.0100\n",
      "Epoch 7/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 1599.7745 - mean_euclidean_distance: 2418.2798 - mean_squared_error: 3420826.2500 - r2_score: 0.9387 - rmse: 1849.5476 - loss: 1405774.0000 - val_loss: 2758345.5000 - learning_rate: 0.0100\n",
      "Epoch 8/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 651.6114 - mean_euclidean_distance: 1137.0707 - mean_squared_error: 1438873.7500 - r2_score: 0.9841 - rmse: 1199.5306 - loss: 838109.2500 - val_loss: 332389.0625 - learning_rate: 0.0100\n",
      "Epoch 9/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 813.5784 - mean_euclidean_distance: 1337.0848 - mean_squared_error: 1149655.2500 - r2_score: 0.9821 - rmse: 1072.2197 - loss: 390960.8438 - val_loss: 191600.1562 - learning_rate: 0.0100\n",
      "Epoch 10/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 565.8863 - mean_euclidean_distance: 964.5408 - mean_squared_error: 871652.0625 - r2_score: 0.9851 - rmse: 933.6231 - loss: 247046.4062 - val_loss: 320337.8125 - learning_rate: 0.0100\n",
      "Epoch 11/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 724.8131 - mean_euclidean_distance: 1069.2449 - mean_squared_error: 691172.0625 - r2_score: 0.9912 - rmse: 831.3676 - loss: 501010.1250 - val_loss: 856567.5000 - learning_rate: 0.0100\n",
      "Epoch 12/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 659.4817 - mean_euclidean_distance: 1029.9994 - mean_squared_error: 687684.8125 - r2_score: 0.9930 - rmse: 829.2676 - loss: 568264.3750 - val_loss: 708907.1875 - learning_rate: 0.0100\n",
      "Epoch 13/100\n",
      "132/132 - 1s - 9ms/step - mean_absolute_error: 423.1180 - mean_euclidean_distance: 688.9606 - mean_squared_error: 355289.1250 - r2_score: 0.9963 - rmse: 596.0613 - loss: 796436.8125 - val_loss: 404979.6875 - learning_rate: 0.0100\n",
      "Epoch 14/100\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 608.5219 - mean_euclidean_distance: 964.3238 - mean_squared_error: 598189.2500 - r2_score: 0.9921 - rmse: 773.4269 - loss: 224151.6562 - val_loss: 190289.2188 - learning_rate: 0.0100\n",
      "Epoch 15/100\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 790.5148 - mean_euclidean_distance: 1277.1158 - mean_squared_error: 1060826.0000 - r2_score: 0.9838 - rmse: 1029.9641 - loss: 2966884.2500 - val_loss: 318530.4062 - learning_rate: 0.0100\n",
      "Epoch 16/100\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 528.0103 - mean_euclidean_distance: 808.7594 - mean_squared_error: 446361.7188 - r2_score: 0.9947 - rmse: 668.1031 - loss: 575031.2500 - val_loss: 676695.5625 - learning_rate: 0.0100\n",
      "Epoch 17/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 488.4239 - mean_euclidean_distance: 777.9507 - mean_squared_error: 423612.5938 - r2_score: 0.9943 - rmse: 650.8553 - loss: 409104.8750 - val_loss: 383744.5312 - learning_rate: 0.0100\n",
      "Epoch 18/100\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 601.5103 - mean_euclidean_distance: 1085.2008 - mean_squared_error: 1373221.3750 - r2_score: 0.9742 - rmse: 1171.8453 - loss: 222249.5000 - val_loss: 187382.4062 - learning_rate: 0.0100\n",
      "Epoch 19/100\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 500.2684 - mean_euclidean_distance: 844.7529 - mean_squared_error: 509451.2500 - r2_score: 0.9933 - rmse: 713.7585 - loss: 623185.4375 - val_loss: 252598.5938 - learning_rate: 0.0100\n",
      "Epoch 20/100\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 438.1432 - mean_euclidean_distance: 741.3563 - mean_squared_error: 375473.7812 - r2_score: 0.9959 - rmse: 612.7592 - loss: 1467865.3750 - val_loss: 315848.0000 - learning_rate: 0.0100\n",
      "Epoch 21/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 545.9276 - mean_euclidean_distance: 825.7350 - mean_squared_error: 418965.2500 - r2_score: 0.9953 - rmse: 647.2753 - loss: 733126.0625 - val_loss: 664562.3750 - learning_rate: 0.0100\n",
      "Epoch 22/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 504.3974 - mean_euclidean_distance: 812.3172 - mean_squared_error: 477984.9375 - r2_score: 0.9940 - rmse: 691.3646 - loss: 1123398.8750 - val_loss: 224310.5469 - learning_rate: 0.0100\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "132/132 - 2s - 11ms/step - mean_absolute_error: 415.4345 - mean_euclidean_distance: 697.1437 - mean_squared_error: 319807.2188 - r2_score: 0.9964 - rmse: 565.5150 - loss: 614583.8125 - val_loss: 343446.7812 - learning_rate: 0.0100\n",
      "Epoch 24/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 403.6876 - mean_euclidean_distance: 641.4714 - mean_squared_error: 287116.2812 - r2_score: 0.9966 - rmse: 535.8323 - loss: 528685.2500 - val_loss: 407806.0938 - learning_rate: 1.0000e-03\n",
      "Epoch 25/100\n",
      "132/132 - 2s - 11ms/step - mean_absolute_error: 390.5469 - mean_euclidean_distance: 616.6520 - mean_squared_error: 276334.9688 - r2_score: 0.9968 - rmse: 525.6757 - loss: 363371.6250 - val_loss: 323518.5000 - learning_rate: 1.0000e-03\n",
      "Epoch 26/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 386.5827 - mean_euclidean_distance: 618.0506 - mean_squared_error: 277995.5000 - r2_score: 0.9968 - rmse: 527.2528 - loss: 177504.8125 - val_loss: 300301.8438 - learning_rate: 1.0000e-03\n",
      "Epoch 27/100\n",
      "132/132 - 2s - 13ms/step - mean_absolute_error: 390.4597 - mean_euclidean_distance: 613.6844 - mean_squared_error: 266213.6250 - r2_score: 0.9969 - rmse: 515.9589 - loss: 448964.3125 - val_loss: 337564.5625 - learning_rate: 1.0000e-03\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "132/132 - 2s - 12ms/step - mean_absolute_error: 430.2431 - mean_euclidean_distance: 663.3880 - mean_squared_error: 297249.8750 - r2_score: 0.9966 - rmse: 545.2062 - loss: 190635.3125 - val_loss: 444317.7500 - learning_rate: 1.0000e-03\n",
      "Epoch 29/100\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 378.8480 - mean_euclidean_distance: 601.9716 - mean_squared_error: 259528.8594 - r2_score: 0.9970 - rmse: 509.4398 - loss: 351720.6562 - val_loss: 318247.4688 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 380.3326 - mean_euclidean_distance: 602.9157 - mean_squared_error: 259249.1094 - r2_score: 0.9970 - rmse: 509.1651 - loss: 377014.4375 - val_loss: 328967.5625 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 378.7899 - mean_euclidean_distance: 603.2443 - mean_squared_error: 261433.9062 - r2_score: 0.9969 - rmse: 511.3061 - loss: 639296.3750 - val_loss: 293597.3125 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 379.4701 - mean_euclidean_distance: 602.0787 - mean_squared_error: 258838.7188 - r2_score: 0.9970 - rmse: 508.7619 - loss: 218639.9375 - val_loss: 326575.6562 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 377.6571 - mean_euclidean_distance: 600.8944 - mean_squared_error: 258193.3438 - r2_score: 0.9970 - rmse: 508.1273 - loss: 174570.4531 - val_loss: 325295.1562 - learning_rate: 1.0000e-04\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "Evaluating on test dataset...\n",
      "29/29 - 0s - 5ms/step - mean_absolute_error: 611.3483 - mean_euclidean_distance: 1083.4464 - mean_squared_error: 1700643.0000 - r2_score: 0.9691 - rmse: 1304.0870 - loss: 207961.7969\n",
      "Test metrics: [<tf.Tensor: shape=(), dtype=float32, numpy=207961.796875>, {'mean_absolute_error': <tf.Tensor: shape=(), dtype=float32, numpy=611.3483276367188>, 'mean_squared_error': <tf.Tensor: shape=(), dtype=float32, numpy=1700643.0>, 'rmse': <tf.Tensor: shape=(), dtype=float32, numpy=1304.0870361328125>, 'r2_score': <tf.Tensor: shape=(), dtype=float32, numpy=0.969131588935852>, 'mean_euclidean_distance': <tf.Tensor: shape=(), dtype=float32, numpy=1083.4464111328125>}]\n",
      "\n",
      "Sample predictions for test scenes:\n",
      "Node 0: True future_x=40149.0, future_y=-16841.0 | Predicted future_x=41410.8, future_y=-17406.6\n",
      "Node 1: True future_x=36150.0, future_y=-21965.0 | Predicted future_x=37030.1, future_y=-23207.5\n",
      "Node 2: True future_x=42131.0, future_y=-21564.0 | Predicted future_x=42482.7, future_y=-21733.5\n",
      "Node 3: True future_x=42021.0, future_y=-23271.0 | Predicted future_x=42250.1, future_y=-23308.2\n",
      "Node 4: True future_x=42498.0, future_y=-21046.0 | Predicted future_x=42938.1, future_y=-21240.7\n",
      "\n",
      "Running Task 2...\n",
      "\n",
      "\n",
      "Run: 1\n",
      "Heads: 2\n",
      "\n",
      "Training...\n",
      "Epoch 1/100\n",
      "132/132 - 4s - 33ms/step - mean_absolute_error: 4075.6611 - mean_euclidean_distance: 7124.8452 - mean_squared_error: 31973714.0000 - r2_score: 0.7437 - rmse: 5654.5303 - loss: 18711218.0000 - val_loss: 9241717.0000 - learning_rate: 0.0100\n",
      "Epoch 2/100\n",
      "132/132 - 1s - 5ms/step - mean_absolute_error: 1398.3895 - mean_euclidean_distance: 2680.1704 - mean_squared_error: 10074395.0000 - r2_score: 0.9230 - rmse: 3174.0188 - loss: 2437621.2500 - val_loss: 1327755.2500 - learning_rate: 0.0100\n",
      "Epoch 3/100\n",
      "132/132 - 1s - 5ms/step - mean_absolute_error: 1005.9688 - mean_euclidean_distance: 2098.2336 - mean_squared_error: 9314959.0000 - r2_score: 0.9361 - rmse: 3052.0417 - loss: 348403.8125 - val_loss: 810319.1250 - learning_rate: 0.0100\n",
      "Epoch 4/100\n",
      "132/132 - 1s - 5ms/step - mean_absolute_error: 4947.0601 - mean_euclidean_distance: 7320.5112 - mean_squared_error: 30984190.0000 - r2_score: 0.6188 - rmse: 5566.3442 - loss: 38839744.0000 - val_loss: 14724899.0000 - learning_rate: 0.0100\n",
      "Epoch 5/100\n",
      "132/132 - 1s - 5ms/step - mean_absolute_error: 1526.4379 - mean_euclidean_distance: 2672.7542 - mean_squared_error: 7152095.0000 - r2_score: 0.9098 - rmse: 2674.3401 - loss: 329747.8125 - val_loss: 1402284.0000 - learning_rate: 0.0100\n",
      "Epoch 6/100\n",
      "132/132 - 1s - 5ms/step - mean_absolute_error: 5348.8740 - mean_euclidean_distance: 9266.6338 - mean_squared_error: 50094316.0000 - r2_score: 0.6378 - rmse: 7077.7339 - loss: 49843396.0000 - val_loss: 13018698.0000 - learning_rate: 0.0100\n",
      "Epoch 7/100\n",
      "132/132 - 1s - 5ms/step - mean_absolute_error: 1687.2318 - mean_euclidean_distance: 3182.2922 - mean_squared_error: 11375026.0000 - r2_score: 0.8943 - rmse: 3372.6882 - loss: 3448198.5000 - val_loss: 2351790.2500 - learning_rate: 0.0100\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "132/132 - 1s - 5ms/step - mean_absolute_error: 1686.8160 - mean_euclidean_distance: 3094.9177 - mean_squared_error: 10924154.0000 - r2_score: 0.9117 - rmse: 3305.1709 - loss: 3276107.5000 - val_loss: 2134691.7500 - learning_rate: 0.0100\n",
      "Epoch 9/100\n",
      "132/132 - 1s - 5ms/step - mean_absolute_error: 1406.4945 - mean_euclidean_distance: 2601.4021 - mean_squared_error: 8124318.0000 - r2_score: 0.9289 - rmse: 2850.3188 - loss: 2373877.0000 - val_loss: 1502028.5000 - learning_rate: 1.0000e-03\n",
      "Epoch 10/100\n",
      "132/132 - 1s - 5ms/step - mean_absolute_error: 1261.6810 - mean_euclidean_distance: 2263.9976 - mean_squared_error: 5866206.0000 - r2_score: 0.9325 - rmse: 2422.0251 - loss: 6053628.0000 - val_loss: 1146645.5000 - learning_rate: 1.0000e-03\n",
      "Epoch 11/100\n",
      "132/132 - 1s - 5ms/step - mean_absolute_error: 1159.1379 - mean_euclidean_distance: 2060.3806 - mean_squared_error: 4516238.0000 - r2_score: 0.9480 - rmse: 2125.1443 - loss: 1676687.2500 - val_loss: 1260487.2500 - learning_rate: 1.0000e-03\n",
      "Epoch 12/100\n",
      "132/132 - 1s - 5ms/step - mean_absolute_error: 1091.7518 - mean_euclidean_distance: 1964.3156 - mean_squared_error: 3893092.7500 - r2_score: 0.9510 - rmse: 1973.0922 - loss: 1890607.6250 - val_loss: 1213007.0000 - learning_rate: 1.0000e-03\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "132/132 - 1s - 5ms/step - mean_absolute_error: 1146.7898 - mean_euclidean_distance: 1876.2812 - mean_squared_error: 3190078.0000 - r2_score: 0.9571 - rmse: 1786.0790 - loss: 3508899.2500 - val_loss: 1387534.6250 - learning_rate: 1.0000e-03\n",
      "Epoch 14/100\n",
      "132/132 - 1s - 5ms/step - mean_absolute_error: 1028.7340 - mean_euclidean_distance: 1793.5458 - mean_squared_error: 3153893.7500 - r2_score: 0.9561 - rmse: 1775.9205 - loss: 537723.8750 - val_loss: 1198751.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "132/132 - 1s - 5ms/step - mean_absolute_error: 1004.8401 - mean_euclidean_distance: 1779.2382 - mean_squared_error: 3196265.2500 - r2_score: 0.9563 - rmse: 1787.8102 - loss: 441431.6875 - val_loss: 1065116.2500 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "132/132 - 1s - 5ms/step - mean_absolute_error: 1004.1063 - mean_euclidean_distance: 1788.9156 - mean_squared_error: 3282367.0000 - r2_score: 0.9551 - rmse: 1811.7303 - loss: 21908846.0000 - val_loss: 1025730.8750 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "132/132 - 1s - 5ms/step - mean_absolute_error: 1020.2562 - mean_euclidean_distance: 1794.0986 - mean_squared_error: 3251027.2500 - r2_score: 0.9557 - rmse: 1803.0605 - loss: 1151057.7500 - val_loss: 1139140.8750 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "132/132 - 1s - 5ms/step - mean_absolute_error: 981.7832 - mean_euclidean_distance: 1773.3459 - mean_squared_error: 3308852.7500 - r2_score: 0.9535 - rmse: 1819.0253 - loss: 379019.5625 - val_loss: 868658.1875 - learning_rate: 1.0000e-04\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Evaluating on test dataset...\n",
      "29/29 - 0s - 4ms/step - mean_absolute_error: 963.8895 - mean_euclidean_distance: 1811.4519 - mean_squared_error: 8974012.0000 - r2_score: 0.9480 - rmse: 2995.6655 - loss: 403046.1250\n",
      "Test metrics: [<tf.Tensor: shape=(), dtype=float32, numpy=403046.125>, {'mean_absolute_error': <tf.Tensor: shape=(), dtype=float32, numpy=963.8895263671875>, 'mean_squared_error': <tf.Tensor: shape=(), dtype=float32, numpy=8974012.0>, 'rmse': <tf.Tensor: shape=(), dtype=float32, numpy=2995.66552734375>, 'r2_score': <tf.Tensor: shape=(), dtype=float32, numpy=0.9480302333831787>, 'mean_euclidean_distance': <tf.Tensor: shape=(), dtype=float32, numpy=1811.451904296875>}]\n",
      "\n",
      "Sample predictions for test scenes:\n",
      "Node 0: True future_x=40149.0, future_y=-16841.0 | Predicted future_x=40027.5, future_y=-16830.8\n",
      "Node 1: True future_x=36150.0, future_y=-21965.0 | Predicted future_x=35903.1, future_y=-22699.7\n",
      "Node 2: True future_x=42131.0, future_y=-21564.0 | Predicted future_x=41971.7, future_y=-21066.5\n",
      "Node 3: True future_x=42021.0, future_y=-23271.0 | Predicted future_x=41542.5, future_y=-22702.5\n",
      "Node 4: True future_x=42498.0, future_y=-21046.0 | Predicted future_x=41803.9, future_y=-20885.5\n",
      "\n",
      "Run: 2\n",
      "Heads: 4\n",
      "\n",
      "Training...\n",
      "Epoch 1/100\n",
      "132/132 - 7s - 55ms/step - mean_absolute_error: 14094.0938 - mean_euclidean_distance: 25998.7246 - mean_squared_error: 3077573376.0000 - r2_score: -4.4017e+01 - rmse: 55475.8828 - loss: 246053168.0000 - val_loss: 32376444.0000 - learning_rate: 0.0100\n",
      "Epoch 2/100\n",
      "132/132 - 1s - 7ms/step - mean_absolute_error: 1682.2140 - mean_euclidean_distance: 3313.9324 - mean_squared_error: 15292234.0000 - r2_score: 0.8952 - rmse: 3910.5286 - loss: 2145444.7500 - val_loss: 1750983.0000 - learning_rate: 0.0100\n",
      "Epoch 3/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 1712.7340 - mean_euclidean_distance: 3161.1738 - mean_squared_error: 13223237.0000 - r2_score: 0.9043 - rmse: 3636.3770 - loss: 7005607.5000 - val_loss: 1174109.1250 - learning_rate: 0.0100\n",
      "Epoch 4/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 1500.9320 - mean_euclidean_distance: 2859.1633 - mean_squared_error: 12013110.0000 - r2_score: 0.9107 - rmse: 3465.9934 - loss: 2229841.0000 - val_loss: 1585082.0000 - learning_rate: 0.0100\n",
      "Epoch 5/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 1261.9741 - mean_euclidean_distance: 2531.2878 - mean_squared_error: 11446798.0000 - r2_score: 0.9165 - rmse: 3383.3118 - loss: 939164.4375 - val_loss: 1076544.2500 - learning_rate: 0.0100\n",
      "Epoch 6/100\n",
      "132/132 - 1s - 7ms/step - mean_absolute_error: 1059.1766 - mean_euclidean_distance: 2222.1824 - mean_squared_error: 10898573.0000 - r2_score: 0.9234 - rmse: 3301.2986 - loss: 541939.0625 - val_loss: 586206.8750 - learning_rate: 0.0100\n",
      "Epoch 7/100\n",
      "132/132 - 1s - 7ms/step - mean_absolute_error: 1534.9856 - mean_euclidean_distance: 2871.1548 - mean_squared_error: 11841491.0000 - r2_score: 0.9158 - rmse: 3441.1467 - loss: 1224038.2500 - val_loss: 1657036.7500 - learning_rate: 0.0100\n",
      "Epoch 8/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 1017.1666 - mean_euclidean_distance: 2136.8601 - mean_squared_error: 10825494.0000 - r2_score: 0.9248 - rmse: 3290.2119 - loss: 117100872.0000 - val_loss: 311717.6875 - learning_rate: 0.0100\n",
      "Epoch 9/100\n",
      "132/132 - 1s - 7ms/step - mean_absolute_error: 2390.8555 - mean_euclidean_distance: 4287.7007 - mean_squared_error: 15917945.0000 - r2_score: 0.8901 - rmse: 3989.7300 - loss: 2496391.5000 - val_loss: 2802528.0000 - learning_rate: 0.0100\n",
      "Epoch 10/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 1043.9161 - mean_euclidean_distance: 2195.0774 - mean_squared_error: 11110550.0000 - r2_score: 0.9235 - rmse: 3333.2493 - loss: 748683.3750 - val_loss: 737207.8750 - learning_rate: 0.0100\n",
      "Epoch 11/100\n",
      "132/132 - 1s - 7ms/step - mean_absolute_error: 996.6104 - mean_euclidean_distance: 2089.1453 - mean_squared_error: 10913967.0000 - r2_score: 0.9246 - rmse: 3303.6294 - loss: 518915.3125 - val_loss: 659622.3750 - learning_rate: 0.0100\n",
      "Epoch 12/100\n",
      "132/132 - 1s - 7ms/step - mean_absolute_error: 1432.6316 - mean_euclidean_distance: 2815.8752 - mean_squared_error: 11939390.0000 - r2_score: 0.9195 - rmse: 3455.3423 - loss: 5253582.0000 - val_loss: 1245941.2500 - learning_rate: 0.0100\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "132/132 - 1s - 7ms/step - mean_absolute_error: 1027.3171 - mean_euclidean_distance: 2115.3840 - mean_squared_error: 10955963.0000 - r2_score: 0.9248 - rmse: 3309.9792 - loss: 277951.0000 - val_loss: 616324.0000 - learning_rate: 0.0100\n",
      "Epoch 14/100\n",
      "132/132 - 1s - 7ms/step - mean_absolute_error: 920.4229 - mean_euclidean_distance: 1963.9755 - mean_squared_error: 10827728.0000 - r2_score: 0.9259 - rmse: 3290.5513 - loss: 757201.1875 - val_loss: 523969.8438 - learning_rate: 1.0000e-03\n",
      "Epoch 15/100\n",
      "132/132 - 1s - 7ms/step - mean_absolute_error: 911.6934 - mean_euclidean_distance: 1968.1493 - mean_squared_error: 10822838.0000 - r2_score: 0.9259 - rmse: 3289.8081 - loss: 856010.1875 - val_loss: 432188.1875 - learning_rate: 1.0000e-03\n",
      "Epoch 16/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 907.6263 - mean_euclidean_distance: 1962.7678 - mean_squared_error: 10818714.0000 - r2_score: 0.9259 - rmse: 3289.1814 - loss: 1171303.8750 - val_loss: 443694.1875 - learning_rate: 1.0000e-03\n",
      "Epoch 17/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 895.6636 - mean_euclidean_distance: 1932.5809 - mean_squared_error: 10798757.0000 - r2_score: 0.9260 - rmse: 3286.1462 - loss: 700739.6875 - val_loss: 457213.8125 - learning_rate: 1.0000e-03\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 903.6254 - mean_euclidean_distance: 1945.0956 - mean_squared_error: 10797495.0000 - r2_score: 0.9259 - rmse: 3285.9541 - loss: 263258.3438 - val_loss: 397276.4062 - learning_rate: 1.0000e-03\n",
      "Epoch 19/100\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 894.0948 - mean_euclidean_distance: 1931.4348 - mean_squared_error: 10790157.0000 - r2_score: 0.9261 - rmse: 3284.8374 - loss: 159622.5938 - val_loss: 433904.6562 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "132/132 - 1s - 7ms/step - mean_absolute_error: 892.8626 - mean_euclidean_distance: 1928.3572 - mean_squared_error: 10788336.0000 - r2_score: 0.9261 - rmse: 3284.5603 - loss: 167340.5312 - val_loss: 449783.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "132/132 - 1s - 7ms/step - mean_absolute_error: 893.7538 - mean_euclidean_distance: 1930.0450 - mean_squared_error: 10788154.0000 - r2_score: 0.9261 - rmse: 3284.5325 - loss: 226411.5938 - val_loss: 431155.3125 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "132/132 - 1s - 7ms/step - mean_absolute_error: 893.4985 - mean_euclidean_distance: 1927.5129 - mean_squared_error: 10786703.0000 - r2_score: 0.9261 - rmse: 3284.3118 - loss: 697661.5000 - val_loss: 453960.5000 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "132/132 - 1s - 8ms/step - mean_absolute_error: 894.5505 - mean_euclidean_distance: 1933.7773 - mean_squared_error: 10788231.0000 - r2_score: 0.9261 - rmse: 3284.5442 - loss: 819652.0000 - val_loss: 429632.9062 - learning_rate: 1.0000e-04\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Evaluating on test dataset...\n",
      "29/29 - 0s - 5ms/step - mean_absolute_error: 1093.4075 - mean_euclidean_distance: 2041.7489 - mean_squared_error: 17372638.0000 - r2_score: 0.8900 - rmse: 4168.0498 - loss: 226361.7344\n",
      "Test metrics: [<tf.Tensor: shape=(), dtype=float32, numpy=226361.734375>, {'mean_absolute_error': <tf.Tensor: shape=(), dtype=float32, numpy=1093.407470703125>, 'mean_squared_error': <tf.Tensor: shape=(), dtype=float32, numpy=17372638.0>, 'rmse': <tf.Tensor: shape=(), dtype=float32, numpy=4168.0498046875>, 'r2_score': <tf.Tensor: shape=(), dtype=float32, numpy=0.8900465965270996>, 'mean_euclidean_distance': <tf.Tensor: shape=(), dtype=float32, numpy=2041.7489013671875>}]\n",
      "\n",
      "Sample predictions for test scenes:\n",
      "Node 0: True future_x=40149.0, future_y=-16841.0 | Predicted future_x=41061.8, future_y=-18401.2\n",
      "Node 1: True future_x=36150.0, future_y=-21965.0 | Predicted future_x=36782.4, future_y=-23289.2\n",
      "Node 2: True future_x=42131.0, future_y=-21564.0 | Predicted future_x=42963.1, future_y=-21640.1\n",
      "Node 3: True future_x=42021.0, future_y=-23271.0 | Predicted future_x=42425.1, future_y=-23262.5\n",
      "Node 4: True future_x=42498.0, future_y=-21046.0 | Predicted future_x=43400.8, future_y=-21525.2\n",
      "\n",
      "Run: 3\n",
      "Heads: 6\n",
      "\n",
      "Training...\n",
      "Epoch 1/100\n",
      "132/132 - 10s - 79ms/step - mean_absolute_error: 15932.0508 - mean_euclidean_distance: 25287.0039 - mean_squared_error: 385001440.0000 - r2_score: -3.6892e+00 - rmse: 19621.4531 - loss: 7529582592.0000 - val_loss: 145624608.0000 - learning_rate: 0.0100\n",
      "Epoch 2/100\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 2341.9465 - mean_euclidean_distance: 3933.2595 - mean_squared_error: 16080209.0000 - r2_score: 0.8551 - rmse: 4010.0137 - loss: 8864032.0000 - val_loss: 3978765.2500 - learning_rate: 0.0100\n",
      "Epoch 3/100\n",
      "132/132 - 2s - 13ms/step - mean_absolute_error: 1372.9729 - mean_euclidean_distance: 2223.7158 - mean_squared_error: 6066109.0000 - r2_score: 0.9314 - rmse: 2462.9473 - loss: 6604436.0000 - val_loss: 1102866.6250 - learning_rate: 0.0100\n",
      "Epoch 4/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 1234.8096 - mean_euclidean_distance: 1996.8898 - mean_squared_error: 4954814.5000 - r2_score: 0.9475 - rmse: 2225.9412 - loss: 10127382.0000 - val_loss: 1009940.8125 - learning_rate: 0.0100\n",
      "Epoch 5/100\n",
      "132/132 - 2s - 14ms/step - mean_absolute_error: 1588.3528 - mean_euclidean_distance: 2553.9595 - mean_squared_error: 10412990.0000 - r2_score: 0.9073 - rmse: 3226.9165 - loss: 1170221.5000 - val_loss: 979338.3125 - learning_rate: 0.0100\n",
      "Epoch 6/100\n",
      "132/132 - 2s - 12ms/step - mean_absolute_error: 1352.6079 - mean_euclidean_distance: 2193.4417 - mean_squared_error: 7660883.0000 - r2_score: 0.9336 - rmse: 2767.8301 - loss: 1154715.3750 - val_loss: 951569.3750 - learning_rate: 0.0100\n",
      "Epoch 7/100\n",
      "132/132 - 2s - 11ms/step - mean_absolute_error: 1669.9025 - mean_euclidean_distance: 2648.4797 - mean_squared_error: 10980833.0000 - r2_score: 0.9075 - rmse: 3313.7339 - loss: 8386294.5000 - val_loss: 1146116.3750 - learning_rate: 0.0100\n",
      "Epoch 8/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 1421.5051 - mean_euclidean_distance: 2410.8652 - mean_squared_error: 10452968.0000 - r2_score: 0.9208 - rmse: 3233.1050 - loss: 1292301.7500 - val_loss: 1401684.5000 - learning_rate: 0.0100\n",
      "Epoch 9/100\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 1164.9291 - mean_euclidean_distance: 1981.2654 - mean_squared_error: 4334736.0000 - r2_score: 0.9480 - rmse: 2082.0029 - loss: 706883.6250 - val_loss: 596799.0000 - learning_rate: 0.0100\n",
      "Epoch 10/100\n",
      "132/132 - 2s - 12ms/step - mean_absolute_error: 2190.8999 - mean_euclidean_distance: 3422.9709 - mean_squared_error: 14947484.0000 - r2_score: 0.8740 - rmse: 3866.1975 - loss: 27245488.0000 - val_loss: 4771701.0000 - learning_rate: 0.0100\n",
      "Epoch 11/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 1380.0844 - mean_euclidean_distance: 2175.9863 - mean_squared_error: 4777402.0000 - r2_score: 0.9506 - rmse: 2185.7268 - loss: 1164896.5000 - val_loss: 1162995.3750 - learning_rate: 0.0100\n",
      "Epoch 12/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 1795.3961 - mean_euclidean_distance: 2927.5496 - mean_squared_error: 7429403.0000 - r2_score: 0.8712 - rmse: 2725.6931 - loss: 2370544.2500 - val_loss: 1462556.7500 - learning_rate: 0.0100\n",
      "Epoch 13/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 3525.0850 - mean_euclidean_distance: 6154.8403 - mean_squared_error: 23941214.0000 - r2_score: 0.5256 - rmse: 4892.9761 - loss: 3960852.5000 - val_loss: 12734175.0000 - learning_rate: 0.0100\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 1442.3096 - mean_euclidean_distance: 2550.9438 - mean_squared_error: 5741426.5000 - r2_score: 0.9265 - rmse: 2396.1274 - loss: 1695035.5000 - val_loss: 1938600.3750 - learning_rate: 0.0100\n",
      "Epoch 15/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 1005.0812 - mean_euclidean_distance: 1740.6143 - mean_squared_error: 3089149.2500 - r2_score: 0.9617 - rmse: 1757.5975 - loss: 2450893.0000 - val_loss: 1020229.3125 - learning_rate: 1.0000e-03\n",
      "Epoch 16/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 910.2905 - mean_euclidean_distance: 1620.4237 - mean_squared_error: 2660083.7500 - r2_score: 0.9676 - rmse: 1630.9763 - loss: 1189944.1250 - val_loss: 1043758.5000 - learning_rate: 1.0000e-03\n",
      "Epoch 17/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 864.4257 - mean_euclidean_distance: 1505.4882 - mean_squared_error: 2173600.5000 - r2_score: 0.9711 - rmse: 1474.3136 - loss: 818203.9375 - val_loss: 913809.6250 - learning_rate: 1.0000e-03\n",
      "Epoch 18/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 861.2846 - mean_euclidean_distance: 1465.5116 - mean_squared_error: 1996891.5000 - r2_score: 0.9735 - rmse: 1413.1141 - loss: 822278.8750 - val_loss: 961117.6250 - learning_rate: 1.0000e-03\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "132/132 - 2s - 11ms/step - mean_absolute_error: 859.6063 - mean_euclidean_distance: 1447.5359 - mean_squared_error: 1904577.6250 - r2_score: 0.9745 - rmse: 1380.0643 - loss: 2286922.0000 - val_loss: 926837.8125 - learning_rate: 1.0000e-03\n",
      "Epoch 20/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 838.7653 - mean_euclidean_distance: 1436.4763 - mean_squared_error: 1928552.6250 - r2_score: 0.9745 - rmse: 1388.7234 - loss: 2022704.6250 - val_loss: 946471.6250 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 841.2361 - mean_euclidean_distance: 1432.0040 - mean_squared_error: 1904538.3750 - r2_score: 0.9747 - rmse: 1380.0502 - loss: 862088.2500 - val_loss: 924165.6250 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 840.7180 - mean_euclidean_distance: 1439.9567 - mean_squared_error: 1914820.1250 - r2_score: 0.9746 - rmse: 1383.7703 - loss: 1429264.5000 - val_loss: 993371.3750 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 843.3226 - mean_euclidean_distance: 1436.8145 - mean_squared_error: 1896456.2500 - r2_score: 0.9748 - rmse: 1377.1188 - loss: 925681.0000 - val_loss: 992246.8125 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 840.5751 - mean_euclidean_distance: 1427.8942 - mean_squared_error: 1886701.5000 - r2_score: 0.9750 - rmse: 1373.5725 - loss: 2000691.5000 - val_loss: 943163.6250 - learning_rate: 1.0000e-04\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Evaluating on test dataset...\n",
      "29/29 - 0s - 5ms/step - mean_absolute_error: 1395.0247 - mean_euclidean_distance: 2305.0996 - mean_squared_error: 17110882.0000 - r2_score: 0.8790 - rmse: 4136.5303 - loss: 1073675.8750\n",
      "Test metrics: [<tf.Tensor: shape=(), dtype=float32, numpy=1073675.875>, {'mean_absolute_error': <tf.Tensor: shape=(), dtype=float32, numpy=1395.024658203125>, 'mean_squared_error': <tf.Tensor: shape=(), dtype=float32, numpy=17110882.0>, 'rmse': <tf.Tensor: shape=(), dtype=float32, numpy=4136.5302734375>, 'r2_score': <tf.Tensor: shape=(), dtype=float32, numpy=0.878998875617981>, 'mean_euclidean_distance': <tf.Tensor: shape=(), dtype=float32, numpy=2305.099609375>}]\n",
      "\n",
      "Sample predictions for test scenes:\n",
      "Node 0: True future_x=40149.0, future_y=-16841.0 | Predicted future_x=40839.9, future_y=-21138.2\n",
      "Node 1: True future_x=36150.0, future_y=-21965.0 | Predicted future_x=37115.3, future_y=-23165.8\n",
      "Node 2: True future_x=42131.0, future_y=-21564.0 | Predicted future_x=40836.3, future_y=-24568.3\n",
      "Node 3: True future_x=42021.0, future_y=-23271.0 | Predicted future_x=41630.5, future_y=-24583.6\n",
      "Node 4: True future_x=42498.0, future_y=-21046.0 | Predicted future_x=41474.4, future_y=-23824.1\n",
      "\n",
      "Run: 4\n",
      "Heads: 8\n",
      "\n",
      "Training...\n",
      "Epoch 1/100\n",
      "132/132 - 15s - 117ms/step - mean_absolute_error: 12492.3711 - mean_euclidean_distance: 21924.3535 - mean_squared_error: 442594272.0000 - r2_score: -7.4182e+00 - rmse: 21037.9238 - loss: 46880812.0000 - val_loss: 178303072.0000 - learning_rate: 0.0100\n",
      "Epoch 2/100\n",
      "132/132 - 3s - 20ms/step - mean_absolute_error: 3927.7551 - mean_euclidean_distance: 7156.2183 - mean_squared_error: 80586704.0000 - r2_score: -2.8388e-01 - rmse: 8977.0098 - loss: 143186032.0000 - val_loss: 25556836.0000 - learning_rate: 0.0100\n",
      "Epoch 3/100\n",
      "132/132 - 2s - 17ms/step - mean_absolute_error: 2525.6482 - mean_euclidean_distance: 4605.9736 - mean_squared_error: 39803164.0000 - r2_score: 0.4564 - rmse: 6308.9751 - loss: 366191360.0000 - val_loss: 6660029.0000 - learning_rate: 0.0100\n",
      "Epoch 4/100\n",
      "132/132 - 2s - 18ms/step - mean_absolute_error: 2243.2378 - mean_euclidean_distance: 3989.8352 - mean_squared_error: 22684388.0000 - r2_score: 0.6650 - rmse: 4762.8130 - loss: 33221500.0000 - val_loss: 3336529.5000 - learning_rate: 0.0100\n",
      "Epoch 5/100\n",
      "132/132 - 2s - 17ms/step - mean_absolute_error: 1849.3594 - mean_euclidean_distance: 3254.6624 - mean_squared_error: 12638290.0000 - r2_score: 0.8186 - rmse: 3555.0374 - loss: 1973529.7500 - val_loss: 2789519.5000 - learning_rate: 0.0100\n",
      "Epoch 6/100\n",
      "132/132 - 3s - 19ms/step - mean_absolute_error: 1544.8167 - mean_euclidean_distance: 2621.9790 - mean_squared_error: 7038056.0000 - r2_score: 0.9004 - rmse: 2652.9333 - loss: 1377424.5000 - val_loss: 2048640.6250 - learning_rate: 0.0100\n",
      "Epoch 7/100\n",
      "132/132 - 2s - 16ms/step - mean_absolute_error: 1466.1211 - mean_euclidean_distance: 2478.6245 - mean_squared_error: 5903180.5000 - r2_score: 0.9112 - rmse: 2429.6462 - loss: 1853680.7500 - val_loss: 1735256.3750 - learning_rate: 0.0100\n",
      "Epoch 8/100\n",
      "132/132 - 2s - 15ms/step - mean_absolute_error: 1509.4795 - mean_euclidean_distance: 2414.7820 - mean_squared_error: 4850459.0000 - r2_score: 0.9264 - rmse: 2202.3757 - loss: 3078796.5000 - val_loss: 1274984.2500 - learning_rate: 0.0100\n",
      "Epoch 9/100\n",
      "132/132 - 2s - 15ms/step - mean_absolute_error: 1369.2515 - mean_euclidean_distance: 2259.1897 - mean_squared_error: 4166821.5000 - r2_score: 0.9339 - rmse: 2041.2794 - loss: 819518.6250 - val_loss: 1190305.3750 - learning_rate: 0.0100\n",
      "Epoch 10/100\n",
      "132/132 - 2s - 15ms/step - mean_absolute_error: 1468.7255 - mean_euclidean_distance: 2332.8894 - mean_squared_error: 4116171.2500 - r2_score: 0.9347 - rmse: 2028.8350 - loss: 2067320.8750 - val_loss: 1728806.3750 - learning_rate: 0.0100\n",
      "Epoch 11/100\n",
      "132/132 - 2s - 15ms/step - mean_absolute_error: 1519.8433 - mean_euclidean_distance: 2439.6917 - mean_squared_error: 4458726.0000 - r2_score: 0.9305 - rmse: 2111.5696 - loss: 8814477.0000 - val_loss: 2082579.3750 - learning_rate: 0.0100\n",
      "Epoch 12/100\n",
      "132/132 - 2s - 15ms/step - mean_absolute_error: 1401.9760 - mean_euclidean_distance: 2257.4602 - mean_squared_error: 4030549.5000 - r2_score: 0.9326 - rmse: 2007.6228 - loss: 4404696.5000 - val_loss: 1763144.6250 - learning_rate: 0.0100\n",
      "Epoch 13/100\n",
      "132/132 - 2s - 15ms/step - mean_absolute_error: 1255.3622 - mean_euclidean_distance: 2010.9735 - mean_squared_error: 3503487.5000 - r2_score: 0.9418 - rmse: 1871.7605 - loss: 8921415.0000 - val_loss: 1178490.8750 - learning_rate: 0.0100\n",
      "Epoch 14/100\n",
      "132/132 - 2s - 17ms/step - mean_absolute_error: 1299.4066 - mean_euclidean_distance: 2152.1521 - mean_squared_error: 3876372.5000 - r2_score: 0.9322 - rmse: 1968.8506 - loss: 2282429.2500 - val_loss: 1449707.5000 - learning_rate: 0.0100\n",
      "Epoch 15/100\n",
      "132/132 - 2s - 19ms/step - mean_absolute_error: 1384.8320 - mean_euclidean_distance: 2231.2766 - mean_squared_error: 3875118.2500 - r2_score: 0.9367 - rmse: 1968.5320 - loss: 1159328.5000 - val_loss: 2280864.5000 - learning_rate: 0.0100\n",
      "Epoch 16/100\n",
      "132/132 - 2s - 18ms/step - mean_absolute_error: 1311.3604 - mean_euclidean_distance: 2130.4678 - mean_squared_error: 3697344.0000 - r2_score: 0.9378 - rmse: 1922.8479 - loss: 1327532.7500 - val_loss: 1152928.3750 - learning_rate: 0.0100\n",
      "Epoch 17/100\n",
      "132/132 - 2s - 16ms/step - mean_absolute_error: 1480.3956 - mean_euclidean_distance: 2397.9097 - mean_squared_error: 4342475.5000 - r2_score: 0.9336 - rmse: 2083.8608 - loss: 3038343.2500 - val_loss: 2429724.0000 - learning_rate: 0.0100\n",
      "Epoch 18/100\n",
      "132/132 - 2s - 15ms/step - mean_absolute_error: 1780.6241 - mean_euclidean_distance: 2770.8303 - mean_squared_error: 5458038.0000 - r2_score: 0.9152 - rmse: 2336.2444 - loss: 28732144.0000 - val_loss: 2609573.5000 - learning_rate: 0.0100\n",
      "Epoch 19/100\n",
      "132/132 - 2s - 17ms/step - mean_absolute_error: 1373.9634 - mean_euclidean_distance: 2262.8333 - mean_squared_error: 3782604.7500 - r2_score: 0.9400 - rmse: 1944.8920 - loss: 2380263.7500 - val_loss: 1610151.2500 - learning_rate: 0.0100\n",
      "Epoch 20/100\n",
      "132/132 - 2s - 16ms/step - mean_absolute_error: 1281.6084 - mean_euclidean_distance: 2174.9956 - mean_squared_error: 4253076.5000 - r2_score: 0.9205 - rmse: 2062.2988 - loss: 823157.5625 - val_loss: 896671.0000 - learning_rate: 0.0100\n",
      "Epoch 21/100\n",
      "132/132 - 2s - 15ms/step - mean_absolute_error: 1197.9004 - mean_euclidean_distance: 1964.5609 - mean_squared_error: 3055873.0000 - r2_score: 0.9495 - rmse: 1748.1056 - loss: 1274420.5000 - val_loss: 1117878.3750 - learning_rate: 0.0100\n",
      "Epoch 22/100\n",
      "132/132 - 2s - 15ms/step - mean_absolute_error: 1445.2444 - mean_euclidean_distance: 2297.5862 - mean_squared_error: 3860251.2500 - r2_score: 0.9377 - rmse: 1964.7522 - loss: 6818752.0000 - val_loss: 1874620.7500 - learning_rate: 0.0100\n",
      "Epoch 23/100\n",
      "132/132 - 2s - 15ms/step - mean_absolute_error: 1622.3450 - mean_euclidean_distance: 2684.6750 - mean_squared_error: 5150045.5000 - r2_score: 0.9223 - rmse: 2269.3711 - loss: 1882587.2500 - val_loss: 2213007.5000 - learning_rate: 0.0100\n",
      "Epoch 24/100\n",
      "132/132 - 2s - 15ms/step - mean_absolute_error: 2216.7805 - mean_euclidean_distance: 3860.2534 - mean_squared_error: 14995675.0000 - r2_score: 0.6981 - rmse: 3872.4250 - loss: 11403327.0000 - val_loss: 5091139.0000 - learning_rate: 0.0100\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "132/132 - 2s - 17ms/step - mean_absolute_error: 2115.7036 - mean_euclidean_distance: 3960.2185 - mean_squared_error: 19263370.0000 - r2_score: 0.7915 - rmse: 4389.0054 - loss: 1223336.0000 - val_loss: 1302172.3750 - learning_rate: 0.0100\n",
      "Epoch 26/100\n",
      "132/132 - 2s - 16ms/step - mean_absolute_error: 1071.9686 - mean_euclidean_distance: 1870.8385 - mean_squared_error: 3310925.0000 - r2_score: 0.9352 - rmse: 1819.5947 - loss: 3422326.7500 - val_loss: 1381984.6250 - learning_rate: 1.0000e-03\n",
      "Epoch 27/100\n",
      "132/132 - 2s - 16ms/step - mean_absolute_error: 1040.9088 - mean_euclidean_distance: 1762.7084 - mean_squared_error: 2658364.5000 - r2_score: 0.9486 - rmse: 1630.4492 - loss: 3929384.2500 - val_loss: 1442653.2500 - learning_rate: 1.0000e-03\n",
      "Epoch 28/100\n",
      "132/132 - 2s - 16ms/step - mean_absolute_error: 1036.2516 - mean_euclidean_distance: 1736.9095 - mean_squared_error: 2509417.0000 - r2_score: 0.9537 - rmse: 1584.1139 - loss: 1943270.6250 - val_loss: 1451932.3750 - learning_rate: 1.0000e-03\n",
      "Epoch 29/100\n",
      "132/132 - 2s - 17ms/step - mean_absolute_error: 1007.6902 - mean_euclidean_distance: 1669.4987 - mean_squared_error: 2401236.0000 - r2_score: 0.9574 - rmse: 1549.5922 - loss: 469730.0938 - val_loss: 1205307.3750 - learning_rate: 1.0000e-03\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "132/132 - 2s - 19ms/step - mean_absolute_error: 1008.2049 - mean_euclidean_distance: 1670.6726 - mean_squared_error: 2316055.7500 - r2_score: 0.9601 - rmse: 1521.8593 - loss: 1817366.2500 - val_loss: 1256474.5000 - learning_rate: 1.0000e-03\n",
      "Epoch 31/100\n",
      "132/132 - 2s - 18ms/step - mean_absolute_error: 1004.2646 - mean_euclidean_distance: 1658.3777 - mean_squared_error: 2296107.0000 - r2_score: 0.9603 - rmse: 1515.2910 - loss: 774950.8750 - val_loss: 1263735.7500 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "132/132 - 2s - 16ms/step - mean_absolute_error: 998.8948 - mean_euclidean_distance: 1637.9020 - mean_squared_error: 2259754.5000 - r2_score: 0.9609 - rmse: 1503.2479 - loss: 2173233.7500 - val_loss: 1231214.3750 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "132/132 - 2s - 17ms/step - mean_absolute_error: 998.5255 - mean_euclidean_distance: 1632.3828 - mean_squared_error: 2260507.0000 - r2_score: 0.9609 - rmse: 1503.4983 - loss: 2751387.2500 - val_loss: 1201035.6250 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "132/132 - 2s - 17ms/step - mean_absolute_error: 988.5147 - mean_euclidean_distance: 1627.9020 - mean_squared_error: 2257225.0000 - r2_score: 0.9611 - rmse: 1502.4064 - loss: 506698.8125 - val_loss: 1160976.7500 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "132/132 - 2s - 16ms/step - mean_absolute_error: 989.5008 - mean_euclidean_distance: 1631.3320 - mean_squared_error: 2254556.7500 - r2_score: 0.9612 - rmse: 1501.5182 - loss: 2556247.0000 - val_loss: 1197635.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Evaluating on test dataset...\n",
      "29/29 - 0s - 5ms/step - mean_absolute_error: 1397.8328 - mean_euclidean_distance: 2327.2581 - mean_squared_error: 8048393.0000 - r2_score: 0.8471 - rmse: 2836.9690 - loss: 713326.8125\n",
      "Test metrics: [<tf.Tensor: shape=(), dtype=float32, numpy=713326.8125>, {'mean_absolute_error': <tf.Tensor: shape=(), dtype=float32, numpy=1397.832763671875>, 'mean_squared_error': <tf.Tensor: shape=(), dtype=float32, numpy=8048393.0>, 'rmse': <tf.Tensor: shape=(), dtype=float32, numpy=2836.968994140625>, 'r2_score': <tf.Tensor: shape=(), dtype=float32, numpy=0.84709632396698>, 'mean_euclidean_distance': <tf.Tensor: shape=(), dtype=float32, numpy=2327.258056640625>}]\n",
      "\n",
      "Sample predictions for test scenes:\n",
      "Node 0: True future_x=40149.0, future_y=-16841.0 | Predicted future_x=38872.1, future_y=-21047.5\n",
      "Node 1: True future_x=36150.0, future_y=-21965.0 | Predicted future_x=37580.9, future_y=-23949.1\n",
      "Node 2: True future_x=42131.0, future_y=-21564.0 | Predicted future_x=42034.5, future_y=-21617.2\n",
      "Node 3: True future_x=42021.0, future_y=-23271.0 | Predicted future_x=42339.7, future_y=-22496.4\n",
      "Node 4: True future_x=42498.0, future_y=-21046.0 | Predicted future_x=41815.1, future_y=-22538.7\n",
      "\n",
      "Running Task 3...\n",
      "\n",
      "Training...\n",
      "Epoch 1/100\n",
      "132/132 - 16s - 120ms/step - mean_absolute_error: 2218.0042 - mean_euclidean_distance: 4294.7148 - mean_squared_error: 58229892.0000 - r2_score: 0.2982 - rmse: 7630.8516 - loss: 2755294.7500 - val_loss: 944271.1875 - learning_rate: 0.0100\n",
      "Epoch 2/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 1528.6400 - mean_euclidean_distance: 2630.7319 - mean_squared_error: 11412749.0000 - r2_score: 0.8561 - rmse: 3378.2761 - loss: 5216395.5000 - val_loss: 1460351.7500 - learning_rate: 0.0100\n",
      "Epoch 3/100\n",
      "132/132 - 2s - 12ms/step - mean_absolute_error: 2013.4061 - mean_euclidean_distance: 3436.3582 - mean_squared_error: 8043392.0000 - r2_score: 0.8451 - rmse: 2836.0874 - loss: 5395539.5000 - val_loss: 5901619.5000 - learning_rate: 0.0100\n",
      "Epoch 4/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 2080.0369 - mean_euclidean_distance: 3825.1731 - mean_squared_error: 25443632.0000 - r2_score: 0.5532 - rmse: 5044.1680 - loss: 4283779.0000 - val_loss: 2039804.7500 - learning_rate: 0.0100\n",
      "Epoch 5/100\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 2568.8694 - mean_euclidean_distance: 4498.1597 - mean_squared_error: 41308244.0000 - r2_score: 0.4651 - rmse: 6427.1489 - loss: 3709825.2500 - val_loss: 5699131.5000 - learning_rate: 0.0100\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "132/132 - 2s - 11ms/step - mean_absolute_error: 1259.2852 - mean_euclidean_distance: 2055.8635 - mean_squared_error: 3683928.5000 - r2_score: 0.9448 - rmse: 1919.3563 - loss: 799323.1250 - val_loss: 2400556.2500 - learning_rate: 0.0100\n",
      "Epoch 7/100\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 975.9523 - mean_euclidean_distance: 1650.5173 - mean_squared_error: 3057510.2500 - r2_score: 0.9583 - rmse: 1748.5737 - loss: 1577398.3750 - val_loss: 1262992.0000 - learning_rate: 1.0000e-03\n",
      "Epoch 8/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 953.3823 - mean_euclidean_distance: 1598.0730 - mean_squared_error: 2970678.2500 - r2_score: 0.9606 - rmse: 1723.5656 - loss: 599725.6250 - val_loss: 1137362.2500 - learning_rate: 1.0000e-03\n",
      "Epoch 9/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 918.5212 - mean_euclidean_distance: 1572.5956 - mean_squared_error: 2783115.5000 - r2_score: 0.9638 - rmse: 1668.2672 - loss: 1882025.1250 - val_loss: 879907.8125 - learning_rate: 1.0000e-03\n",
      "Epoch 10/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 884.5997 - mean_euclidean_distance: 1489.2225 - mean_squared_error: 2642673.7500 - r2_score: 0.9663 - rmse: 1625.6302 - loss: 995228.4375 - val_loss: 990715.0000 - learning_rate: 1.0000e-03\n",
      "Epoch 11/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 882.1208 - mean_euclidean_distance: 1480.2893 - mean_squared_error: 2606998.2500 - r2_score: 0.9668 - rmse: 1614.6201 - loss: 1071904.0000 - val_loss: 1027170.0000 - learning_rate: 1.0000e-03\n",
      "Epoch 12/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 823.7004 - mean_euclidean_distance: 1398.5328 - mean_squared_error: 2437454.2500 - r2_score: 0.9700 - rmse: 1561.2349 - loss: 1028819.8125 - val_loss: 764535.3750 - learning_rate: 1.0000e-03\n",
      "Epoch 13/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 830.1840 - mean_euclidean_distance: 1378.2875 - mean_squared_error: 2309444.2500 - r2_score: 0.9720 - rmse: 1519.6855 - loss: 615488.9375 - val_loss: 733580.7500 - learning_rate: 1.0000e-03\n",
      "Epoch 14/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 770.9836 - mean_euclidean_distance: 1319.8527 - mean_squared_error: 2256998.7500 - r2_score: 0.9734 - rmse: 1502.3311 - loss: 965318.0000 - val_loss: 675609.6250 - learning_rate: 1.0000e-03\n",
      "Epoch 15/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 757.5682 - mean_euclidean_distance: 1280.7643 - mean_squared_error: 2093159.7500 - r2_score: 0.9755 - rmse: 1446.7756 - loss: 686675.0000 - val_loss: 815634.6250 - learning_rate: 1.0000e-03\n",
      "Epoch 16/100\n",
      "132/132 - 2s - 12ms/step - mean_absolute_error: 763.3690 - mean_euclidean_distance: 1297.3058 - mean_squared_error: 2108269.7500 - r2_score: 0.9762 - rmse: 1451.9882 - loss: 462181.2500 - val_loss: 611125.4375 - learning_rate: 1.0000e-03\n",
      "Epoch 17/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 815.4244 - mean_euclidean_distance: 1364.8546 - mean_squared_error: 2220252.5000 - r2_score: 0.9746 - rmse: 1490.0511 - loss: 977931.2500 - val_loss: 518273.1562 - learning_rate: 1.0000e-03\n",
      "Epoch 18/100\n",
      "132/132 - 2s - 11ms/step - mean_absolute_error: 700.6320 - mean_euclidean_distance: 1183.2565 - mean_squared_error: 1874481.1250 - r2_score: 0.9793 - rmse: 1369.1169 - loss: 315520.0625 - val_loss: 689197.6875 - learning_rate: 1.0000e-03\n",
      "Epoch 19/100\n",
      "132/132 - 2s - 12ms/step - mean_absolute_error: 687.9365 - mean_euclidean_distance: 1181.7441 - mean_squared_error: 1837344.5000 - r2_score: 0.9800 - rmse: 1355.4868 - loss: 1231933.5000 - val_loss: 677635.2500 - learning_rate: 1.0000e-03\n",
      "Epoch 20/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 677.6674 - mean_euclidean_distance: 1142.0999 - mean_squared_error: 1768453.0000 - r2_score: 0.9812 - rmse: 1329.8319 - loss: 671550.7500 - val_loss: 575667.8750 - learning_rate: 1.0000e-03\n",
      "Epoch 21/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 711.9662 - mean_euclidean_distance: 1169.9546 - mean_squared_error: 1835957.2500 - r2_score: 0.9812 - rmse: 1354.9750 - loss: 734045.1875 - val_loss: 749318.6875 - learning_rate: 1.0000e-03\n",
      "Epoch 22/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 646.9512 - mean_euclidean_distance: 1098.1096 - mean_squared_error: 1667115.3750 - r2_score: 0.9830 - rmse: 1291.1682 - loss: 372801.8438 - val_loss: 480651.1875 - learning_rate: 1.0000e-03\n",
      "Epoch 23/100\n",
      "132/132 - 2s - 13ms/step - mean_absolute_error: 630.1224 - mean_euclidean_distance: 1061.1493 - mean_squared_error: 1660696.1250 - r2_score: 0.9836 - rmse: 1288.6801 - loss: 253467.8438 - val_loss: 517524.0938 - learning_rate: 1.0000e-03\n",
      "Epoch 24/100\n",
      "132/132 - 2s - 14ms/step - mean_absolute_error: 634.9717 - mean_euclidean_distance: 1063.9701 - mean_squared_error: 1589572.8750 - r2_score: 0.9845 - rmse: 1260.7826 - loss: 559095.8750 - val_loss: 563805.8750 - learning_rate: 1.0000e-03\n",
      "Epoch 25/100\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 651.2413 - mean_euclidean_distance: 1073.6744 - mean_squared_error: 1603190.5000 - r2_score: 0.9852 - rmse: 1266.1716 - loss: 722752.3125 - val_loss: 561970.1875 - learning_rate: 1.0000e-03\n",
      "Epoch 26/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 594.2039 - mean_euclidean_distance: 1005.3714 - mean_squared_error: 1508568.3750 - r2_score: 0.9860 - rmse: 1228.2379 - loss: 215696.3438 - val_loss: 586265.7500 - learning_rate: 1.0000e-03\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 625.4548 - mean_euclidean_distance: 1029.9855 - mean_squared_error: 1558695.7500 - r2_score: 0.9858 - rmse: 1248.4774 - loss: 1701416.3750 - val_loss: 618315.4375 - learning_rate: 1.0000e-03\n",
      "Epoch 28/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 556.6548 - mean_euclidean_distance: 938.0071 - mean_squared_error: 1447173.5000 - r2_score: 0.9871 - rmse: 1202.9852 - loss: 2022274.6250 - val_loss: 471345.0625 - learning_rate: 1.0000e-04\n",
      "Epoch 29/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 562.5805 - mean_euclidean_distance: 945.5065 - mean_squared_error: 1423440.8750 - r2_score: 0.9873 - rmse: 1193.0804 - loss: 504974.6875 - val_loss: 440257.5938 - learning_rate: 1.0000e-04\n",
      "Epoch 30/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 554.9324 - mean_euclidean_distance: 938.5793 - mean_squared_error: 1418267.2500 - r2_score: 0.9874 - rmse: 1190.9103 - loss: 289560.5000 - val_loss: 421247.0938 - learning_rate: 1.0000e-04\n",
      "Epoch 31/100\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 551.5225 - mean_euclidean_distance: 928.7850 - mean_squared_error: 1396567.3750 - r2_score: 0.9876 - rmse: 1181.7645 - loss: 615794.8125 - val_loss: 460064.3438 - learning_rate: 1.0000e-04\n",
      "Epoch 32/100\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 553.0565 - mean_euclidean_distance: 928.9178 - mean_squared_error: 1407834.1250 - r2_score: 0.9876 - rmse: 1186.5219 - loss: 1964660.5000 - val_loss: 466127.0938 - learning_rate: 1.0000e-04\n",
      "Epoch 33/100\n",
      "132/132 - 2s - 13ms/step - mean_absolute_error: 548.9442 - mean_euclidean_distance: 929.9710 - mean_squared_error: 1392471.2500 - r2_score: 0.9878 - rmse: 1180.0302 - loss: 161181.9375 - val_loss: 437195.9062 - learning_rate: 1.0000e-04\n",
      "Epoch 34/100\n",
      "132/132 - 2s - 13ms/step - mean_absolute_error: 545.8762 - mean_euclidean_distance: 925.9056 - mean_squared_error: 1395763.0000 - r2_score: 0.9878 - rmse: 1181.4242 - loss: 293991.0625 - val_loss: 419690.9062 - learning_rate: 1.0000e-04\n",
      "Epoch 35/100\n",
      "132/132 - 2s - 12ms/step - mean_absolute_error: 552.1770 - mean_euclidean_distance: 927.1626 - mean_squared_error: 1396316.2500 - r2_score: 0.9878 - rmse: 1181.6582 - loss: 205640.7969 - val_loss: 506634.9062 - learning_rate: 1.0000e-04\n",
      "Epoch 36/100\n",
      "132/132 - 2s - 12ms/step - mean_absolute_error: 551.5735 - mean_euclidean_distance: 922.8414 - mean_squared_error: 1393501.2500 - r2_score: 0.9879 - rmse: 1180.4666 - loss: 266245.3438 - val_loss: 501533.5000 - learning_rate: 1.0000e-04\n",
      "Epoch 37/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 545.7283 - mean_euclidean_distance: 915.7739 - mean_squared_error: 1391824.3750 - r2_score: 0.9880 - rmse: 1179.7561 - loss: 267114.5000 - val_loss: 486038.1562 - learning_rate: 1.0000e-04\n",
      "Epoch 38/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 556.7925 - mean_euclidean_distance: 925.7601 - mean_squared_error: 1391048.5000 - r2_score: 0.9880 - rmse: 1179.4272 - loss: 243556.5938 - val_loss: 519165.0938 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 541.0354 - mean_euclidean_distance: 910.5157 - mean_squared_error: 1366525.2500 - r2_score: 0.9882 - rmse: 1168.9847 - loss: 380951.5625 - val_loss: 455370.8125 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 537.2509 - mean_euclidean_distance: 906.2079 - mean_squared_error: 1363954.1250 - r2_score: 0.9883 - rmse: 1167.8845 - loss: 115040.7266 - val_loss: 428428.8438 - learning_rate: 1.0000e-05\n",
      "Epoch 41/100\n",
      "132/132 - 2s - 12ms/step - mean_absolute_error: 537.0167 - mean_euclidean_distance: 904.9918 - mean_squared_error: 1364132.2500 - r2_score: 0.9883 - rmse: 1167.9607 - loss: 1630870.5000 - val_loss: 434785.6875 - learning_rate: 1.0000e-05\n",
      "Epoch 42/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 539.0043 - mean_euclidean_distance: 905.4962 - mean_squared_error: 1363527.5000 - r2_score: 0.9883 - rmse: 1167.7018 - loss: 605536.0000 - val_loss: 460046.5625 - learning_rate: 1.0000e-05\n",
      "Epoch 43/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 537.1102 - mean_euclidean_distance: 903.6342 - mean_squared_error: 1363358.5000 - r2_score: 0.9883 - rmse: 1167.6294 - loss: 1497021.7500 - val_loss: 447685.8125 - learning_rate: 1.0000e-05\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 537.2699 - mean_euclidean_distance: 903.5366 - mean_squared_error: 1362870.8750 - r2_score: 0.9883 - rmse: 1167.4207 - loss: 295236.3438 - val_loss: 442953.3438 - learning_rate: 1.0000e-05\n",
      "Epoch 45/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 537.2361 - mean_euclidean_distance: 903.4815 - mean_squared_error: 1362812.1250 - r2_score: 0.9883 - rmse: 1167.3954 - loss: 273246.3125 - val_loss: 443057.4062 - learning_rate: 1.0000e-06\n",
      "Epoch 46/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 537.2186 - mean_euclidean_distance: 903.4717 - mean_squared_error: 1362745.1250 - r2_score: 0.9883 - rmse: 1167.3667 - loss: 163415.7031 - val_loss: 442594.6562 - learning_rate: 1.0000e-06\n",
      "Epoch 47/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 537.1203 - mean_euclidean_distance: 903.3282 - mean_squared_error: 1362608.7500 - r2_score: 0.9883 - rmse: 1167.3083 - loss: 293483.2812 - val_loss: 443667.0000 - learning_rate: 1.0000e-06\n",
      "Epoch 48/100\n",
      "132/132 - 1s - 10ms/step - mean_absolute_error: 537.0013 - mean_euclidean_distance: 903.2028 - mean_squared_error: 1362913.6250 - r2_score: 0.9883 - rmse: 1167.4390 - loss: 1698970.2500 - val_loss: 444713.1562 - learning_rate: 1.0000e-06\n",
      "Epoch 49/100\n",
      "132/132 - 1s - 11ms/step - mean_absolute_error: 536.9098 - mean_euclidean_distance: 903.0781 - mean_squared_error: 1362543.7500 - r2_score: 0.9883 - rmse: 1167.2805 - loss: 735833.3125 - val_loss: 445247.9062 - learning_rate: 1.0000e-06\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Evaluating on test dataset...\n",
      "29/29 - 0s - 5ms/step - mean_absolute_error: 741.0971 - mean_euclidean_distance: 1265.5735 - mean_squared_error: 10672429.0000 - r2_score: 0.9291 - rmse: 3266.8684 - loss: 302751.5000\n",
      "Test metrics: [<tf.Tensor: shape=(), dtype=float32, numpy=302751.5>, {'mean_absolute_error': <tf.Tensor: shape=(), dtype=float32, numpy=741.0971069335938>, 'mean_squared_error': <tf.Tensor: shape=(), dtype=float32, numpy=10672429.0>, 'rmse': <tf.Tensor: shape=(), dtype=float32, numpy=3266.868408203125>, 'r2_score': <tf.Tensor: shape=(), dtype=float32, numpy=0.9291020035743713>, 'mean_euclidean_distance': <tf.Tensor: shape=(), dtype=float32, numpy=1265.573486328125>}]\n",
      "\n",
      "Sample predictions for test scenes:\n",
      "Node 0: True future_x=40149.0, future_y=-16841.0 | Predicted future_x=41391.8, future_y=-17360.2\n",
      "Node 1: True future_x=36150.0, future_y=-21965.0 | Predicted future_x=36465.1, future_y=-22539.3\n",
      "Node 2: True future_x=42131.0, future_y=-21564.0 | Predicted future_x=42048.3, future_y=-21472.4\n",
      "Node 3: True future_x=42021.0, future_y=-23271.0 | Predicted future_x=41915.2, future_y=-22788.5\n",
      "Node 4: True future_x=42498.0, future_y=-21046.0 | Predicted future_x=42907.8, future_y=-21004.2\n",
      "Running time: 0 hours, 5 minutes, 28 seconds\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(2)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "dataset_dir = \"dataset\"\n",
    "\n",
    "feature_cols = [\"current_x\", \"current_y\", \"previous_x\", \"previous_y\"]\n",
    "target_cols = [\"future_x\", \"future_y\"]\n",
    "\n",
    "scenes = load_all_subgraphs(dataset_dir)\n",
    "print(f\"Loaded {len(scenes)} scenes.\")\n",
    "train_scenes, val_scenes, test_scenes = split_scenes(scenes, train_ratio=0.7, val_ratio=0.15)\n",
    "print(f\"Train scenes: {len(train_scenes)}, Val scenes: {len(val_scenes)}, Test scenes: {len(test_scenes)}\")\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: scene_generator(train_scenes, feature_cols, target_cols),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, len(feature_cols)), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 2), dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=(None, len(target_cols)), dtype=tf.float32),\n",
    "    ),\n",
    ")\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: scene_generator(val_scenes, feature_cols, target_cols),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, len(feature_cols)), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 2), dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=(None, len(target_cols)), dtype=tf.float32),\n",
    "    ),\n",
    ")\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: scene_generator(test_scenes, feature_cols, target_cols),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, len(feature_cols)), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 2), dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=(None, len(target_cols)), dtype=tf.float32),\n",
    "    ),\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.shuffle(100).batch(1).map(squeeze_batch)\n",
    "val_dataset = val_dataset.batch(1).map(squeeze_batch)\n",
    "test_dataset = test_dataset.batch(1).map(squeeze_batch)\n",
    "\n",
    "HIDDEN_UNITS = 100\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 3\n",
    "OUTPUT_DIM = 2\n",
    "LEARNING_RATE = 1e-2\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "gat_model = None\n",
    "history = None\n",
    "\n",
    "tasks = [1, 2, 3]\n",
    "\n",
    "for task in tasks:\n",
    "\n",
    "    if task == 1:\n",
    "        print(\"\\nRunning Task 1...\\n\")\n",
    "\n",
    "        gat_model = GraphAttentionNetwork(\n",
    "            hidden_units=HIDDEN_UNITS, num_heads=NUM_HEADS, num_layers=NUM_LAYERS, output_dim=OUTPUT_DIM, task=task\n",
    "        )\n",
    "\n",
    "    elif task == 2:\n",
    "        print(\"\\nRunning Task 2...\\n\")\n",
    "        num_heads = [2, 4, 6, 8]\n",
    "\n",
    "        for i, heads in enumerate(num_heads):\n",
    "            print(f\"\\nRun: {i + 1}\\nHeads: {heads}\\n\")\n",
    "\n",
    "            gat_model = GraphAttentionNetwork(\n",
    "                hidden_units=HIDDEN_UNITS, num_heads=heads, num_layers=NUM_LAYERS, output_dim=OUTPUT_DIM, task=task\n",
    "            )\n",
    "\n",
    "            gat_model, history = compile_and_train(\n",
    "                gat_model=gat_model,\n",
    "                train_dataset=train_dataset,\n",
    "                val_dataset=val_dataset,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                learning_rate=LEARNING_RATE,\n",
    "            )\n",
    "\n",
    "            evaluate_and_plot(\n",
    "                gat_model=gat_model, history=history, test_dataset=test_dataset, task=task, run=str(i + 1)\n",
    "            )\n",
    "\n",
    "    elif task == 3:\n",
    "        print(\"\\nRunning Task 3...\\n\")\n",
    "        NUM_HEADS = 8\n",
    "\n",
    "        gat_model = CosineGraphAttentionNetwork(\n",
    "            hidden_units=HIDDEN_UNITS,\n",
    "            num_heads=NUM_HEADS,\n",
    "            num_layers=NUM_LAYERS,\n",
    "            output_dim=OUTPUT_DIM,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown task\")\n",
    "\n",
    "    if task != 2:\n",
    "        gat_model, history = compile_and_train(\n",
    "            gat_model=gat_model,\n",
    "            train_dataset=train_dataset,\n",
    "            val_dataset=val_dataset,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "        )\n",
    "\n",
    "        evaluate_and_plot(gat_model=gat_model, history=history, test_dataset=test_dataset, task=task)\n",
    "\n",
    "end_time = time.time()\n",
    "running_time = end_time - start_time\n",
    "hours = int(running_time // 3600)\n",
    "minutes = int((running_time % 3600) // 60)\n",
    "seconds = int(running_time % 60)\n",
    "print(f\"Running time: {hours} hours, {minutes} minutes, {seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5b1730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
