{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "922fc247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 10:27:44.750925: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 10:27:44.752061: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-14 10:27:44.755682: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-14 10:27:44.765081: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744619264.781620 2391859 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744619264.787340 2391859 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 10:27:44.804375: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original edges count: 15\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 14\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890817715 contains -1 edges. Processing...\n",
      "Original edges count: 16\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 15\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890814428 contains -1 edges. Processing...\n",
      "Scene ID 1352890802323 contains -1 edges. Processing...\n",
      "Original edges count: 23\n",
      "Original nodes count: 12\n",
      "Filtered edges count: 22\n",
      "Filtered nodes count: 11\n",
      "Scene ID 1352890800322 contains -1 edges. Processing...\n",
      "Scene ID 1352890875617 contains -1 edges. Processing...\n",
      "Original edges count: 16\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 13\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890804562 contains -1 edges. Processing...\n",
      "Original edges count: 14\n",
      "Original nodes count: 10\n",
      "Filtered edges count: 13\n",
      "Filtered nodes count: 9\n",
      "Scene ID 1352890841688 contains -1 edges. Processing...\n",
      "Scene ID 1352890837555 contains -1 edges. Processing...\n",
      "Scene ID 1352890825684 contains -1 edges. Processing...\n",
      "Original edges count: 19\n",
      "Original nodes count: 12\n",
      "Filtered edges count: 18\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890801553 contains -1 edges. Processing...\n",
      "Original edges count: 35\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 31\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890832535 contains -1 edges. Processing...\n",
      "Original edges count: 34\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 31\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890829505 contains -1 edges. Processing...\n",
      "Original edges count: 15\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 10\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890803926 contains -1 edges. Processing...\n",
      "Original edges count: 14\n",
      "Original nodes count: 9\n",
      "Filtered edges count: 13\n",
      "Filtered nodes count: 8\n",
      "Scene ID 1352890842354 contains -1 edges. Processing...\n",
      "Scene ID 1352890813672 contains -1 edges. Processing...\n",
      "Scene ID 1352890884154 contains -1 edges. Processing...\n",
      "Original edges count: 3\n",
      "Original nodes count: 5\n",
      "Filtered edges count: 2\n",
      "Filtered nodes count: 5\n",
      "Scene ID 1352890846971 contains -1 edges. Processing...\n",
      "Scene ID 1352890834297 contains -1 edges. Processing...\n",
      "Scene ID 1352890834338 contains -1 edges. Processing...\n",
      "Original edges count: 17\n",
      "Original nodes count: 15\n",
      "Filtered edges count: 16\n",
      "Filtered nodes count: 14\n",
      "Scene ID 1352890812682 contains -1 edges. Processing...\n",
      "Original edges count: 20\n",
      "Original nodes count: 12\n",
      "Filtered edges count: 19\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890801292 contains -1 edges. Processing...\n",
      "Original edges count: 16\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 11\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890807487 contains -1 edges. Processing...\n",
      "Scene ID 1352890815643 contains -1 edges. Processing...\n",
      "Scene ID 1352890808973 contains -1 edges. Processing...\n",
      "Scene ID 1352890834536 contains -1 edges. Processing...\n",
      "Scene ID 1352890836794 contains -1 edges. Processing...\n",
      "Scene ID 1352890828841 contains -1 edges. Processing...\n",
      "Original edges count: 9\n",
      "Original nodes count: 10\n",
      "Filtered edges count: 8\n",
      "Filtered nodes count: 10\n",
      "Scene ID 1352890919291 contains -1 edges. Processing...\n",
      "Scene ID 1352890828882 contains -1 edges. Processing...\n",
      "Scene ID 1352890891802 contains -1 edges. Processing...\n",
      "Scene ID 1352890801118 contains -1 edges. Processing...\n",
      "Original edges count: 5\n",
      "Original nodes count: 6\n",
      "Filtered edges count: 4\n",
      "Filtered nodes count: 6\n",
      "Scene ID 1352890849798 contains -1 edges. Processing...\n",
      "Original edges count: 7\n",
      "Original nodes count: 9\n",
      "Filtered edges count: 4\n",
      "Filtered nodes count: 9\n",
      "Scene ID 1352890894347 contains -1 edges. Processing...\n",
      "Original edges count: 23\n",
      "Original nodes count: 12\n",
      "Filtered edges count: 22\n",
      "Filtered nodes count: 11\n",
      "Scene ID 1352890800459 contains -1 edges. Processing...\n",
      "Original edges count: 14\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 10\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890803486 contains -1 edges. Processing...\n",
      "Original edges count: 35\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 32\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890829713 contains -1 edges. Processing...\n",
      "Scene ID 1352890828668 contains -1 edges. Processing...\n",
      "Scene ID 1352890809063 contains -1 edges. Processing...\n",
      "Original edges count: 30\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 28\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890829002 contains -1 edges. Processing...\n",
      "Scene ID 1352890918879 contains -1 edges. Processing...\n",
      "Original edges count: 6\n",
      "Original nodes count: 9\n",
      "Filtered edges count: 4\n",
      "Filtered nodes count: 7\n",
      "Scene ID 1352890890812 contains -1 edges. Processing...\n",
      "Scene ID 1352890837871 contains -1 edges. Processing...\n",
      "Original edges count: 20\n",
      "Original nodes count: 15\n",
      "Filtered edges count: 13\n",
      "Filtered nodes count: 14\n",
      "Scene ID 135289080699 contains -1 edges. Processing...\n",
      "Original edges count: 15\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 13\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890815512 contains -1 edges. Processing...\n",
      "Original edges count: 31\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 29\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890829207 contains -1 edges. Processing...\n",
      "Scene ID 1352890839303 contains -1 edges. Processing...\n",
      "Original edges count: 8\n",
      "Original nodes count: 10\n",
      "Filtered edges count: 7\n",
      "Filtered nodes count: 10\n",
      "Scene ID 1352890919525 contains -1 edges. Processing...\n",
      "Original edges count: 36\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 33\n",
      "Filtered nodes count: 12\n",
      "Scene ID 135289083242 contains -1 edges. Processing...\n",
      "Original edges count: 34\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 30\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890832654 contains -1 edges. Processing...\n",
      "Scene ID 135289082308 contains -1 edges. Processing...\n",
      "Original edges count: 32\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 28\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890832698 contains -1 edges. Processing...\n",
      "Original edges count: 21\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 17\n",
      "Filtered nodes count: 14\n",
      "Scene ID 1352890818928 contains -1 edges. Processing...\n",
      "Original edges count: 14\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 11\n",
      "Filtered nodes count: 14\n",
      "Scene ID 1352890809821 contains -1 edges. Processing...\n",
      "Original edges count: 14\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 11\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890803574 contains -1 edges. Processing...\n",
      "Original edges count: 25\n",
      "Original nodes count: 12\n",
      "Filtered edges count: 24\n",
      "Filtered nodes count: 11\n",
      "Scene ID 13528908000089998 contains -1 edges. Processing...\n",
      "Scene ID 1352890830824 contains -1 edges. Processing...\n",
      "Original edges count: 4\n",
      "Original nodes count: 6\n",
      "Filtered edges count: 3\n",
      "Filtered nodes count: 6\n",
      "Scene ID 1352890849578 contains -1 edges. Processing...\n",
      "Scene ID 1352890826701 contains -1 edges. Processing...\n",
      "Scene ID 13528908087 contains -1 edges. Processing...\n",
      "Original edges count: 32\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 29\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890833057 contains -1 edges. Processing...\n",
      "Scene ID 1352890809106 contains -1 edges. Processing...\n",
      "Scene ID 1352890834498 contains -1 edges. Processing...\n",
      "Scene ID 1352890919111 contains -1 edges. Processing...\n",
      "Original edges count: 31\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 28\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890832737 contains -1 edges. Processing...\n",
      "Original edges count: 13\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 10\n",
      "Filtered nodes count: 12\n",
      "Scene ID 135289080379 contains -1 edges. Processing...\n",
      "Original edges count: 10\n",
      "Original nodes count: 10\n",
      "Filtered edges count: 9\n",
      "Filtered nodes count: 10\n",
      "Scene ID 135289091722 contains -1 edges. Processing...\n",
      "Original edges count: 6\n",
      "Original nodes count: 9\n",
      "Filtered edges count: 5\n",
      "Filtered nodes count: 9\n",
      "Scene ID 1352890906673 contains -1 edges. Processing...\n",
      "Original edges count: 4\n",
      "Original nodes count: 4\n",
      "Filtered edges count: 3\n",
      "Filtered nodes count: 3\n",
      "Scene ID 1352890844758 contains -1 edges. Processing...\n",
      "Original edges count: 15\n",
      "Original nodes count: 15\n",
      "Filtered edges count: 14\n",
      "Filtered nodes count: 14\n",
      "Scene ID 1352890813256 contains -1 edges. Processing...\n",
      "Original edges count: 21\n",
      "Original nodes count: 12\n",
      "Filtered edges count: 20\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890801209 contains -1 edges. Processing...\n",
      "Original edges count: 22\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 18\n",
      "Filtered nodes count: 14\n",
      "Scene ID 1352890818793 contains -1 edges. Processing...\n",
      "Original edges count: 28\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 27\n",
      "Filtered nodes count: 13\n",
      "Scene ID 13528908349910002 contains -1 edges. Processing...\n",
      "Original edges count: 16\n",
      "Original nodes count: 15\n",
      "Filtered edges count: 15\n",
      "Filtered nodes count: 14\n",
      "Scene ID 1352890812805 contains -1 edges. Processing...\n",
      "Scene ID 1352890833183 contains -1 edges. Processing...\n",
      "Scene ID 1352890886909 contains -1 edges. Processing...\n",
      "Original edges count: 18\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 17\n",
      "Filtered nodes count: 13\n",
      "Scene ID 135289080254 contains -1 edges. Processing...\n",
      "Scene ID 1352890813937 contains -1 edges. Processing...\n",
      "Scene ID 1352890831704 contains -1 edges. Processing...\n",
      "Original edges count: 15\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 10\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890803131 contains -1 edges. Processing...\n",
      "Original edges count: 17\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 14\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890806668 contains -1 edges. Processing...\n",
      "Original edges count: 19\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 15\n",
      "Filtered nodes count: 14\n",
      "Scene ID 1352890805653 contains -1 edges. Processing...\n",
      "Original edges count: 18\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 15\n",
      "Filtered nodes count: 14\n",
      "Scene ID 1352890805012 contains -1 edges. Processing...\n",
      "Scene ID 1352890878093 contains -1 edges. Processing...\n",
      "Original edges count: 18\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 15\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890806119 contains -1 edges. Processing...\n",
      "Original edges count: 23\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 22\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890823766 contains -1 edges. Processing...\n",
      "Scene ID 135289081753 contains -1 edges. Processing...\n",
      "Original edges count: 16\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 11\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890803042 contains -1 edges. Processing...\n",
      "Scene ID 1352890821689 contains -1 edges. Processing...\n",
      "Original edges count: 25\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 24\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890835826 contains -1 edges. Processing...\n",
      "Original edges count: 4\n",
      "Original nodes count: 5\n",
      "Filtered edges count: 2\n",
      "Filtered nodes count: 4\n",
      "Scene ID 1352890844845 contains -1 edges. Processing...\n",
      "Scene ID 1352890834053 contains -1 edges. Processing...\n",
      "Scene ID 135289091765 contains -1 edges. Processing...\n",
      "Scene ID 1352890916071 contains -1 edges. Processing...\n",
      "Scene ID 1352890820444 contains -1 edges. Processing...\n",
      "Original edges count: 7\n",
      "Original nodes count: 8\n",
      "Filtered edges count: 5\n",
      "Filtered nodes count: 8\n",
      "Scene ID 1352890860907 contains -1 edges. Processing...\n",
      "Original edges count: 16\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 11\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890803972 contains -1 edges. Processing...\n",
      "Original edges count: 20\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 16\n",
      "Filtered nodes count: 14\n",
      "Scene ID 1352890819103 contains -1 edges. Processing...\n",
      "Scene ID 1352890810586 contains -1 edges. Processing...\n",
      "Scene ID 1352890820576 contains -1 edges. Processing...\n",
      "Scene ID 1352890915979 contains -1 edges. Processing...\n",
      "Original edges count: 4\n",
      "Original nodes count: 5\n",
      "Filtered edges count: 3\n",
      "Filtered nodes count: 3\n",
      "Scene ID 1352890844712 contains -1 edges. Processing...\n",
      "Original edges count: 17\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 16\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890838234 contains -1 edges. Processing...\n",
      "Original edges count: 30\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 28\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890829166 contains -1 edges. Processing...\n",
      "Original edges count: 3\n",
      "Original nodes count: 4\n",
      "Filtered edges count: 2\n",
      "Filtered nodes count: 4\n",
      "Scene ID 1352890845672 contains -1 edges. Processing...\n",
      "Original edges count: 13\n",
      "Original nodes count: 8\n",
      "Filtered edges count: 9\n",
      "Filtered nodes count: 7\n",
      "Scene ID 1352890842712 contains -1 edges. Processing...\n",
      "Original edges count: 36\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 32\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890832497 contains -1 edges. Processing...\n",
      "Original edges count: 9\n",
      "Original nodes count: 7\n",
      "Filtered edges count: 4\n",
      "Filtered nodes count: 5\n",
      "Scene ID 1352890843708 contains -1 edges. Processing...\n",
      "Original edges count: 18\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 14\n",
      "Filtered nodes count: 14\n",
      "Scene ID 13528908058 contains -1 edges. Processing...\n",
      "Scene ID 1352890839439 contains -1 edges. Processing...\n",
      "Original edges count: 24\n",
      "Original nodes count: 12\n",
      "Filtered edges count: 23\n",
      "Filtered nodes count: 11\n",
      "Scene ID 13528908003660002 contains -1 edges. Processing...\n",
      "Scene ID 1352890824946 contains -1 edges. Processing...\n",
      "Scene ID 1352890824516 contains -1 edges. Processing...\n",
      "Scene ID 135289081098 contains -1 edges. Processing...\n",
      "Original edges count: 32\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 30\n",
      "Filtered nodes count: 13\n",
      "Scene ID 13528908292589998 contains -1 edges. Processing...\n",
      "Original edges count: 17\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 16\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890817934 contains -1 edges. Processing...\n",
      "Scene ID 1352890800907 contains -1 edges. Processing...\n",
      "Original edges count: 16\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 13\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890815016 contains -1 edges. Processing...\n",
      "Scene ID 1352890834692 contains -1 edges. Processing...\n",
      "Original edges count: 8\n",
      "Original nodes count: 9\n",
      "Filtered edges count: 7\n",
      "Filtered nodes count: 9\n",
      "Scene ID 1352890867565 contains -1 edges. Processing...\n",
      "Original edges count: 17\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 13\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890814839 contains -1 edges. Processing...\n",
      "Original edges count: 10\n",
      "Original nodes count: 11\n",
      "Filtered edges count: 8\n",
      "Filtered nodes count: 10\n",
      "Scene ID 1352890916428 contains -1 edges. Processing...\n",
      "Original edges count: 7\n",
      "Original nodes count: 10\n",
      "Filtered edges count: 5\n",
      "Filtered nodes count: 9\n",
      "Scene ID 1352890887794 contains -1 edges. Processing...\n",
      "Scene ID 1352890813762 contains -1 edges. Processing...\n",
      "Scene ID 13528908331360002 contains -1 edges. Processing...\n",
      "Original edges count: 16\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 13\n",
      "Filtered nodes count: 14\n",
      "Scene ID 1352890807035 contains -1 edges. Processing...\n",
      "Original edges count: 15\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 12\n",
      "Filtered nodes count: 14\n",
      "Scene ID 1352890807396 contains -1 edges. Processing...\n",
      "Original edges count: 16\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 13\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890806949 contains -1 edges. Processing...\n",
      "Original edges count: 21\n",
      "Original nodes count: 12\n",
      "Filtered edges count: 20\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890801417 contains -1 edges. Processing...\n",
      "Original edges count: 15\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 11\n",
      "Filtered nodes count: 14\n",
      "Scene ID 1352890809687 contains -1 edges. Processing...\n",
      "Scene ID 1352890820225 contains -1 edges. Processing...\n",
      "Original edges count: 16\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 13\n",
      "Filtered nodes count: 14\n",
      "Scene ID 135289080722 contains -1 edges. Processing...\n",
      "Original edges count: 6\n",
      "Original nodes count: 8\n",
      "Filtered edges count: 5\n",
      "Filtered nodes count: 7\n",
      "Scene ID 1352890891769 contains -1 edges. Processing...\n",
      "Original edges count: 35\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 32\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890832459 contains -1 edges. Processing...\n",
      "Original edges count: 5\n",
      "Original nodes count: 8\n",
      "Filtered edges count: 4\n",
      "Filtered nodes count: 8\n",
      "Scene ID 1352890894309 contains -1 edges. Processing...\n",
      "Scene ID 1352890837646 contains -1 edges. Processing...\n",
      "Original edges count: 36\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 32\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890829843 contains -1 edges. Processing...\n",
      "Original edges count: 14\n",
      "Original nodes count: 11\n",
      "Filtered edges count: 13\n",
      "Filtered nodes count: 10\n",
      "Scene ID 1352890841153 contains -1 edges. Processing...\n",
      "Original edges count: 22\n",
      "Original nodes count: 12\n",
      "Filtered edges count: 21\n",
      "Filtered nodes count: 11\n",
      "Scene ID 1352890800768 contains -1 edges. Processing...\n",
      "Original edges count: 19\n",
      "Original nodes count: 15\n",
      "Filtered edges count: 18\n",
      "Filtered nodes count: 15\n",
      "Scene ID 1352890811843 contains -1 edges. Processing...\n",
      "Scene ID 1352890827838 contains -1 edges. Processing...\n",
      "Original edges count: 32\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 29\n",
      "Filtered nodes count: 12\n",
      "Scene ID 13528908329 contains -1 edges. Processing...\n",
      "Original edges count: 13\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 10\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890803659 contains -1 edges. Processing...\n",
      "Scene ID 135289083891 contains -1 edges. Processing...\n",
      "Original edges count: 15\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 13\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890804018 contains -1 edges. Processing...\n",
      "Original edges count: 16\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 15\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890814167 contains -1 edges. Processing...\n",
      "Scene ID 1352890875117 contains -1 edges. Processing...\n",
      "Scene ID 1352890836572 contains -1 edges. Processing...\n",
      "Scene ID 1352890825035 contains -1 edges. Processing...\n",
      "Original edges count: 24\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 23\n",
      "Filtered nodes count: 13\n",
      "Scene ID 135289083596 contains -1 edges. Processing...\n",
      "Scene ID 13528908282510002 contains -1 edges. Processing...\n",
      "Original edges count: 17\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 16\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890802778 contains -1 edges. Processing...\n",
      "Original edges count: 18\n",
      "Original nodes count: 15\n",
      "Filtered edges count: 17\n",
      "Filtered nodes count: 15\n",
      "Scene ID 1352890812416 contains -1 edges. Processing...\n",
      "Scene ID 135289083913 contains -1 edges. Processing...\n",
      "Original edges count: 34\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 31\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890832378 contains -1 edges. Processing...\n",
      "Original edges count: 10\n",
      "Original nodes count: 10\n",
      "Filtered edges count: 9\n",
      "Filtered nodes count: 9\n",
      "Scene ID 1352890917968 contains -1 edges. Processing...\n",
      "Scene ID 13528908366160002 contains -1 edges. Processing...\n",
      "Original edges count: 22\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 21\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890823862 contains -1 edges. Processing...\n",
      "Original edges count: 8\n",
      "Original nodes count: 10\n",
      "Filtered edges count: 7\n",
      "Filtered nodes count: 10\n",
      "Scene ID 1352890919792 contains -1 edges. Processing...\n",
      "Original edges count: 10\n",
      "Original nodes count: 11\n",
      "Filtered edges count: 9\n",
      "Filtered nodes count: 11\n",
      "Scene ID 1352890872601 contains -1 edges. Processing...\n",
      "Original edges count: 10\n",
      "Original nodes count: 10\n",
      "Filtered edges count: 4\n",
      "Filtered nodes count: 8\n",
      "Scene ID 1352890894888 contains -1 edges. Processing...\n",
      "Scene ID 135289091426 contains -1 edges. Processing...\n",
      "Original edges count: 7\n",
      "Original nodes count: 10\n",
      "Filtered edges count: 6\n",
      "Filtered nodes count: 10\n",
      "Scene ID 1352890919969 contains -1 edges. Processing...\n",
      "Original edges count: 26\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 25\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890835036 contains -1 edges. Processing...\n",
      "Original edges count: 15\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 12\n",
      "Filtered nodes count: 14\n",
      "Scene ID 1352890809912 contains -1 edges. Processing...\n",
      "Original edges count: 20\n",
      "Original nodes count: 12\n",
      "Filtered edges count: 19\n",
      "Filtered nodes count: 12\n",
      "Scene ID 135289080146 contains -1 edges. Processing...\n",
      "Scene ID 1352890833505 contains -1 edges. Processing...\n",
      "Original edges count: 5\n",
      "Original nodes count: 8\n",
      "Filtered edges count: 4\n",
      "Filtered nodes count: 8\n",
      "Scene ID 1352890895393 contains -1 edges. Processing...\n",
      "Original edges count: 16\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 15\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890838867 contains -1 edges. Processing...\n",
      "Scene ID 1352890833338 contains -1 edges. Processing...\n",
      "Original edges count: 20\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 16\n",
      "Filtered nodes count: 14\n",
      "Scene ID 1352890819768 contains -1 edges. Processing...\n",
      "Original edges count: 14\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 9\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890803216 contains -1 edges. Processing...\n",
      "Scene ID 1352890808433 contains -1 edges. Processing...\n",
      "Original edges count: 24\n",
      "Original nodes count: 12\n",
      "Filtered edges count: 23\n",
      "Filtered nodes count: 11\n",
      "Scene ID 1352890800052 contains -1 edges. Processing...\n",
      "Original edges count: 18\n",
      "Original nodes count: 15\n",
      "Filtered edges count: 17\n",
      "Filtered nodes count: 15\n",
      "Scene ID 1352890811475 contains -1 edges. Processing...\n",
      "Scene ID 1352890834655 contains -1 edges. Processing...\n",
      "Original edges count: 17\n",
      "Original nodes count: 14\n",
      "Filtered edges count: 13\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890814706 contains -1 edges. Processing...\n",
      "Scene ID 1352890837601 contains -1 edges. Processing...\n",
      "Scene ID 1352890808346 contains -1 edges. Processing...\n",
      "Original edges count: 18\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 17\n",
      "Filtered nodes count: 13\n",
      "Scene ID 1352890818385 contains -1 edges. Processing...\n",
      "Original edges count: 18\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 17\n",
      "Filtered nodes count: 12\n",
      "Scene ID 1352890838146 contains -1 edges. Processing...\n",
      "Original edges count: 25\n",
      "Original nodes count: 12\n",
      "Filtered edges count: 24\n",
      "Filtered nodes count: 11\n",
      "Scene ID 1352890800142 contains -1 edges. Processing...\n",
      "Original edges count: 5\n",
      "Original nodes count: 7\n",
      "Filtered edges count: 4\n",
      "Filtered nodes count: 7\n",
      "Scene ID 1352890851846 contains -1 edges. Processing...\n",
      "Scene ID 1352890837115 contains -1 edges. Processing...\n",
      "Scene ID 13528909148 contains -1 edges. Processing...\n",
      "Original edges count: 7\n",
      "Original nodes count: 10\n",
      "Filtered edges count: 6\n",
      "Filtered nodes count: 9\n",
      "Scene ID 1352890908102 contains -1 edges. Processing...\n",
      "Scene ID 1352890841295 contains -1 edges. Processing...\n",
      "Original edges count: 9\n",
      "Original nodes count: 10\n",
      "Filtered edges count: 8\n",
      "Filtered nodes count: 10\n",
      "Scene ID 1352890870132 contains -1 edges. Processing...\n",
      "Scene ID 1352890837204 contains -1 edges. Processing...\n",
      "Scene ID 1352890802191 contains -1 edges. Processing...\n",
      "Scene ID 1352890819948 contains -1 edges. Processing...\n",
      "Scene ID 1352890824206 contains -1 edges. Processing...\n",
      "Original edges count: 16\n",
      "Original nodes count: 13\n",
      "Filtered edges count: 15\n",
      "Filtered nodes count: 13\n",
      "Scene ID 135289081789 contains -1 edges. Processing...\n",
      "Original edges count: 7\n",
      "Original nodes count: 10\n",
      "Filtered edges count: 6\n",
      "Filtered nodes count: 10\n",
      "Scene ID 1352890910955 contains -1 edges. Processing...\n",
      "Loaded 193 scenes.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Title: GAT Regression for Pedestrian Future Position Prediction\n",
    "Description:\n",
    "    This script demonstrates how to use a Graph Attention Network (GAT)\n",
    "    for a regression task over pedestrian trajectory data.\n",
    "\n",
    "    Each scene is treated as a separate graph. The nodes represent\n",
    "    pedestrians with features (e.g. current position, previous motion, etc.)\n",
    "    and the edges represent interactions (or connectivity) between them.\n",
    "\n",
    "    The model learns to predict the pedestrian's future position, namely\n",
    "    future_x and future_y one second ahead.\n",
    "\n",
    "Author: Your Name\n",
    "Date: 2025-04-13\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(2)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Data Loading and Preprocessing\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Define the dataset directory\n",
    "dataset_dir = \"dataset\"\n",
    "\n",
    "\n",
    "# Function to find all scene IDs in the dataset directory\n",
    "def find_all_scene_ids(dataset_dir):\n",
    "    scene_ids = []\n",
    "    for file in os.listdir(dataset_dir):\n",
    "        if file.endswith(\".edges\"):\n",
    "            scene_id = file.split(\".\")[0]\n",
    "            scene_ids.append(scene_id)\n",
    "    return scene_ids\n",
    "\n",
    "\n",
    "# Function to load all subgraphs for the found scene IDs\n",
    "def load_all_subgraphs(dataset_dir):\n",
    "    scene_ids = find_all_scene_ids(dataset_dir)\n",
    "    scenes = []\n",
    "\n",
    "    for scene_id in scene_ids:\n",
    "\n",
    "        edges_file = os.path.join(dataset_dir, f\"{scene_id}.edges\")\n",
    "        nodes_file = os.path.join(dataset_dir, f\"{scene_id}.nodes\")\n",
    "\n",
    "        # Check if both files exist\n",
    "        if not os.path.exists(edges_file) or not os.path.exists(nodes_file):\n",
    "            print(f\"Skipping scene ID {scene_id}: Missing files.\")\n",
    "            continue\n",
    "\n",
    "        # Load edges\n",
    "        edges = pd.read_csv(edges_file, sep=\",\", header=None, names=[\"target\", \"source\"])\n",
    "\n",
    "        # Load nodes\n",
    "        nodes = pd.read_csv(\n",
    "            nodes_file,\n",
    "            sep=\",\",\n",
    "            header=None,\n",
    "            names=[\"node_id\", \"current_x\", \"current_y\", \"previous_x\", \"previous_y\", \"future_x\", \"future_y\"],\n",
    "        )\n",
    "\n",
    "        for col in nodes.columns:\n",
    "            nodes[col] = pd.to_numeric(nodes[col], errors=\"coerce\")\n",
    "\n",
    "        if nodes.isnull().any().any():\n",
    "            # Step 1: Identify rows with NaN values in nodes_df\n",
    "            nan_nodes = nodes[nodes.isnull().any(axis=1)]\n",
    "\n",
    "            # Step 2: Extract the node_id values of those rows\n",
    "            nan_node_ids = nan_nodes[\"node_id\"].tolist()\n",
    "\n",
    "            # Step 3: Filter out edges in edges_df where source or target is in nan_node_ids\n",
    "            # Display the filtered edges\n",
    "            print(f\"Original edges count: {len(edges)}\")\n",
    "            print(f\"Original nodes count: {len(nodes)}\")\n",
    "            edges = edges[~edges[\"source\"].isin(nan_node_ids) & ~edges[\"target\"].isin(nan_node_ids)]\n",
    "\n",
    "            print(f\"Filtered edges count: {len(edges)}\")\n",
    "            nodes = nodes.dropna(subset=[\"future_x\", \"future_y\"])\n",
    "            print(f\"Filtered nodes count: {len(nodes)}\")\n",
    "\n",
    "        # # Filter out edges with -1 as source value\n",
    "        # edges = edges[edges[\"source\"] != -1]\n",
    "\n",
    "        # Check if there are any -1 edges\n",
    "        if (edges[\"source\"] == -1).any() or (edges[\"target\"] == -1).any():\n",
    "            print(f\"Scene ID {scene_id} contains -1 edges. Processing...\")\n",
    "\n",
    "            # Remove edges with -1 as source or target\n",
    "            edges = edges[(edges[\"source\"] != -1) & (edges[\"target\"] != -1)]\n",
    "\n",
    "            # Get unique node IDs from the remaining edges\n",
    "            connected_nodes = pd.unique(edges[[\"target\", \"source\"]].values.ravel())\n",
    "\n",
    "            # Filter nodes to keep only those that are connected\n",
    "            nodes = nodes[nodes[\"node_id\"].isin(connected_nodes)]\n",
    "\n",
    "        # Store the subgraph\n",
    "        scenes.append(\n",
    "            {\"scene_id\": scene_id, \"edges\": edges, \"nodes\": nodes},\n",
    "        )\n",
    "\n",
    "    return scenes\n",
    "\n",
    "\n",
    "# Example usage\n",
    "scenes = load_all_subgraphs(dataset_dir)\n",
    "print(f\"Loaded {len(scenes)} scenes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5595e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_scenes(scenes):\n",
    "    nodes_list = []\n",
    "    edges_list = []\n",
    "    scene_node_indices = {}\n",
    "    node_offset = 0\n",
    "\n",
    "    for scene in scenes:\n",
    "        scene_id = scene[\"scene_id\"]\n",
    "        nodes_df = scene[\"nodes\"].copy().reset_index(drop=True)\n",
    "        edges_df = scene[\"edges\"].copy().reset_index(drop=True)\n",
    "        num_nodes = nodes_df.shape[0]\n",
    "        scene_node_indices[scene_id] = np.arange(node_offset, node_offset + num_nodes)\n",
    "\n",
    "        # Map original node_id to aggregated index.\n",
    "        node_id_to_index = dict(zip(nodes_df[\"node_id\"], range(node_offset, node_offset + num_nodes)))\n",
    "        edges_df[\"target\"] = edges_df[\"target\"].apply(lambda x: node_id_to_index.get(x, -1))\n",
    "        edges_df[\"source\"] = edges_df[\"source\"].apply(lambda x: node_id_to_index.get(x, -1))\n",
    "        edges_df = edges_df[(edges_df[\"target\"] != -1) & (edges_df[\"source\"] != -1)]\n",
    "        nodes_list.append(nodes_df)\n",
    "        edges_list.append(edges_df)\n",
    "        node_offset += num_nodes\n",
    "\n",
    "    all_nodes = pd.concat(nodes_list, ignore_index=True)\n",
    "    all_edges = pd.concat(edges_list, ignore_index=True).to_numpy().astype(np.int32)\n",
    "    return all_nodes, all_edges, scene_node_indices\n",
    "\n",
    "\n",
    "def scene_based_split(scene_node_indices, train_ratio=0.5):\n",
    "    scene_ids = np.array(list(scene_node_indices.keys()))\n",
    "    np.random.shuffle(scene_ids)\n",
    "    n_train = int(len(scene_ids) * train_ratio)\n",
    "    train_scenes = scene_ids[:n_train]\n",
    "    test_scenes = scene_ids[n_train:]\n",
    "    train_indices = np.concatenate([scene_node_indices[sid] for sid in train_scenes])\n",
    "    test_indices = np.concatenate([scene_node_indices[sid] for sid in test_scenes])\n",
    "    return train_indices, test_indices\n",
    "\n",
    "\n",
    "def create_train_val_split(train_indices, val_ratio=0.1):\n",
    "    # Randomly split the train_indices into training and validation sets.\n",
    "    np.random.shuffle(train_indices)\n",
    "    n_val = int(len(train_indices) * val_ratio)\n",
    "    val_indices = train_indices[:n_val]\n",
    "    train_indices_new = train_indices[n_val:]\n",
    "    return train_indices_new, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f46f113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# GAT Model Components for Regression\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class GraphAttention(layers.Layer):\n",
    "    def __init__(self, units, kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(input_shape[0][-1], self.units),\n",
    "            trainable=True,\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            name=\"kernel\",\n",
    "        )\n",
    "        self.kernel_attention = self.add_weight(\n",
    "            shape=(self.units * 2, 1),\n",
    "            trainable=True,\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            name=\"kernel_attention\",\n",
    "        )\n",
    "        self.built = True  # Original\n",
    "\n",
    "    def call(self, inputs):\n",
    "        node_states, edges = inputs\n",
    "        node_states_transformed = tf.matmul(node_states, self.kernel)\n",
    "        target_states = tf.gather(node_states_transformed, edges[:, 0])\n",
    "        source_states = tf.gather(node_states_transformed, edges[:, 1])\n",
    "        concat_features = tf.concat([target_states, source_states], axis=-1)\n",
    "        e = tf.nn.leaky_relu(tf.matmul(concat_features, self.kernel_attention))\n",
    "        e = tf.squeeze(e, axis=-1)\n",
    "        e = tf.exp(tf.clip_by_value(e, -2, 2))\n",
    "        sum_e = tf.math.unsorted_segment_sum(e, edges[:, 0], num_segments=tf.shape(node_states)[0])\n",
    "        sum_e_rep = tf.gather(sum_e, edges[:, 0])\n",
    "        attention = e / (sum_e_rep + 1e-9)\n",
    "        source_transformed = tf.gather(node_states_transformed, edges[:, 1])\n",
    "        messages = source_transformed * tf.expand_dims(attention, -1)\n",
    "        output = tf.math.unsorted_segment_sum(messages, edges[:, 0], num_segments=tf.shape(node_states)[0])\n",
    "        return output\n",
    "\n",
    "\n",
    "class MultiHeadGraphAttention(layers.Layer):\n",
    "    def __init__(self, units, num_heads=8, merge_type=\"concat\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.merge_type = merge_type\n",
    "        self.attention_layers = [GraphAttention(units) for _ in range(num_heads)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        node_states, edges = inputs\n",
    "        head_outputs = [att([node_states, edges]) for att in self.attention_layers]\n",
    "        if self.merge_type == \"concat\":\n",
    "            output = tf.concat(head_outputs, axis=-1)\n",
    "        else:\n",
    "            output = tf.reduce_mean(tf.stack(head_outputs, axis=-1), axis=-1)\n",
    "        return tf.nn.relu(output)\n",
    "\n",
    "\n",
    "class GraphAttentionNetwork(keras.Model):\n",
    "    def __init__(self, node_states, edges, hidden_units, num_heads, num_layers, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.node_states = node_states\n",
    "        self.edges = edges\n",
    "        self.preprocess = layers.Dense(hidden_units * num_heads, activation=\"relu\")\n",
    "        self.attention_layers = [MultiHeadGraphAttention(hidden_units, num_heads) for _ in range(num_layers)]\n",
    "        self.output_layer = layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, _=None):\n",
    "        x = self.preprocess(self.node_states)\n",
    "        for att_layer in self.attention_layers:\n",
    "            x = att_layer([x, self.edges]) + x  # residual connection\n",
    "        return self.output_layer(x)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        indices, labels = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            # outputs = self([None])\n",
    "            outputs = self()\n",
    "            predictions = tf.gather(outputs, indices)\n",
    "            loss = self.compiled_loss(labels, predictions, regularization_losses=self.losses)\n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(labels, predictions)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results[\"loss\"] = loss\n",
    "        return results\n",
    "\n",
    "    def test_step(self, data):\n",
    "        indices, labels = data\n",
    "        outputs = self([None])\n",
    "        predictions = tf.gather(outputs, indices)\n",
    "        loss = self.compiled_loss(labels, predictions, regularization_losses=self.losses)\n",
    "        self.compiled_metrics.update_state(labels, predictions)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results[\"loss\"] = loss\n",
    "        return results\n",
    "\n",
    "    def predict_step(self, data):\n",
    "        outputs = self([None])\n",
    "        predictions = tf.gather(outputs, data)\n",
    "        return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fecefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated nodes shape: (1669, 4)\n",
      "Aggregated edges shape: (2721, 2)\n",
      "Training nodes: (1205,) Validation nodes: (133,) Test nodes: (331,)\n",
      "Training...\n",
      "Epoch 1/100\n",
      "76/76 - 17s - 225ms/step - mean_absolute_error: 2206.8406 - mean_squared_error: 11119790.0000 - r2_score: 0.8192 - loss: 17037722.0000 - val_loss: 67074848.0000 - learning_rate: 0.0100\n",
      "Epoch 2/100\n",
      "76/76 - 8s - 109ms/step - mean_absolute_error: 1154.2870 - mean_squared_error: 2457567.0000 - r2_score: 0.9614 - loss: 2500720.5000 - val_loss: 1525053.7500 - learning_rate: 0.0100\n",
      "Epoch 3/100\n",
      "76/76 - 10s - 131ms/step - mean_absolute_error: 707.5989 - mean_squared_error: 944168.9375 - r2_score: 0.9863 - loss: 1688120.6250 - val_loss: 487349.5625 - learning_rate: 0.0100\n",
      "Epoch 4/100\n",
      "76/76 - 12s - 158ms/step - mean_absolute_error: 651.5798 - mean_squared_error: 764235.2500 - r2_score: 0.9899 - loss: 180539.3594 - val_loss: 383879.5312 - learning_rate: 0.0100\n",
      "Epoch 5/100\n",
      "76/76 - 13s - 169ms/step - mean_absolute_error: 665.3077 - mean_squared_error: 2342685.2500 - r2_score: 0.9825 - loss: 580856.6250 - val_loss: 27728644.0000 - learning_rate: 0.0100\n",
      "Epoch 6/100\n",
      "76/76 - 12s - 162ms/step - mean_absolute_error: 746.4586 - mean_squared_error: 1177717.0000 - r2_score: 0.9854 - loss: 464893.0000 - val_loss: 8998718.0000 - learning_rate: 0.0100\n",
      "Epoch 7/100\n",
      "76/76 - 12s - 164ms/step - mean_absolute_error: 558.3000 - mean_squared_error: 443702.0625 - r2_score: 0.9935 - loss: 804478.1250 - val_loss: 369924.4375 - learning_rate: 0.0100\n",
      "Epoch 8/100\n",
      "76/76 - 14s - 189ms/step - mean_absolute_error: 566.1633 - mean_squared_error: 610851.3750 - r2_score: 0.9925 - loss: 301220.5000 - val_loss: 2217606.5000 - learning_rate: 0.0100\n",
      "Epoch 9/100\n",
      "76/76 - 12s - 157ms/step - mean_absolute_error: 609.8769 - mean_squared_error: 503832.1250 - r2_score: 0.9926 - loss: 277344.4688 - val_loss: 612787.1250 - learning_rate: 0.0100\n",
      "Epoch 10/100\n",
      "76/76 - 11s - 151ms/step - mean_absolute_error: 453.4007 - mean_squared_error: 323021.2188 - r2_score: 0.9956 - loss: 344575.8125 - val_loss: 167870.1250 - learning_rate: 0.0100\n",
      "Epoch 11/100\n",
      "76/76 - 12s - 153ms/step - mean_absolute_error: 656.0944 - mean_squared_error: 689743.1875 - r2_score: 0.9899 - loss: 247427.5000 - val_loss: 3790926.5000 - learning_rate: 0.0100\n",
      "Epoch 12/100\n",
      "76/76 - 12s - 158ms/step - mean_absolute_error: 582.2491 - mean_squared_error: 548034.8750 - r2_score: 0.9900 - loss: 279237.1875 - val_loss: 512942.0625 - learning_rate: 0.0100\n",
      "Epoch 13/100\n",
      "76/76 - 12s - 159ms/step - mean_absolute_error: 506.3992 - mean_squared_error: 348766.3750 - r2_score: 0.9951 - loss: 348924.7812 - val_loss: 441268.4375 - learning_rate: 0.0100\n",
      "Epoch 14/100\n",
      "76/76 - 12s - 157ms/step - mean_absolute_error: 779.7860 - mean_squared_error: 919622.6250 - r2_score: 0.9862 - loss: 248810.0938 - val_loss: 781481.1875 - learning_rate: 0.0100\n",
      "Epoch 15/100\n",
      "76/76 - 12s - 159ms/step - mean_absolute_error: 474.2029 - mean_squared_error: 312019.3125 - r2_score: 0.9947 - loss: 280887.9688 - val_loss: 537337.3125 - learning_rate: 0.0100\n",
      "Epoch 16/100\n",
      "76/76 - 12s - 153ms/step - mean_absolute_error: 628.4841 - mean_squared_error: 4069584.0000 - r2_score: 0.9075 - loss: 61818.2070 - val_loss: 46563500.0000 - learning_rate: 0.0100\n",
      "Epoch 17/100\n",
      "76/76 - 11s - 150ms/step - mean_absolute_error: 490.5388 - mean_squared_error: 428535.8750 - r2_score: 0.9947 - loss: 500277.1562 - val_loss: 360761.9062 - learning_rate: 0.0100\n",
      "Epoch 18/100\n",
      "76/76 - 12s - 164ms/step - mean_absolute_error: 832.5347 - mean_squared_error: 1158149.0000 - r2_score: 0.9883 - loss: 227978.6719 - val_loss: 5132791.0000 - learning_rate: 0.0100\n",
      "Epoch 19/100\n",
      "76/76 - 11s - 151ms/step - mean_absolute_error: 451.7348 - mean_squared_error: 561889.3125 - r2_score: 0.9946 - loss: 281678.4062 - val_loss: 3448481.5000 - learning_rate: 0.0100\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "76/76 - 12s - 157ms/step - mean_absolute_error: 546.6887 - mean_squared_error: 439428.0000 - r2_score: 0.9919 - loss: 321629.8438 - val_loss: 359327.8750 - learning_rate: 0.0100\n",
      "Epoch 21/100\n",
      "76/76 - 11s - 148ms/step - mean_absolute_error: 309.1373 - mean_squared_error: 160066.7344 - r2_score: 0.9977 - loss: 216135.1562 - val_loss: 168388.4062 - learning_rate: 1.0000e-03\n",
      "Epoch 22/100\n",
      "76/76 - 13s - 172ms/step - mean_absolute_error: 313.3204 - mean_squared_error: 155423.7188 - r2_score: 0.9977 - loss: 169344.3750 - val_loss: 71232.4766 - learning_rate: 1.0000e-03\n",
      "Epoch 23/100\n",
      "76/76 - 12s - 164ms/step - mean_absolute_error: 301.0262 - mean_squared_error: 149051.8125 - r2_score: 0.9978 - loss: 56220.1484 - val_loss: 58816.6797 - learning_rate: 1.0000e-03\n",
      "Epoch 24/100\n",
      "76/76 - 12s - 153ms/step - mean_absolute_error: 325.1047 - mean_squared_error: 159491.1875 - r2_score: 0.9978 - loss: 158681.9219 - val_loss: 55814.1992 - learning_rate: 1.0000e-03\n",
      "Epoch 25/100\n",
      "76/76 - 12s - 156ms/step - mean_absolute_error: 292.2480 - mean_squared_error: 142190.0938 - r2_score: 0.9979 - loss: 142505.5312 - val_loss: 50289.0820 - learning_rate: 1.0000e-03\n",
      "Epoch 26/100\n",
      "76/76 - 12s - 152ms/step - mean_absolute_error: 289.2285 - mean_squared_error: 139640.8750 - r2_score: 0.9979 - loss: 103760.7344 - val_loss: 71210.1719 - learning_rate: 1.0000e-03\n",
      "Epoch 27/100\n",
      "76/76 - 11s - 150ms/step - mean_absolute_error: 292.7551 - mean_squared_error: 137205.7344 - r2_score: 0.9980 - loss: 366027.9375 - val_loss: 51162.7500 - learning_rate: 1.0000e-03\n",
      "Epoch 28/100\n",
      "76/76 - 12s - 155ms/step - mean_absolute_error: 275.7053 - mean_squared_error: 132280.7812 - r2_score: 0.9981 - loss: 226167.7500 - val_loss: 46407.9453 - learning_rate: 1.0000e-03\n",
      "Epoch 29/100\n",
      "76/76 - 12s - 161ms/step - mean_absolute_error: 281.1032 - mean_squared_error: 131574.8438 - r2_score: 0.9981 - loss: 232467.4688 - val_loss: 39177.6797 - learning_rate: 1.0000e-03\n",
      "Epoch 30/100\n",
      "76/76 - 12s - 155ms/step - mean_absolute_error: 307.3688 - mean_squared_error: 145106.6875 - r2_score: 0.9978 - loss: 151490.6406 - val_loss: 64591.2578 - learning_rate: 1.0000e-03\n",
      "Epoch 31/100\n",
      "76/76 - 12s - 161ms/step - mean_absolute_error: 301.4315 - mean_squared_error: 138716.8906 - r2_score: 0.9981 - loss: 112268.9531 - val_loss: 47476.6992 - learning_rate: 1.0000e-03\n",
      "Epoch 32/100\n",
      "76/76 - 13s - 165ms/step - mean_absolute_error: 283.2682 - mean_squared_error: 128207.7422 - r2_score: 0.9981 - loss: 108341.7891 - val_loss: 42269.3398 - learning_rate: 1.0000e-03\n",
      "Epoch 33/100\n",
      "76/76 - 12s - 154ms/step - mean_absolute_error: 284.0265 - mean_squared_error: 133038.6719 - r2_score: 0.9980 - loss: 120113.3516 - val_loss: 55557.2695 - learning_rate: 1.0000e-03\n",
      "Epoch 34/100\n",
      "76/76 - 12s - 152ms/step - mean_absolute_error: 267.1429 - mean_squared_error: 120417.8281 - r2_score: 0.9983 - loss: 158431.3750 - val_loss: 41167.0117 - learning_rate: 1.0000e-03\n",
      "Epoch 35/100\n",
      "76/76 - 11s - 149ms/step - mean_absolute_error: 273.3958 - mean_squared_error: 121879.4922 - r2_score: 0.9982 - loss: 173659.1719 - val_loss: 51882.5586 - learning_rate: 1.0000e-03\n",
      "Epoch 36/100\n",
      "76/76 - 11s - 147ms/step - mean_absolute_error: 269.3481 - mean_squared_error: 126228.8438 - r2_score: 0.9981 - loss: 73877.8281 - val_loss: 59414.7188 - learning_rate: 1.0000e-03\n",
      "Epoch 37/100\n",
      "76/76 - 11s - 150ms/step - mean_absolute_error: 256.2184 - mean_squared_error: 118015.3281 - r2_score: 0.9983 - loss: 58486.8242 - val_loss: 50367.9805 - learning_rate: 1.0000e-03\n",
      "Epoch 38/100\n",
      "76/76 - 11s - 149ms/step - mean_absolute_error: 272.2718 - mean_squared_error: 120818.4141 - r2_score: 0.9982 - loss: 182036.7500 - val_loss: 43836.8750 - learning_rate: 1.0000e-03\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "76/76 - 12s - 154ms/step - mean_absolute_error: 264.6685 - mean_squared_error: 115406.5547 - r2_score: 0.9984 - loss: 95390.5547 - val_loss: 54945.7383 - learning_rate: 1.0000e-03\n",
      "Epoch 40/100\n",
      "76/76 - 11s - 150ms/step - mean_absolute_error: 260.0895 - mean_squared_error: 111570.8438 - r2_score: 0.9984 - loss: 164620.0469 - val_loss: 45411.3203 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "76/76 - 12s - 154ms/step - mean_absolute_error: 263.1826 - mean_squared_error: 112152.4844 - r2_score: 0.9984 - loss: 162361.2031 - val_loss: 39112.1641 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "76/76 - 13s - 168ms/step - mean_absolute_error: 256.1574 - mean_squared_error: 109110.4609 - r2_score: 0.9984 - loss: 81215.4766 - val_loss: 38647.0391 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "76/76 - 12s - 159ms/step - mean_absolute_error: 255.2354 - mean_squared_error: 109016.6016 - r2_score: 0.9984 - loss: 226490.8438 - val_loss: 39679.0977 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "76/76 - 13s - 172ms/step - mean_absolute_error: 266.6144 - mean_squared_error: 113647.8672 - r2_score: 0.9984 - loss: 197394.4844 - val_loss: 38424.7734 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "76/76 - 12s - 164ms/step - mean_absolute_error: 254.2299 - mean_squared_error: 108252.3125 - r2_score: 0.9984 - loss: 101946.1797 - val_loss: 37155.6133 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "76/76 - 12s - 164ms/step - mean_absolute_error: 255.8585 - mean_squared_error: 108991.7266 - r2_score: 0.9984 - loss: 162282.8750 - val_loss: 39800.8203 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "76/76 - 12s - 164ms/step - mean_absolute_error: 255.2773 - mean_squared_error: 107924.1484 - r2_score: 0.9985 - loss: 98254.4531 - val_loss: 36585.5664 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "76/76 - 13s - 174ms/step - mean_absolute_error: 254.6833 - mean_squared_error: 107975.0703 - r2_score: 0.9985 - loss: 122694.7969 - val_loss: 37562.6484 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "76/76 - 14s - 190ms/step - mean_absolute_error: 249.8538 - mean_squared_error: 106287.7344 - r2_score: 0.9985 - loss: 121571.0234 - val_loss: 39199.4102 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "76/76 - 13s - 177ms/step - mean_absolute_error: 251.7799 - mean_squared_error: 106652.5156 - r2_score: 0.9985 - loss: 77040.4297 - val_loss: 38051.4922 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "76/76 - 13s - 166ms/step - mean_absolute_error: 253.1583 - mean_squared_error: 107336.8203 - r2_score: 0.9985 - loss: 43822.8242 - val_loss: 38279.9961 - learning_rate: 1.0000e-04\n",
      "Epoch 52/100\n",
      "76/76 - 13s - 177ms/step - mean_absolute_error: 248.8894 - mean_squared_error: 105688.8984 - r2_score: 0.9985 - loss: 168732.9219 - val_loss: 38415.8516 - learning_rate: 1.0000e-04\n",
      "Epoch 53/100\n",
      "76/76 - 14s - 191ms/step - mean_absolute_error: 261.3491 - mean_squared_error: 110560.6250 - r2_score: 0.9985 - loss: 195628.0625 - val_loss: 35653.7109 - learning_rate: 1.0000e-04\n",
      "Epoch 54/100\n",
      "76/76 - 13s - 177ms/step - mean_absolute_error: 248.8489 - mean_squared_error: 105827.2422 - r2_score: 0.9985 - loss: 222349.4688 - val_loss: 40417.3438 - learning_rate: 1.0000e-04\n",
      "Epoch 55/100\n",
      "76/76 - 13s - 168ms/step - mean_absolute_error: 253.5168 - mean_squared_error: 106070.9844 - r2_score: 0.9985 - loss: 72471.0312 - val_loss: 34527.1445 - learning_rate: 1.0000e-04\n",
      "Epoch 56/100\n",
      "76/76 - 13s - 169ms/step - mean_absolute_error: 242.8747 - mean_squared_error: 104850.1406 - r2_score: 0.9985 - loss: 103935.5781 - val_loss: 41172.6641 - learning_rate: 1.0000e-04\n",
      "Epoch 57/100\n",
      "76/76 - 13s - 173ms/step - mean_absolute_error: 251.9662 - mean_squared_error: 106155.0078 - r2_score: 0.9985 - loss: 22977.0156 - val_loss: 36489.9922 - learning_rate: 1.0000e-04\n",
      "Epoch 58/100\n",
      "76/76 - 14s - 178ms/step - mean_absolute_error: 259.6261 - mean_squared_error: 109411.3594 - r2_score: 0.9985 - loss: 16732.9414 - val_loss: 38174.8047 - learning_rate: 1.0000e-04\n",
      "Epoch 59/100\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Main: Data Preparation, Model Training, and Evaluation\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_nodes, all_edges, scene_node_indices = aggregate_scenes(scenes)\n",
    "    train_indices, test_indices = scene_based_split(scene_node_indices, train_ratio=0.8)\n",
    "    # Create a validation set from the training nodes (e.g., 10% of training nodes)\n",
    "    train_indices, val_indices = create_train_val_split(train_indices, val_ratio=0.1)\n",
    "\n",
    "    # Define features and targets\n",
    "    feature_cols = [col for col in all_nodes.columns if col not in [\"node_id\", \"future_x\", \"future_y\"]]\n",
    "    target_cols = [\"future_x\", \"future_y\"]\n",
    "    node_features_np = all_nodes[feature_cols].to_numpy().astype(np.float32)\n",
    "    targets_np = all_nodes[target_cols].to_numpy().astype(np.float32)\n",
    "\n",
    "    print(\"Aggregated nodes shape:\", node_features_np.shape)\n",
    "    print(\"Aggregated edges shape:\", all_edges.shape)\n",
    "    print(\n",
    "        \"Training nodes:\",\n",
    "        train_indices.shape,\n",
    "        \"Validation nodes:\",\n",
    "        val_indices.shape,\n",
    "        \"Test nodes:\",\n",
    "        test_indices.shape,\n",
    "    )\n",
    "\n",
    "    node_features_tensor = tf.convert_to_tensor(node_features_np)\n",
    "    edges_tensor = tf.convert_to_tensor(all_edges)\n",
    "\n",
    "    # Define hyper-parameters\n",
    "    HIDDEN_UNITS = 100\n",
    "    NUM_HEADS = 8\n",
    "    NUM_LAYERS = 3\n",
    "    OUTPUT_DIM = 2  # future_x and future_y\n",
    "    NUM_EPOCHS = 100\n",
    "    BATCH_SIZE = 16\n",
    "    LEARNING_RATE = 1e-2\n",
    "\n",
    "    # Build the model\n",
    "    gat_model = GraphAttentionNetwork(\n",
    "        node_states=node_features_tensor,\n",
    "        edges=edges_tensor,\n",
    "        hidden_units=HIDDEN_UNITS,\n",
    "        num_heads=NUM_HEADS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        output_dim=OUTPUT_DIM,\n",
    "    )\n",
    "\n",
    "    # Compile the model with MSE for loss and MAE as a metric.\n",
    "    gat_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        metrics=[\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "            keras.metrics.MeanSquaredError(),\n",
    "            keras.metrics.R2Score(),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Prepare tf.data.Datasets for training, validation, and testing.\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_indices, targets_np[train_indices]))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=len(train_indices)).batch(BATCH_SIZE)\n",
    "\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_indices, targets_np[val_indices]))\n",
    "    val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_indices, targets_np[test_indices]))\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    # Set up callbacks: ReduceLROnPlateau and EarlyStopping.\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.1,\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        min_delta=0.0001,\n",
    "        cooldown=0,\n",
    "        min_lr=0.0,\n",
    "    )\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    print(\"Training...\")\n",
    "    gat_model.fit(\n",
    "        train_dataset,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        validation_data=val_dataset,\n",
    "        callbacks=[reduce_lr, early_stopping],\n",
    "        verbose=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating on test set...\")\n",
    "results = gat_model.evaluate(test_dataset, verbose=2)\n",
    "print(f\"\\nTest Loss (MSE): {results[0]:.4f}, Test MAE: {results[1][\"mean_absolute_error\"]:.4f}\")\n",
    "\n",
    "# Run predictions on test nodes\n",
    "print(\"\\nSample predictions for test nodes:\")\n",
    "predictions = gat_model.predict(tf.convert_to_tensor(test_indices))\n",
    "for i, idx in enumerate(test_indices[:5]):\n",
    "    print(\n",
    "        f\"Node {idx}: True future_x={targets_np[idx,0]:.1f}, future_y={targets_np[idx,1]:.1f} | Predicted future_x={predictions[i,0]:.1f}, future_y={predictions[i,1]:.1f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
