{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e788c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 16:08:21.375976: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import glob\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 6)\n",
    "pd.set_option(\"display.max_rows\", 6)\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ca19b",
   "metadata": {},
   "source": [
    "## Load the data and process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "427efbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total scenes: 193\n",
      "Training scenes: 135\n",
      "Validation scenes: 38\n",
      "Test scenes: 20\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "As in the tutorial, the provided dataset consists of two files for each traffic scene:\n",
    "\n",
    "<scene_id>.edges\n",
    "two columns containing node IDs\n",
    "target, source\n",
    "Note: The tutorial models directed edges with source -> target.\n",
    "You can either use undirected edges by changing the implementation or adding the missing entries to the edges file,\n",
    "e.g., to the line target, source, you add the line source target. If you want to be more fancy, you could also try to infer\n",
    "which other pedestrians the source node can see in their field of view and only add those (this would model that the movement\n",
    "decisions are based only on the pedestrians in the field of view.)\n",
    "<scene_id>.nodes\n",
    "seven columns with node properties and target values, which should be predicted \n",
    "node id, current x, current y, previous x, previous y, future x, future y\n",
    "the previous x and y represents the location of the pedestrian 1 second ago (you can use those values directly or infer the\n",
    "movement direction and some speed estimate yourself)\n",
    "the future x and y represents the target value, i.e., the location where the pedestrian will be in 1 second\n",
    "Note: Some pedestrians do not have a future x and y coordinate, so you need to filter those for prediction. However, you can\n",
    "still use their current and previous location when predicting the future location of other pedestrians.\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Sample data: \n",
    "file: dataset/13528908058.edges:\n",
    "contains data: target, source\n",
    "19585800, 19590700\n",
    "19585800, 19595200\n",
    "19585800, 20000100\n",
    "19590700, 19595200\n",
    "19590700, 20000100\n",
    "19591900, 19594200\n",
    "19591900, 19595300\n",
    "19591900, 19595800\n",
    "19592201, 19595800\n",
    "19592400, 20000200\n",
    "19592800, 20000200\n",
    "19592800, 20000300\n",
    "19594200, 19595300\n",
    "19594200, 19595800\n",
    "19595200, 20000100\n",
    "19595300, 19595800\n",
    "20000200, 20000300\n",
    "19502500, -1\n",
    "\n",
    "corresponding nodes file: \n",
    "file: dataset/13528908058.nodes\n",
    "contains data: node id, current x, current y, previous x, previous y, future x, future y\n",
    "19502500,40050.0,-16544.0,40176.0,-16619.0,40205.0,-16357.0\n",
    "19585800,16802.0,-11108.0,16140.0,-10573.0,17831.0,-11792.0\n",
    "19590700,16846.0,-10526.0,16079.0,-9694.0,17528.0,-11131.0\n",
    "19591900,11346.0,-6253.0,10833.0,-5840.0,12184.0,-6936.0\n",
    "19592201,14232.0,-8556.0,13610.0,-7856.0,14867.0,-9359.0\n",
    "19592400,5649.0,191.0,6542.0,-779.0,4809.0,1245.0\n",
    "19592800,9097.0,1278.0,9323.0,1412.0,9221.0,1551.0\n",
    "19594200,11262.0,-5387.0,10468.0,-4863.0,12387.0,-6358.0\n",
    "19595200,18425.0,-11390.0,17495.0,-10254.0,20034.0,-12398.0\n",
    "19595300,11060.0,-5800.0,10335.0,-5510.0,11890.0,-6411.0\n",
    "19595800,12432.0,-7962.0,_,_,12267.0,-7515.0\n",
    "20000100,18149.0,-10095.0,18159.0,-9697.0,17792.0,-10597.0\n",
    "20000200,7989.0,-70.0,7759.0,1511.0,8475.0,-1480.0\n",
    "20000300,8677.0,41.0,8353.0,1315.0,9280.0,-1068.0\n",
    "\"\"\" \n",
    "\n",
    "\"\"\"\n",
    "Sample data: \n",
    "file: dataset/13528908058.edges:\n",
    "contains data: target, source\n",
    "19585800, 19590700\n",
    "19585800, 19595200\n",
    "19585800, 20000100\n",
    "19590700, 19595200\n",
    "19590700, 20000100\n",
    "19591900, 19594200\n",
    "19591900, 19595300\n",
    "19591900, 19595800\n",
    "19592201, 19595800\n",
    "19592400, 20000200\n",
    "19592800, 20000200\n",
    "19592800, 20000300\n",
    "19594200, 19595300\n",
    "19594200, 19595800\n",
    "19595200, 20000100\n",
    "19595300, 19595800\n",
    "20000200, 20000300\n",
    "19502500, -1\n",
    "\n",
    "corresponding nodes file: \n",
    "file: dataset/13528908058.nodes\n",
    "contains data: node id, current x, current y, previous x, previous y, future x, future y\n",
    "19502500,40050.0,-16544.0,40176.0,-16619.0,40205.0,-16357.0\n",
    "19585800,16802.0,-11108.0,16140.0,-10573.0,17831.0,-11792.0\n",
    "19590700,16846.0,-10526.0,16079.0,-9694.0,17528.0,-11131.0\n",
    "19591900,11346.0,-6253.0,10833.0,-5840.0,12184.0,-6936.0\n",
    "19592201,14232.0,-8556.0,13610.0,-7856.0,14867.0,-9359.0\n",
    "19592400,5649.0,191.0,6542.0,-779.0,4809.0,1245.0\n",
    "19592800,9097.0,1278.0,9323.0,1412.0,9221.0,1551.0\n",
    "19594200,11262.0,-5387.0,10468.0,-4863.0,12387.0,-6358.0\n",
    "19595200,18425.0,-11390.0,17495.0,-10254.0,20034.0,-12398.0\n",
    "19595300,11060.0,-5800.0,10335.0,-5510.0,11890.0,-6411.0\n",
    "19595800,12432.0,-7962.0,_,_,12267.0,-7515.0\n",
    "20000100,18149.0,-10095.0,18159.0,-9697.0,17792.0,-10597.0\n",
    "20000200,7989.0,-70.0,7759.0,1511.0,8475.0,-1480.0\n",
    "20000300,8677.0,41.0,8353.0,1315.0,9280.0,-1068.0\n",
    "\"\"\" \n",
    "\n",
    "dataset_path = \"dataset/\"\n",
    "\n",
    "# Function to load all scenes while keeping each scene as a separate graph\n",
    "def load_all_scenes():\n",
    "    scene_ids = [file.split(\"/\")[-1].split(\".\")[0] for file in glob.glob(f\"{dataset_path}*.nodes\")]\n",
    "    \n",
    "    all_scenes = []\n",
    "    for scene_id in scene_ids:\n",
    "        edges_file = os.path.join(dataset_path, f\"{scene_id}.edges\")\n",
    "        nodes_file = os.path.join(dataset_path, f\"{scene_id}.nodes\")\n",
    "\n",
    "        edges_df = pd.read_csv(edges_file, header=None, names=[\"target\", \"source\"], na_values=\"_\")\n",
    "        nodes_df = pd.read_csv(\n",
    "            nodes_file,\n",
    "            header=None,\n",
    "            names=[\"node_id\", \"current_x\", \"current_y\", \"prev_x\", \"prev_y\", \"future_x\", \"future_y\"],\n",
    "            na_values=\"_\"\n",
    "        )\n",
    "        \n",
    "        # Convert \"_\" to NaN\n",
    "        nodes_df = nodes_df.replace('_', np.nan)\n",
    "        edges_df = edges_df.replace('_', np.nan)\n",
    "        \n",
    "        # Filter out nodes with missing future positions\n",
    "        nodes_df = nodes_df.dropna(subset=[\"future_x\", \"future_y\"])\n",
    "        \n",
    "        # Create mapping for node ids within this scene\n",
    "        node_id_to_index = {node_id: idx for idx, node_id in enumerate(nodes_df[\"node_id\"].values)}\n",
    "        \n",
    "        # Process edges using the node id mapping\n",
    "        edges_df = edges_df.dropna()\n",
    "        edges_df['target'] = edges_df['target'].apply(lambda x: node_id_to_index.get(x, -1))\n",
    "        edges_df['source'] = edges_df['source'].apply(lambda x: node_id_to_index.get(x, -1))\n",
    "        edges_df = edges_df[(edges_df['target'] != -1) & (edges_df['source'] != -1)]\n",
    "\n",
    "        # Calculate motion features\n",
    "        # nodes_df[\"dir_x\"] = nodes_df[\"current_x\"] - nodes_df[\"prev_x\"]\n",
    "        # nodes_df[\"dir_y\"] = nodes_df[\"current_y\"] - nodes_df[\"prev_y\"]\n",
    "        # nodes_df[\"speed\"] = np.sqrt(nodes_df[\"dir_x\"]**2 + nodes_df[\"dir_y\"]**2)\n",
    "        \n",
    "        # Extract features and labels\n",
    "        node_features = nodes_df[[\"current_x\", \"current_y\", \"prev_x\", \"prev_y\"]].values\n",
    "        labels = nodes_df[[\"future_x\", \"future_y\"]].values\n",
    "        edges = edges_df[[\"target\", \"source\"]].values\n",
    "        \n",
    "        # Store as a structured scene\n",
    "        all_scenes.append({\n",
    "            \"scene_id\": scene_id,\n",
    "            \"node_features\": tf.convert_to_tensor(node_features, dtype=tf.float32),\n",
    "            \"edges\": tf.convert_to_tensor(edges, dtype=tf.int32),\n",
    "            \"labels\": tf.convert_to_tensor(labels, dtype=tf.float32),\n",
    "            \"node_indices\": np.arange(len(nodes_df)),\n",
    "        })\n",
    "    \n",
    "    return all_scenes\n",
    "\n",
    "scenes = load_all_scenes()\n",
    "\n",
    "# np.random.seed(2)\n",
    "np.random.shuffle(scenes)\n",
    "\n",
    "\"\"\" Om man vill ha 70% Training set \"\"\"\n",
    "train_scenes = scenes[:int(0.7 * len(scenes))]\n",
    "val_scenes = scenes[int(0.7 * len(scenes)):int(0.9 * len(scenes))]\n",
    "test_scenes = scenes[int(0.9 * len(scenes)):]\n",
    "\n",
    "\"\"\" Om man vill ha 50% Training set \"\"\"\n",
    "# train_scenes = scenes[:int(0.5 * len(scenes))]\n",
    "# val_scenes = scenes[int(0.5 * len(scenes)):int(0.9 * len(scenes))]\n",
    "# test_scenes = scenes[int(0.9 * len(scenes)):]\n",
    "\n",
    "print(f\"Total scenes: {len(scenes)}\")\n",
    "print(f\"Training scenes: {len(train_scenes)}\")\n",
    "print(f\"Validation scenes: {len(val_scenes)}\")\n",
    "print(f\"Test scenes: {len(test_scenes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe26e544",
   "metadata": {},
   "source": [
    "## GAT model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b1d5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAttention(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        units,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        kernel_regularizer=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(input_shape[0][-1], self.units),\n",
    "            trainable=True,\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            name=\"kernel\",\n",
    "        )\n",
    "        self.kernel_attention = self.add_weight(\n",
    "            shape=(self.units * 2, 1),\n",
    "            trainable=True,\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            name=\"kernel_attention\",\n",
    "        )\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        node_states, edges = inputs\n",
    "\n",
    "        # Linearly transform node states\n",
    "        node_states_transformed = tf.matmul(node_states, self.kernel)\n",
    "\n",
    "        # (1) Compute pair-wise attention scores\n",
    "        node_states_expanded = tf.gather(node_states_transformed, edges)\n",
    "        node_states_expanded = tf.reshape(\n",
    "            node_states_expanded, (tf.shape(edges)[0], -1)\n",
    "        )\n",
    "        attention_scores = tf.nn.leaky_relu(\n",
    "            tf.matmul(node_states_expanded, self.kernel_attention)\n",
    "        )\n",
    "        attention_scores = tf.squeeze(attention_scores, -1)\n",
    "\n",
    "        # (2) Normalize attention scores\n",
    "        attention_scores = tf.math.exp(tf.clip_by_value(attention_scores, -2, 2))\n",
    "        attention_scores_sum = tf.math.unsorted_segment_sum(\n",
    "            data=attention_scores,\n",
    "            segment_ids=edges[:, 0],\n",
    "            num_segments=tf.reduce_max(edges[:, 0]) + 1,\n",
    "        )\n",
    "        attention_scores_sum = tf.repeat(\n",
    "            attention_scores_sum, tf.math.bincount(tf.cast(edges[:, 0], \"int32\"))\n",
    "        )\n",
    "        attention_scores_norm = attention_scores / attention_scores_sum\n",
    "\n",
    "        # (3) Gather node states of neighbors, apply attention scores and aggregate\n",
    "        node_states_neighbors = tf.gather(node_states_transformed, edges[:, 1])\n",
    "        out = tf.math.unsorted_segment_sum(\n",
    "            data=node_states_neighbors * attention_scores_norm[:, tf.newaxis],\n",
    "            segment_ids=edges[:, 0],\n",
    "            num_segments=tf.shape(node_states)[0],\n",
    "        )\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHeadGraphAttention(layers.Layer):\n",
    "    def __init__(self, units, num_heads=8, merge_type=\"concat\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.merge_type = merge_type\n",
    "        self.attention_layers = [GraphAttention(units) for _ in range(num_heads)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        atom_features, pair_indices = inputs\n",
    "\n",
    "        # Obtain outputs from each attention head\n",
    "        outputs = [\n",
    "            attention_layer([atom_features, pair_indices])\n",
    "            for attention_layer in self.attention_layers\n",
    "        ]\n",
    "        # Concatenate or average the node states from each head\n",
    "        if self.merge_type == \"concat\":\n",
    "            outputs = tf.concat(outputs, axis=-1)\n",
    "        else:\n",
    "            outputs = tf.reduce_mean(tf.stack(outputs, axis=-1), axis=-1)\n",
    "        # Activate and return node states\n",
    "        return tf.nn.relu(outputs)\n",
    "\n",
    "\n",
    "class GraphAttentionNetwork(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_states,\n",
    "        edges,\n",
    "        hidden_units,\n",
    "        num_heads,\n",
    "        num_layers,\n",
    "        output_dim,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.node_states = node_states\n",
    "        self.edges = edges\n",
    "        self.preprocess = layers.Dense(hidden_units * num_heads, activation=\"relu\")\n",
    "        self.attention_layers = [\n",
    "            MultiHeadGraphAttention(hidden_units, num_heads) for _ in range(num_layers)\n",
    "        ]\n",
    "        self.output_layer = layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        node_states, edges = inputs\n",
    "        x = self.preprocess(node_states)\n",
    "        for attention_layer in self.attention_layers:\n",
    "            x = attention_layer([x, edges]) + x\n",
    "        outputs = self.output_layer(x)\n",
    "        return outputs\n",
    "\n",
    "    def train_step(self, data):\n",
    "        indices, labels = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            outputs = self([self.node_states, self.edges])\n",
    "            # Compute loss\n",
    "            loss = self.compiled_loss(labels, tf.gather(outputs, indices))\n",
    "        # Compute gradients\n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        # Apply gradients (update weights)\n",
    "        optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        # Update metric(s)\n",
    "        self.compiled_metrics.update_state(labels, tf.gather(outputs, indices))\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def predict_step(self, data):\n",
    "        # indices = data\n",
    "        # # Forward pass\n",
    "        # outputs = self([self.node_states, self.edges])\n",
    "        # # Compute probabilities\n",
    "        # return tf.nn.softmax(tf.gather(outputs, indices))\n",
    "        indices = data\n",
    "        \n",
    "        outputs = self([self.node_states, self.edges])\n",
    "        return tf.gather(outputs, indices)\n",
    "\n",
    "    def test_step(self, data):\n",
    "        indices, labels = data\n",
    "        # Forward pass\n",
    "        outputs = self([self.node_states, self.edges])\n",
    "        # Compute loss\n",
    "        loss = self.compiled_loss(labels, tf.gather(outputs, indices))\n",
    "        # Update metric(s)\n",
    "        self.compiled_metrics.update_state(labels, tf.gather(outputs, indices))\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8d024f",
   "metadata": {},
   "source": [
    "## Test and evaluation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d8abcf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges:  tf.Tensor(\n",
      "[[ 0  9]\n",
      " [ 1 11]\n",
      " [ 2  3]\n",
      " [ 2  5]\n",
      " [ 2  6]\n",
      " [ 2 10]\n",
      " [ 3  5]\n",
      " [ 3  6]\n",
      " [ 3 10]\n",
      " [ 5  6]], shape=(10, 2), dtype=int32)\n",
      "node_states:  tf.Tensor(\n",
      "[[0.8478331  0.28035972 0.8478601  0.2801659 ]\n",
      " [0.7390847  0.08876313 0.7381145  0.08124346]\n",
      " [0.9218413  0.07608822 0.89852846 0.09841467]\n",
      " [0.912624   0.01845033 0.8942702  0.03449746]\n",
      " [0.01347564 1.         0.01732967 0.9844955 ]\n",
      " [0.9331339  0.09062367 0.90631735 0.1182604 ]\n",
      " [0.9389284  0.04961433 0.91248924 0.06938253]\n",
      " [0.96172917 0.20512423 0.92731243 0.2168301 ]\n",
      " [0.9600582  0.23252839 0.93394244 0.2434978 ]\n",
      " [0.8798512  0.22415598 0.85007006 0.21384549]], shape=(10, 4), dtype=float32)\n",
      "Training: 931 nodes\n",
      "Validation: 295 nodes\n",
      "Testing: 194 nodes\n",
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 628ms/step - mean_squared_error: 0.2627 - loss: 0.0701 - val_loss: 0.0703\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step - mean_squared_error: 0.2620 - loss: 0.0721 - val_loss: 0.0740\n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - mean_squared_error: 0.2539 - loss: 0.0776 - val_loss: 0.0776\n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - mean_squared_error: 0.2496 - loss: 0.0832 - val_loss: 0.0811\n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step - mean_squared_error: 0.2472 - loss: 0.0858 - val_loss: 0.0847\n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 179ms/step - mean_squared_error: 0.2443 - loss: 0.0866 - val_loss: 0.0882\n",
      "Epoch 7/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - mean_squared_error: 0.2468 - loss: 0.0917 - val_loss: 0.0916\n",
      "Epoch 8/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - mean_squared_error: 0.2392 - loss: 0.0973 - val_loss: 0.0950\n",
      "Epoch 9/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - mean_squared_error: 0.2349 - loss: 0.1005 - val_loss: 0.0983\n",
      "Epoch 10/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - mean_squared_error: 0.2327 - loss: 0.1005 - val_loss: 0.1016\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - mean_squared_error: 0.2359 - loss: 0.1025\n",
      "Test MSE: {'mean_squared_error': <tf.Tensor: shape=(), dtype=float32, numpy=0.24942957>}\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 449ms/step\n",
      "Warning: NaN values found in min_vals or max_vals\n",
      "min_vals: [0.00348609 0.        ]\n",
      "max_vals: [1.        0.9934591]\n",
      "Predictions vs Ground Truth (first 5):\n",
      "Pred: [0.52, 0.48], True: [1.00, 0.19]\n",
      "Pred: [0.52, 0.48], True: [0.88, 0.00]\n",
      "Pred: [0.53, 0.47], True: [0.84, 0.03]\n",
      "Pred: [0.53, 0.47], True: [0.72, 0.16]\n",
      "Pred: [0.47, 0.53], True: [0.75, 0.11]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define hyper-parameters\n",
    "HIDDEN_UNITS = 100\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 3\n",
    "OUTPUT_DIM = 2 # For position prediction, output_dim should be 2 (x and y coordinates)\n",
    "\n",
    "# The rest of your model definition and training code can remain the same\n",
    "# Just remember that you're now predicting continuous values (positions)\n",
    "# instead of class labels\n",
    "\n",
    "NUM_EPOCHS = 2\n",
    "BATCH_SIZE = 256\n",
    "VALIDATION_SPLIT = 0.2\n",
    "LEARNING_RATE = 1e-6\n",
    "\n",
    "# MOMENTUM = 0.9\n",
    "# loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# optimizer = keras.optimizers.SGD(LEARNING_RATE, momentum=MOMENTUM)\n",
    "# accuracy_fn = keras.metrics.SparseCategoricalAccuracy(name=\"acc\")\n",
    "\n",
    "\n",
    "loss_fn = keras.losses.MeanSquaredError(name=\"mean_squared_error\")\n",
    "optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE, \n",
    "    clipnorm=1.0,\n",
    "    epsilon=1e-8\n",
    ")\n",
    "accuracy_fn = keras.metrics.MeanSquaredError(name=\"mean_squared_error\")\n",
    "\n",
    "# Prepare data for training and testing\n",
    "# Let's use the scenes we've loaded earlier\n",
    "\n",
    "# Helper function to prepare data from scenes\n",
    "# Modified prepare_data_from_scenes function to handle NaN values\n",
    "def prepare_data_from_scenes(scenes):\n",
    "    all_node_features = []\n",
    "    all_edges = []\n",
    "    all_labels = []\n",
    "    all_indices = []\n",
    "    \n",
    "    total_nodes = 0\n",
    "    for scene in scenes:\n",
    "        # Get data from scene\n",
    "        node_features = scene[\"node_features\"]\n",
    "        edges = scene[\"edges\"]\n",
    "        labels = scene[\"labels\"]\n",
    "        \n",
    "        # Check for NaN values\n",
    "        valid_mask = tf.math.logical_not(tf.math.reduce_any(tf.math.is_nan(node_features), axis=1))\n",
    "        #if tf.reduce_sum(tf.cast(valid_mask, tf.int32)) < len(node_features):\n",
    "            #print(f\"Found {len(node_features) - tf.reduce_sum(tf.cast(valid_mask, tf.int32))} NaN values in scene {scene['scene_id']}\")\n",
    "        \n",
    "        # Filter out nodes with NaN values and adjust edges\n",
    "        valid_indices = tf.where(valid_mask)[:, 0]\n",
    "        \n",
    "        # Create index mapping for valid nodes\n",
    "        old_to_new = {}\n",
    "        for new_idx, old_idx in enumerate(valid_indices.numpy()):\n",
    "            old_to_new[old_idx] = new_idx\n",
    "        \n",
    "        # Filter node features and labels\n",
    "        node_features_filtered = tf.gather(node_features, valid_indices)\n",
    "        labels_filtered = tf.gather(labels, valid_indices)\n",
    "        \n",
    "        # Adjust edges to account for removed nodes\n",
    "        valid_edges = []\n",
    "        for edge in edges.numpy():\n",
    "            source, target = edge\n",
    "            if source in old_to_new and target in old_to_new:\n",
    "                valid_edges.append([old_to_new[source], old_to_new[target]])\n",
    "        \n",
    "        # Skip if no valid edges remain\n",
    "        if not valid_edges:\n",
    "            # print(f\"Skipping scene {scene['scene_id']} - no valid edges after filtering\")\n",
    "            continue\n",
    "            \n",
    "        # Convert to tensor\n",
    "        edges_filtered = tf.constant(valid_edges, dtype=tf.int32)\n",
    "        \n",
    "        # Adjust edge indices to account for the total number of nodes so far\n",
    "        adjusted_edges = edges_filtered + total_nodes\n",
    "        \n",
    "        # Create node indices for this scene\n",
    "        indices = tf.range(len(node_features_filtered)) + total_nodes\n",
    "        \n",
    "        # Append to our lists\n",
    "        all_node_features.append(node_features_filtered)\n",
    "        all_edges.append(adjusted_edges)\n",
    "        all_labels.append(labels_filtered)\n",
    "        all_indices.append(indices)\n",
    "        \n",
    "        # Update total node count\n",
    "        total_nodes += len(node_features_filtered)\n",
    "    \n",
    "    # Concatenate all data\n",
    "    node_states = tf.concat(all_node_features, axis=0)\n",
    "    edges_list = tf.concat(all_edges, axis=0)\n",
    "    labels = tf.concat(all_labels, axis=0)\n",
    "    indices = tf.concat(all_indices, axis=0)\n",
    "    \n",
    "    return node_states, edges_list, indices, labels\n",
    "# Prepare training data\n",
    "node_states, edges, train_indices, train_labels = prepare_data_from_scenes(train_scenes)\n",
    "\n",
    "print(\"edges: \", edges[:10])\n",
    "print(\"node_states: \", node_states[:10])\n",
    "# Prepare validation data (optional)\n",
    "val_node_states, val_edges, val_indices, val_labels = prepare_data_from_scenes(val_scenes)\n",
    "\n",
    "# Prepare test data\n",
    "test_node_states, test_edges, test_indices, test_labels = prepare_data_from_scenes(test_scenes)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"Training: {len(train_indices)} nodes\")\n",
    "print(f\"Validation: {len(val_indices)} nodes\")\n",
    "print(f\"Testing: {len(test_indices)} nodes\")\n",
    "\n",
    "# Build model\n",
    "gat_model = GraphAttentionNetwork(\n",
    "    node_states, edges, HIDDEN_UNITS, NUM_HEADS, NUM_LAYERS, OUTPUT_DIM\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "gat_model.compile(loss=loss_fn, optimizer=optimizer, metrics=[accuracy_fn])\n",
    "\n",
    "# Define callbacks for better training\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_mean_squared_error\",\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Train the model with TensorFlow indices\n",
    "history = gat_model.fit(\n",
    "    x=train_indices,\n",
    "    y=train_labels,\n",
    "    validation_data=(val_indices, val_labels),\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "_, test_accuracy = gat_model.evaluate(x=test_indices, y=test_labels, verbose=1)\n",
    "print(f\"Test MSE: {test_accuracy}\")\n",
    "\n",
    "# Make predictions on test data\n",
    "test_predictions = gat_model.predict(test_indices)\n",
    "\n",
    "# Denormalize predictions and ground truth for visualization\n",
    "def denormalize(normalized_coords, min_vals, max_vals):\n",
    "    return normalized_coords * (max_vals - min_vals) + min_vals\n",
    "\n",
    "# Visualize some predictions (first test scene as example)\n",
    "test_scene = test_scenes[0]\n",
    "# Convert to tensor-compatible indexing\n",
    "scene_indices = tf.where(test_indices < len(test_scene[\"node_features\"]))[:, 0]\n",
    "\n",
    "if len(scene_indices) > 0:\n",
    "    # Convert to numpy array for easier handling\n",
    "    scene_indices_np = scene_indices.numpy()\n",
    "    scene_predictions = np.array(test_predictions)[scene_indices_np]\n",
    "    scene_ground_truth = np.array(test_labels)[scene_indices_np]\n",
    "    \n",
    "    # Check for valid min/max values\n",
    "    if np.any(np.isnan(test_scene[\"min_vals\"])) or np.any(np.isnan(test_scene[\"max_vals\"])):\n",
    "        print(\"Warning: NaN values found in min_vals or max_vals\")\n",
    "        # Use reasonable defaults if min/max values are NaN\n",
    "        min_vals = np.nanmin(scene_ground_truth, axis=0) if np.any(np.isnan(test_scene[\"min_vals\"])) else test_scene[\"min_vals\"]\n",
    "        max_vals = np.nanmax(scene_ground_truth, axis=0) if np.any(np.isnan(test_scene[\"max_vals\"])) else test_scene[\"max_vals\"]\n",
    "    else:\n",
    "        min_vals = test_scene[\"min_vals\"]\n",
    "        max_vals = test_scene[\"max_vals\"]\n",
    "    \n",
    "    # Print min/max values\n",
    "    print(f\"min_vals: {min_vals}\")\n",
    "    print(f\"max_vals: {max_vals}\")\n",
    "    \n",
    "    # Make sure we don't have division by zero in the original normalization\n",
    "    range_vals = max_vals - min_vals\n",
    "    if np.any(range_vals == 0):\n",
    "        print(\"Warning: Range of values is zero, adding small epsilon\")\n",
    "        range_vals = np.where(range_vals == 0, 1e-8, range_vals)\n",
    "        \n",
    "    # Denormalize with safeguards\n",
    "    pred_denorm = scene_predictions * range_vals + min_vals\n",
    "    truth_denorm = scene_ground_truth * range_vals + min_vals\n",
    "    \n",
    "    # Print some predictions\n",
    "    print(\"Predictions vs Ground Truth (first 5):\")\n",
    "    for i in range(min(5, len(scene_predictions))):\n",
    "        print(f\"Pred: [{pred_denorm[i][0]:.2f}, {pred_denorm[i][1]:.2f}], \" \n",
    "              f\"True: [{truth_denorm[i][0]:.2f}, {truth_denorm[i][1]:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dd98a8",
   "metadata": {},
   "source": [
    "## Test and evaluation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ffa24b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 970 nodes\n",
      "Validation: 285 nodes\n",
      "Testing: 165 nodes\n",
      "Epoch 1/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 639ms/step - mean_absolute_error: 18741.5293 - loss: 422.2069 - val_loss: 445.0100\n",
      "Epoch 2/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 178ms/step - mean_absolute_error: 16971.0137 - loss: 476.4238 - val_loss: 571.2065\n",
      "Epoch 3/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - mean_absolute_error: 15897.3115 - loss: 568.1819 - val_loss: 671.7411\n",
      "Epoch 4/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - mean_absolute_error: 14188.2725 - loss: 727.1000 - val_loss: 817.9021\n",
      "Epoch 5/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - mean_absolute_error: 12481.5254 - loss: 939.2967 - val_loss: 1075.7410\n",
      "Epoch 6/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - mean_absolute_error: 11351.4365 - loss: 1326.4062 - val_loss: 1799.7566\n",
      "Epoch 7/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - mean_absolute_error: 10987.4570 - loss: 2133.4089 - val_loss: 2492.4219\n",
      "Epoch 8/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - mean_absolute_error: 10879.6182 - loss: 2670.2744 - val_loss: 2797.7705\n",
      "Epoch 9/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - mean_absolute_error: 10526.0811 - loss: 2774.6455 - val_loss: 2690.9053\n",
      "Epoch 10/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - mean_absolute_error: 10657.7002 - loss: 2523.6982 - val_loss: 2584.6536\n",
      "Epoch 11/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - mean_absolute_error: 10056.1055 - loss: 2571.9993 - val_loss: 2556.3818\n",
      "Epoch 12/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - mean_absolute_error: 9963.4434 - loss: 2690.1008 - val_loss: 2492.6023\n",
      "Epoch 13/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - mean_absolute_error: 9887.2617 - loss: 2484.8206 - val_loss: 2502.9915\n",
      "Epoch 14/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - mean_absolute_error: 9391.1914 - loss: 2668.7131 - val_loss: 2614.5549\n",
      "Epoch 15/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 179ms/step - mean_absolute_error: 9429.2314 - loss: 2633.2871 - val_loss: 2741.4707\n",
      "Epoch 16/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - mean_absolute_error: 9209.8955 - loss: 2819.3279 - val_loss: 2825.6082\n",
      "Epoch 17/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - mean_absolute_error: 9046.2715 - loss: 2934.7708 - val_loss: 2899.4814\n",
      "Epoch 18/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - mean_absolute_error: 8600.9355 - loss: 3040.7131 - val_loss: 3032.6912\n",
      "Epoch 19/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - mean_absolute_error: 8717.5635 - loss: 3195.2886 - val_loss: 3109.1357\n",
      "Epoch 20/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - mean_absolute_error: 8331.8154 - loss: 3271.3525 - val_loss: 3166.1460\n",
      "Epoch 21/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 178ms/step - mean_absolute_error: 8273.3975 - loss: 3242.7253 - val_loss: 3222.7927\n",
      "Epoch 22/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - mean_absolute_error: 8409.9854 - loss: 3257.1697 - val_loss: 3275.4685\n",
      "Epoch 23/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - mean_absolute_error: 8202.6533 - loss: 3357.7412 - val_loss: 3249.0032\n",
      "Epoch 24/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - mean_absolute_error: 7934.7402 - loss: 3446.3918 - val_loss: 3159.0337\n",
      "Epoch 25/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - mean_absolute_error: 8041.5435 - loss: 3268.2021 - val_loss: 3296.0225\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - mean_absolute_error: 11629.1045 - loss: 2736.4873\n",
      "Test Mean Absolute Error: {'mean_absolute_error': <tf.Tensor: shape=(), dtype=float32, numpy=11826.349>}\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 526ms/step\n",
      "Filtered out 0 test scenes with NaN values\n",
      "Remaining valid test scenes: 13\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Selected scene 1352890820225 for visualization\n",
      "\n",
      "Predictions vs Ground Truth (first 5):\n",
      "Pred: [6993.40, -9536.65], True: [41199.00, -16423.00]\n",
      "Pred: [26043.21, -13985.17], True: [30368.00, -18207.00]\n",
      "Pred: [23209.40, -13318.34], True: [30422.00, -17732.00]\n",
      "Pred: [19134.74, -11298.92], True: [25220.00, -15159.00]\n",
      "Pred: [22137.72, -12943.10], True: [26272.00, -16371.00]\n",
      "Mean Absolute Error: 10108.15\n",
      "Mean Euclidean Distance Error: 15712.75 units\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for training and testing\n",
    "# Let's use the scenes we've loaded earlier\n",
    "\n",
    "# Helper function to prepare data from scenes\n",
    "# Modified prepare_data_from_scenes function to handle NaN values\n",
    "def prepare_data_from_scenes(scenes):\n",
    "    all_node_features = []\n",
    "    all_edges = []\n",
    "    all_labels = []\n",
    "    all_indices = []\n",
    "    \n",
    "    total_nodes = 0\n",
    "    for scene in scenes:\n",
    "        # Get data from scene\n",
    "        node_features = scene[\"node_features\"]\n",
    "        edges = scene[\"edges\"]\n",
    "        labels = scene[\"labels\"]\n",
    "        \n",
    "        # Check for NaN values\n",
    "        valid_mask = tf.math.logical_not(tf.math.reduce_any(tf.math.is_nan(node_features), axis=1))\n",
    "        #if tf.reduce_sum(tf.cast(valid_mask, tf.int32)) < len(node_features):\n",
    "            #print(f\"Found {len(node_features) - tf.reduce_sum(tf.cast(valid_mask, tf.int32))} NaN values in scene {scene['scene_id']}\")\n",
    "        \n",
    "        # Filter out nodes with NaN values and adjust edges\n",
    "        valid_indices = tf.where(valid_mask)[:, 0]\n",
    "        \n",
    "        # Create index mapping for valid nodes\n",
    "        old_to_new = {}\n",
    "        for new_idx, old_idx in enumerate(valid_indices.numpy()):\n",
    "            old_to_new[old_idx] = new_idx\n",
    "        \n",
    "        # Filter node features and labels\n",
    "        node_features_filtered = tf.gather(node_features, valid_indices)\n",
    "        labels_filtered = tf.gather(labels, valid_indices)\n",
    "        \n",
    "        # Adjust edges to account for removed nodes\n",
    "        valid_edges = []\n",
    "        for edge in edges.numpy():\n",
    "            source, target = edge\n",
    "            if source in old_to_new and target in old_to_new:\n",
    "                valid_edges.append([old_to_new[source], old_to_new[target]])\n",
    "        \n",
    "        # Skip if no valid edges remain\n",
    "        if not valid_edges:\n",
    "            # print(f\"Skipping scene {scene['scene_id']} - no valid edges after filtering\")\n",
    "            continue\n",
    "            \n",
    "        # Convert to tensor\n",
    "        edges_filtered = tf.constant(valid_edges, dtype=tf.int32)\n",
    "        \n",
    "        # Adjust edge indices to account for the total number of nodes so far\n",
    "        adjusted_edges = edges_filtered + total_nodes\n",
    "        \n",
    "        # Create node indices for this scene\n",
    "        indices = tf.range(len(node_features_filtered)) + total_nodes\n",
    "        \n",
    "        # Append to our lists\n",
    "        all_node_features.append(node_features_filtered)\n",
    "        all_edges.append(adjusted_edges)\n",
    "        all_labels.append(labels_filtered)\n",
    "        all_indices.append(indices)\n",
    "        \n",
    "        # Update total node count\n",
    "        total_nodes += len(node_features_filtered)\n",
    "    \n",
    "    # Concatenate all data\n",
    "    node_states = tf.concat(all_node_features, axis=0)\n",
    "    edges_list = tf.concat(all_edges, axis=0)\n",
    "    labels = tf.concat(all_labels, axis=0)\n",
    "    indices = tf.concat(all_indices, axis=0)\n",
    "    \n",
    "    return node_states, edges_list, indices, labels\n",
    "\n",
    "# Prepare training data\n",
    "node_states, edges, train_indices, train_labels = prepare_data_from_scenes(train_scenes)\n",
    "train_labels = train_labels\n",
    "\n",
    "# print(\"edges: \", edges[:10])\n",
    "# print(\"node_states: \", node_states[:10])\n",
    "\n",
    "# Prepare validation data (optional)\n",
    "val_node_states, val_edges, val_indices, val_labels = prepare_data_from_scenes(val_scenes)\n",
    "\n",
    "# Prepare test data\n",
    "test_node_states, test_edges, test_indices, test_labels = prepare_data_from_scenes(test_scenes)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"Training: {len(train_indices)} nodes\")\n",
    "print(f\"Validation: {len(val_indices)} nodes\")\n",
    "print(f\"Testing: {len(test_indices)} nodes\")\n",
    "\n",
    "\n",
    "# Define hyper-parameters\n",
    "HIDDEN_UNITS = 100\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 3\n",
    "OUTPUT_DIM = 2\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "loss_fn = keras.losses.MeanAbsoluteError(name=\"mean_absolute_error\")\n",
    "optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE, \n",
    "    #clipnorm=1.0,\n",
    "    epsilon=1e-8\n",
    ")\n",
    "accuracy_fn = keras.metrics.MeanAbsoluteError(name=\"mean_absolute_error\")\n",
    "\n",
    "# Build model\n",
    "gat_model = GraphAttentionNetwork(\n",
    "    node_states, edges, HIDDEN_UNITS, NUM_HEADS, NUM_LAYERS, OUTPUT_DIM\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "gat_model.compile(loss=loss_fn, optimizer=optimizer, metrics=[accuracy_fn])\n",
    "\n",
    "# Train the model with TensorFlow indices\n",
    "history = gat_model.fit(\n",
    "    x=train_indices,\n",
    "    y=train_labels,\n",
    "    validation_data=(val_indices, val_labels),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "_, test_accuracy = gat_model.evaluate(x=test_indices, y=test_labels, verbose=1)\n",
    "print(f\"Test Mean Absolute Error: {test_accuracy}\")\n",
    "\n",
    "# Visualize some predictions (first test scene as example)\n",
    "test_scene = test_scenes[0]\n",
    "# Convert to tensor-compatible indexing\n",
    "scene_indices = tf.where(test_indices < len(test_scene[\"node_features\"]))[:, 0]\n",
    "\n",
    "# Make predictions on test data\n",
    "test_predictions = gat_model.predict(test_indices)\n",
    "\n",
    "def check_scene_validity(scene):\n",
    "    \"\"\"Check if a scene has valid normalization values and features.\"\"\"\n",
    "    has_nan_features = tf.math.reduce_any(tf.math.is_nan(scene[\"node_features\"]))\n",
    "    \n",
    "    return not (has_nan_features)\n",
    "\n",
    "# First, filter out test scenes with NaN values\n",
    "valid_test_scenes = [scene for scene in test_scenes if check_scene_validity(scene)]\n",
    "print(f\"Filtered out {len(test_scenes) - len(valid_test_scenes)} test scenes with NaN values\")\n",
    "print(f\"Remaining valid test scenes: {len(valid_test_scenes)}\")\n",
    "\n",
    "# Make predictions on test data\n",
    "test_predictions = gat_model.predict(test_indices)\n",
    "\n",
    "# Visualize predictions for the first valid test scene\n",
    "if valid_test_scenes:\n",
    "    test_scene = valid_test_scenes[0]\n",
    "    print(f\"Selected scene {test_scene['scene_id']} for visualization\")\n",
    "    \n",
    "    # Get indices for this scene\n",
    "    scene_node_count = len(test_scene[\"node_features\"])\n",
    "    # Find which indices in the test set correspond to this scene\n",
    "    scene_global_indices = []\n",
    "    current_offset = 0\n",
    "    \n",
    "    for i, s in enumerate(valid_test_scenes):\n",
    "        if i == 0:  # First scene matches our selected test_scene\n",
    "            scene_global_indices = np.arange(current_offset, current_offset + scene_node_count)\n",
    "            break\n",
    "        current_offset += len(s[\"node_features\"])\n",
    "    \n",
    "    # Get predictions for these indices\n",
    "    scene_predictions = np.array(test_predictions)[scene_global_indices]\n",
    "    scene_ground_truth = np.array(test_labels)[scene_global_indices]\n",
    "    \n",
    "    # Print some predictions in the original coordinate space\n",
    "    print(\"\\nPredictions vs Ground Truth (first 5):\")\n",
    "    for i in range(min(5, len(scene_predictions))):\n",
    "        print(f\"Pred: [{scene_predictions[i][0]:.2f}, {scene_predictions[i][1]:.2f}], \" \n",
    "              f\"True: [{scene_ground_truth[i][0]:.2f}, {scene_ground_truth[i][1]:.2f}]\")\n",
    "    \n",
    "    # Calculate mean absolute error\n",
    "    mae = np.mean(np.abs(scene_predictions - scene_ground_truth))\n",
    "    print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "    \n",
    "    # Calculate Euclidean distance error\n",
    "    euclidean_errors = np.sqrt(np.sum((scene_predictions - scene_ground_truth)**2, axis=1))\n",
    "    mean_euclidean_error = np.mean(euclidean_errors)\n",
    "    print(f\"Mean Euclidean Distance Error: {mean_euclidean_error:.2f} units\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
